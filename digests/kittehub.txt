Directory structure:
‚îî‚îÄ‚îÄ kittehub/
    ‚îú‚îÄ‚îÄ ai_agents/
    ‚îÇ   ‚îú‚îÄ‚îÄ langgraph_bot/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ openai_agent_researcher/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ ai.py
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îú‚îÄ‚îÄ data.py
    ‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
    ‚îÇ       ‚îú‚îÄ‚îÄ slack.py
    ‚îÇ       ‚îú‚îÄ‚îÄ tools.py
    ‚îÇ       ‚îî‚îÄ‚îÄ workflow.py
    ‚îú‚îÄ‚îÄ ai_chat_assistant/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ ai.py
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ helpers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ prompt.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ repo_scanner.py
    ‚îú‚îÄ‚îÄ anthropic_slack_thread_tldr/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ workflow.py
    ‚îú‚îÄ‚îÄ auth0_to_hubspot/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ break_glass/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ approval_message.json.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ request_modal.json.txt
    ‚îú‚îÄ‚îÄ carbcat/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ _gendata.sh
    ‚îÇ   ‚îú‚îÄ‚îÄ _raw.zip
    ‚îÇ   ‚îú‚îÄ‚îÄ ai.py
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ data.py
    ‚îÇ   ‚îú‚îÄ‚îÄ handlers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ Makefile
    ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ test_ai.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_data.py
    ‚îú‚îÄ‚îÄ categorize_emails/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ confluence_to_slack/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ data_pipeline/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ bucket_event.json
    ‚îÇ   ‚îú‚îÄ‚îÄ example-sns-event.json
    ‚îÇ   ‚îú‚îÄ‚îÄ Makefile
    ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
    ‚îÇ   ‚îú‚îÄ‚îÄ schema.sql
    ‚îÇ   ‚îî‚îÄ‚îÄ subscription-event.json
    ‚îú‚îÄ‚îÄ devops/
    ‚îÇ   ‚îú‚îÄ‚îÄ github_issue_alert/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ github_workflows/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ postgresql/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ purrr/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_helper.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ debug.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github_helper.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github_pr.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github_pr_test.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ markdown_test.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slack_channel.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slack_cmd.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slack_cmd_test.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ slack_helper.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_utils.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ users.py
    ‚îÇ   ‚îú‚îÄ‚îÄ reviewkitteh/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ sftp/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îú‚îÄ‚îÄ program.py
    ‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ discord_to_spreadsheet/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ github_copilot_seats/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ message.json
    ‚îÇ   ‚îú‚îÄ‚îÄ seats.py
    ‚îÇ   ‚îú‚îÄ‚îÄ triggers.py
    ‚îÇ   ‚îî‚îÄ‚îÄ users.py
    ‚îú‚îÄ‚îÄ github_marketplace_to_slack/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ gocat/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ handlers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ Makefile
    ‚îÇ   ‚îú‚îÄ‚îÄ store.py
    ‚îÇ   ‚îî‚îÄ‚îÄ _extension/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ background.js
    ‚îÇ       ‚îú‚îÄ‚îÄ manifest.json
    ‚îÇ       ‚îú‚îÄ‚îÄ options.html
    ‚îÇ       ‚îú‚îÄ‚îÄ options.js
    ‚îÇ       ‚îî‚îÄ‚îÄ rules.json
    ‚îú‚îÄ‚îÄ google_cal_to_asana/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ google_forms_to_jira/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ hackernews/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ invoice_processing/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ openAI_handling.py
    ‚îÇ   ‚îú‚îÄ‚îÄ process_gmails.py
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ scan_gmails.py
    ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
    ‚îú‚îÄ‚îÄ jenkins_release/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ jira_google_calendar/
    ‚îÇ   ‚îú‚îÄ‚îÄ assignee_from_schedule/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ deadline_to_event/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ leash/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py
    ‚îÇ   ‚îú‚îÄ‚îÄ handlers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ incidents.py
    ‚îÇ   ‚îú‚îÄ‚îÄ Makefile
    ‚îÇ   ‚îú‚îÄ‚îÄ model.py
    ‚îÇ   ‚îú‚îÄ‚îÄ notifications.py
    ‚îÇ   ‚îú‚îÄ‚îÄ store.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_handlers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_incidents.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_model.py
    ‚îÇ   ‚îú‚îÄ‚îÄ test_store.py
    ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
    ‚îú‚îÄ‚îÄ project_template/
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ readme_template.md
    ‚îú‚îÄ‚îÄ quickstart/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ reliability/
    ‚îÇ   ‚îú‚îÄ‚îÄ aws_health_monitor/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ incidenter/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ height.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ zoom.py
    ‚îÇ   ‚îú‚îÄ‚îÄ missing_jira_events_monitor/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ session_errors_monitor/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ room_reservation/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ available_rooms.py
    ‚îÇ   ‚îú‚îÄ‚îÄ reserve_room.py
    ‚îÇ   ‚îú‚îÄ‚îÄ room_status.py
    ‚îÇ   ‚îî‚îÄ‚îÄ util.py
    ‚îú‚îÄ‚îÄ samples/
    ‚îÇ   ‚îú‚îÄ‚îÄ anthropic/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ asana/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ atlassian/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jira/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ auth0/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ discord/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discord_client/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ github/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ google/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calendar/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ drive/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forms/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ new_question.json
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gmail/
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sheets/
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ http/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ basic_auth.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bearer_token.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ no_auth.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ webhooks.py
    ‚îÇ   ‚îú‚îÄ‚îÄ hubspot/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ linear/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ queries.py
    ‚îÇ   ‚îú‚îÄ‚îÄ notion/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ openai_chatgpt/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ pipedrive/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ reddit/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ runtime_events/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ scheduler/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ slack/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ approval_message.json.txt
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ message.json
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ sync_webhook/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ twilio/
    ‚îÇ       ‚îú‚îÄ‚îÄ README.md
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ scrapingbee_fetch_news/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ sheets_to_soap/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ slack_discord_sync/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ slack_support/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ directory.py
    ‚îÇ   ‚îú‚îÄ‚îÄ gemini.py
    ‚îÇ   ‚îî‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ task_chain/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ event_driven/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interactive_message.json.txt
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ single_workflow/
    ‚îÇ       ‚îú‚îÄ‚îÄ advanced/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ interactive_message.json.txt
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ       ‚îî‚îÄ‚îÄ basic/
    ‚îÇ           ‚îú‚îÄ‚îÄ README.md
    ‚îÇ           ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ           ‚îú‚îÄ‚îÄ interactive_message.json.txt
    ‚îÇ           ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ telegram_ai_translator/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py
    ‚îú‚îÄ‚îÄ walkthroughs/
    ‚îÇ   ‚îú‚îÄ‚îÄ new_gmail_notification/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ quickstart/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ send_email/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îú‚îÄ‚îÄ send_slack_message/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îÇ   ‚îî‚îÄ‚îÄ webhook/
    ‚îÇ       ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ webhook_to_jira/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îú‚îÄ‚îÄ whatsapp_chatbot/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ autokitteh.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ program.py
    ‚îî‚îÄ‚îÄ youtube_upload_notif/
        ‚îú‚îÄ‚îÄ README.md
        ‚îú‚îÄ‚îÄ autokitteh.yaml
        ‚îî‚îÄ‚îÄ program.py

================================================
FILE: ai_agents/langgraph_bot/README.md
================================================
title: LangGraph Bot with Tavily, and Google Sheets
description: Slack bot built with LangGraph and powered by Gemini LLM that can search information and update Google Sheets
integrations: ["slack", "googlesheets"]
categories: ["AI", "Productivity"]
tags: ["user_interactions", "notifications", "webhook_handling", "data_processing"]



================================================
FILE: ai_agents/langgraph_bot/autokitteh.yaml
================================================
# This YAML file defines a manifest for an AutoKitteh project that
# creates a Langgraph bot.

version: v1

project:
  name: Langgraph_Bot

  connections:
    - name: slack_conn
      integration: slack
    - name: sheets_conn
      integration: googlesheets

  triggers:
    - name: on_message
      event_type: app_mention
      connection: slack_conn
      call: program.py:on_app_mention

  vars:
    - name: GOOGLE_API_KEY
      value: ""
    - name: TAVILY_API_KEY
      value: ""



================================================
FILE: ai_agents/langgraph_bot/program.py
================================================
"""LangGraph Bot for Slack using LangGraph, Google Gemini LLM, and Google Sheet API."""

from typing import Annotated, TypedDict

from autokitteh.google import google_sheets_client
from autokitteh.slack import slack_client
from langchain_core.tools import tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch
from langgraph.graph import END
from langgraph.graph import START
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.prebuilt import tools_condition


slack = slack_client("slack_conn")
sheet = google_sheets_client("sheets_conn").spreadsheets().values()


SYSTEM_ROLE = (
    "You are a helpful assistant. Answer the user's questions clearly and concisely. "
    "If you don't know something, you may use a search engine to find "
    "reliable information."
)


@tool
def write_to_sheet(sheet_id: str, table: str):
    """Write into a specified Google Sheet. Provide rows as a CSV-style string."""
    rows = [row.strip().split(",") for row in table.strip().split("\n")]

    sheet.update(
        spreadsheetId=sheet_id,
        range="Sheet1!A1:B7",
        valueInputOption="USER_ENTERED",
        body={"values": rows},
    ).execute()

    return {"status": "success", "message": "wrote to sheet successfully!"}


class State(TypedDict):
    """State of the LangGraph bot."""

    messages: Annotated[list, add_messages]


llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash")
search_tool = TavilySearch(max_results=2)
tools = [search_tool, write_to_sheet]
llm_with_tools = llm.bind_tools(tools)


def chatbot(state: State):
    """Chat interaction using the LLM and available tools."""
    messages = [{"role": "system", "content": SYSTEM_ROLE}] + state["messages"]
    return {"messages": [llm_with_tools.invoke(messages)]}


# Compile the LangGraph here instead of inside an autokitteh activity.
# Returning builder.compile() directly from an activity causes a pickle error
# due to non-deterministic objects.

builder = StateGraph(State)
builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
builder.add_node("tools", tool_node)

builder.add_edge(START, "chatbot")
builder.add_conditional_edges("chatbot", tools_condition)
builder.add_edge("tools", "chatbot")
builder.add_edge("chatbot", END)

graph = builder.compile()


def on_app_mention(event):
    """Handle incoming Slack messages and respond using the LangGraph bot."""
    initial_state = {"messages": [{"role": "user", "content": event.data.text}]}
    result = graph.invoke(initial_state)

    ai_message = result["messages"][-1]

    slack.chat_postMessage(channel=event.data.channel, text=ai_message.content)



================================================
FILE: ai_agents/langgraph_bot/requirements.txt
================================================
langgraph
langchain
typing
langchain_google_genai
langchain-core
langchain-tavily



================================================
FILE: ai_agents/openai_agent_researcher/README.md
================================================
title: OpenAI Agent Researcher
description: A Slack-based research agent workflow.
integrations: ["chatgpt", "slack"]
categories: ["AI"]
tags: ["interactive_workflows", "user_interactions", "activity"]



================================================
FILE: ai_agents/openai_agent_researcher/ai.py
================================================
"""AI Agents definitions."""

import asyncio
from time import sleep

from agents import Agent
from agents import Runner
from agents import WebSearchTool
from agents.model_settings import ModelSettings
from agents.run import RunConfig
from autokitteh import activity
from openai import RateLimitError

from data import Report
from data import ResearchPlan
from data import SearchResearchItem
from slack import next_input
from slack import send
from tools import send_slack_report


_plan_agent = Agent(
    name="PlannerAgent",
    instructions="""
You are a helpful research assistant. Given a query, come up with a set of tasks
to perform to best answer the query. Output between 3 and 10 tasks to perform.
A task can be either:
- A search task: search the web for a specific term and summarize the results.
- An ask someone task: ask a specific person a question and summarize the answer.
  If a user explicitly specifies a time limit for a specific user, set it as such.
  Do this only if the user explicitly specifies a person to ask.
For each task result, if applicable, default max tokens to None, unless user explicitly
specified otherwise. User cannot be allowed to specify max tokens below 16.
You can also modify an existing plan, by adding or removing searches.
Always provide the complete plan as output along with an indication if the user
considers it final.
Consider the plan as final only if the user explicitly specifies so.
""",
    model="gpt-4o",
    output_type=ResearchPlan,
)

_search_agent = Agent(
    name="SearchAgent",
    instructions="""
You are a research assistant. Given a search term, you search the web for that term and
produce a concise summary of the results. The summary must 2-3 paragraphs and less than
300 words. Capture the main points. Write succinctly, no need to have complete sentences
or good grammar. This will be consumed by someone synthesizing a report, so its vital
you capture the essence and ignore any fluff. Do not include any additional commentary
other than the summary itself.
""",
    tools=[WebSearchTool()],
    model_settings=ModelSettings(tool_choice="required"),
    output_type=str,
)

_report_agent = Agent(
    name="ReporterAgent",
    instructions="""
Given a question and a set of search results, write a short summary of the findings.
Refine the report per user's feedback.
If the user wishes to send a slack report, use the appropriate tools to send the slack
report to the desired user.
""",
    model="gpt-4o",
    tools=[send_slack_report],
    output_type=Report | str,
)


@activity
def _run(agent: Agent, history: list, q: str, rc: RunConfig) -> tuple[str, list]:
    """Run the agent with the given query and history."""
    send("ü§î")

    while True:
        try:
            response = asyncio.run(
                Runner.run(
                    agent,
                    history + [{"role": "user", "content": q}],
                    run_config=rc,
                )
            )

            return response.final_output, response.to_input_list()
        except RateLimitError as e:
            # In case of a rate limit error, retry after waiting for 5 seconds.
            send(f"Rate limit error: {e}\n\nWaiting 5 seconds and retrying...")
            sleep(5)


def _chat(agent, is_final, q: str):
    """Chat with the agent until the response is final.

    An interaction using this function can span some back and forth
    between the user and the agent.

    Args:
        agent: The agent to chat with.
        is_final: A function to check if the response is final.
        q: The initial query.
    """
    history = []
    response = None

    while not (response and is_final(response)):
        if not q:
            q = next_input()

        response, history = _run(agent, history, q, RunConfig())

        send(response)

        q = None

    return response


def plan(q: str) -> ResearchPlan:
    """Plan agent driver."""
    return _chat(_plan_agent, lambda x: x.is_final, q)


def search(q: SearchResearchItem) -> str:
    """Search agent driver."""
    return _run(
        _search_agent,
        [],
        q.query,
        RunConfig(
            model_settings=ModelSettings(
                tool_choice="required",
                max_tokens=q.max_tokens,
            ),
        ),
    )[0]


def report(q: str, tasks: dict[str, str]):
    """Report agent driver."""
    q = f"Question: {q}\n\n\nTasks results: \n"
    for key, value in tasks.items():
        q += f"- {key}: {value}\n\n"

    return _chat(_report_agent, lambda _: False, q)



================================================
FILE: ai_agents/openai_agent_researcher/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that monitors comments on GitHub issues.

version: v1

project:
  name: openai_agent_researcher

  vars:
    - # The invocation command to trigger the agent from slack.
      # It will always be prefixed with '!'.
      name: INVOCATION_CMD
      value: "research"
    - name: OPENAI_API_KEY
      secret: true
      # Put here your Open AI API key.
      value: "sk-..."

  connections:
    # We use Slack to interact with the users.
    - name: slack_conn
      integration: slack

  triggers:
    # workflow.py:on_slack message will be triggered on every `message` event
    # that is not a reply to a thread and starts with `!`.
    - name: slack_message
      connection: slack_conn
      event_type: message
      filter: "data.thread_ts == '' && data.text.startsWith('!')"
      call: workflow.py:on_slack_message



================================================
FILE: ai_agents/openai_agent_researcher/data.py
================================================
"""AI Agents data definitions."""

from pydantic import BaseModel


class ResearchItemCommon(BaseModel):
    """Common fields for research items.

    This is not use as a base class since there are some issues with
    openai agents and polymorphism.
    """

    id: int
    "The id of the search item"

    reason: str
    "Your reasoning for why this search is important to the query."

    def __str__(self):
        return f"üîç {self.id}. {self.reason.removesuffix('.')}:\n"


class SearchResearchItem(BaseModel):
    """Search the web for a specific query."""

    max_tokens: int | None
    "The maximum number of tokens to generate for the search result."

    query: str
    "The search term to use for the web search."

    common: ResearchItemCommon
    "Common fields for research items"

    def __str__(self):
        return f"""{self.common}Search Query: "{self.query}"
{f"Max Tokens: {self.max_tokens}" if self.max_tokens else ""}"""


class AskSomeoneResearchItem(BaseModel):
    """Ask someone for additional information."""

    wait_time_in_seconds: int
    "The time to wait for a response from the person."

    question: str
    "The question to ask someone."

    who: str
    "Who to ask the question to."

    common: ResearchItemCommon
    "Common fields for research items"

    def __str__(self):
        time_limit = ""
        if self.wait_time_in_seconds:
            time_limit = f"Time Limit: {self.wait_time_in_seconds} seconds"

        return f"""{self.common}Person: {self.who}
Question: "{self.question}"
{time_limit}"""


class ResearchPlan(BaseModel):
    """A plan for a research report."""

    question: str
    """What is the question the report needs to answer."""

    tasks: list[SearchResearchItem | AskSomeoneResearchItem]
    """A list of tasks to perform to best answer the query."""

    is_final: bool
    """If the plan is final or not"""

    explanation: str
    """Explanation of the plan"""

    def __str__(self):
        text = f"""{self.explanation}

Q: {self.question}

{"Final" if self.is_final else "Draft"} Plan:
"""
        for task in self.tasks:
            text += f"{task}\n"

        return text


class Report(BaseModel):
    """A report summarizing the findings of the research."""

    question: str
    """The question the report is answering."""

    result: str
    """The result of the report."""

    def __str__(self):
        return f"""\nFinal Report:
Q: {self.question}
A: {self.result}
"""



================================================
FILE: ai_agents/openai_agent_researcher/requirements.txt
================================================
openai-agents
pydantic



================================================
FILE: ai_agents/openai_agent_researcher/slack.py
================================================
"""Entrypoint when using from AutoKitteh with Slack."""

from autokitteh import next_event, subscribe
from autokitteh.slack import slack_client
from slack_sdk.errors import SlackApiError


slack = slack_client("slack_conn")

_ch = None
_ts = None
_subscription = None


def init(ch: str, ts: str):
    """Initialize the Slack channel and thread timestamp."""
    global _ch, _ts, _subscription

    _subscription = subscribe(
        "slack_conn",
        f"data.type == 'message' && data.bot_id == '' && data.thread_ts == '{ts}'",
    )

    _ch = ch
    _ts = ts


def _lookup_user(who: str) -> dict[str, any]:
    user_id = who
    if who.startswith("<@"):
        user_id = who[2:-1]
    elif who.startswith("@"):
        user_id = who[1:]
    elif "@" in who:
        try:
            user_id = slack.users_lookupByEmail(email=who)["user"]["id"]
        except SlackApiError as e:
            print(f"error: {e}")
            return None
    else:
        return None

    try:
        user = slack.users_info(user=user_id).get("user")
    except SlackApiError as e:
        print(f"error: {e}")
        return None

    print(f"lookup: {who} -> {user}")

    return user


def _post(text: str, user_id: str | None = None):
    ch, ts = _ch, _ts
    if user_id:
        ch, ts = user_id, None

    print(f"{ch}{(',' + ts) if ts else ''}: {text}")
    slack.chat_postMessage(channel=ch, text=text, thread_ts=ts)


def send(content: any, who: str | None = None):
    print(f"send: {who} <- {content}")
    if who:
        who = _lookup_user(who)
        if not who:
            _post(f"Sorry, I couldn't find the user {who}.")
            return

        who = who.get("id")

    _post(str(content), who)


def next_input():
    event = next_event(_subscription)
    if event is None:
        raise EOFError

    print(f"Q: {event.text}")

    return event.text


def ask(what: str, who: str, t: int | None = None) -> tuple[str, str]:
    user = _lookup_user(who)
    if not user:
        _post(f"Sorry, I couldn't find the user {who}.")
        return None, None

    user_id = user.get("id")

    send(f"‚ùì <@{user_id}>: {what}")

    while True:
        event = next_event(_subscription, timeout=t)
        if not event:
            return user, None

        if event.user == user_id:
            return user, event.text

        _post("Sorry, only the person mentioned can respond.")



================================================
FILE: ai_agents/openai_agent_researcher/tools.py
================================================
"""Agent tools for the OpenAI agent."""

from agents import function_tool

import data
import slack


@function_tool
async def send_slack_report(r: data.Report, user: str) -> None:
    """Send a Slack report to the given user."""
    slack.send(r, user)



================================================
FILE: ai_agents/openai_agent_researcher/workflow.py
================================================
"""Main workflow logic."""

from os import getenv

import ai
import data
import slack


_prefix = f"!{getenv('INVOCATION_CMD', 'research')} "


def workflow(q: str):
    """Run the entire interaction with the user.

    There are three phases:
    1. Plan the search.
    2. Execute the search.
    3. Report the results.
    """
    # Plan the search.
    search_plan = ai.plan(q)

    # Iterate over all tasks in the plan and execute them.
    slack.send("Now I will execute on the plan.\n")
    tasks: dict[str, data.ResearchItem] = {}
    for t in search_plan.tasks:
        match type(t):
            case data.SearchResearchItem:
                slack.send(f"üîç Searching for: {t.query}...")
                tasks[f"Search query result for {t.query}"] = ai.search(t)
            case data.AskSomeoneResearchItem:
                slack.send(f"üí¨ Asking {t.who} the question: {t.question}...")
                who, answer = slack.ask(t.question, t.who, t.wait_time_in_seconds)
                if who:
                    if not answer:
                        slack.send(f"{who['real_name']} did not answer the question.")
                        answer = "No answer"

                    tasks[f"According to the user {who['real_name']}"] = answer
                else:
                    tasks[f"According to the user {t.who}"] = (
                        f"could not figure out which user is {t.who}"
                    )

    # Summarize and report the results.
    slack.send("All tasks complete, summarizing results...")
    ai.report(search_plan.question, tasks)


def on_slack_message(event):
    text = event.data.text

    if not text.startswith(_prefix):
        print("irrelevant")
        return

    slack.init(event.data.channel, event.data.ts)

    q = text.removeprefix(_prefix)
    print(f"Q: {q}")

    workflow(q)



================================================
FILE: ai_chat_assistant/README.md
================================================
title: AI chat assistant
description: A Slack-based automation assistant that leverages ChatGPT to manage and respond to messages by integrating with GitHub and Google Sheets.
integrations: ["chatgpt", "github", "googlesheets", "slack"]
categories: ["AI"]
tags: ["subscribe", "next_event", "event_loops", "long_running", "interactive_workflows", "essential"]



================================================
FILE: ai_chat_assistant/ai.py
================================================
"""This module provides the main functionality for the AI chatbot assistant.

It integrates with Slack and uses OpenAI's GPT model to generate responses based
on user messages. It also interacts with Google Sheets to store and retrieve data.
"""

import json
import os
from pathlib import Path

import autokitteh
from autokitteh.openai import openai_client
from autokitteh.slack import slack_client

import helpers
from repo_scanner import find_unanswered_comments


REPO_NAME = os.getenv("REPO_NAME")
SHEET_ID = os.getenv("SHEET_ID")
SHEET_NAME = os.getenv("SHEET_NAME")
SYSTEM_PROMPT = Path("prompt.txt").read_text()

chatgpt = openai_client("chatgpt_conn")
slack = slack_client("slack_conn")


def on_activate(_):
    """Entrypoint for the AI chatbot assistant."""
    while True:
        print("Waiting for a message...")
        subs = autokitteh.subscribe("slack_conn", "event_type == 'message'")
        data = autokitteh.next_event(subs)
        if data:
            on_slack_message(data)


def on_slack_message(data):
    """Determine the action to take based on an incoming Slack message.

    Args:
        data: The data from the Slack event.
    """
    user, user_text = data["user"], data["text"]
    response = get_chatgpt_response(user_text)

    # Always send initial response.
    slack.chat_postMessage(channel=user, text=response["message"])

    match response["action"]:
        case "list":
            rows = helpers.get_sheets_data(SHEET_NAME)
            message = helpers.format_messages_for_slack(rows)
            slack.chat_postMessage(channel=user, text=message)
        case "scan":
            comments = find_unanswered_comments(REPO_NAME, user)
            helpers.append_row_to_sheet(SHEET_NAME, comments)
            rows = helpers.get_sheets_data(SHEET_NAME)
            message = helpers.format_messages_for_slack(rows)
            slack.chat_postMessage(channel=user, text=message)


def get_chatgpt_response(user_text):
    response = chatgpt.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ],
    )
    return json.loads(response.choices[0].message.content)



================================================
FILE: ai_chat_assistant/autokitteh.yaml
================================================
version: v1

project:
  name: ai_chatbot_assistant

  vars:
    - name: SHEET_ID
      value:
    - name: SHEET_NAME
      value:
    - name: REPO_NAME
      value:

  connections:
    - name: chatgpt_conn
      integration: chatgpt
    - name: github_conn
      integration: github
    - name: sheets_conn
      integration: googlesheets
    - name: slack_conn
      integration: slack



================================================
FILE: ai_chat_assistant/helpers.py
================================================
"""Helper functions for Google Sheets and Slack."""

import os

import autokitteh
from autokitteh.google import google_sheets_client


sheets = google_sheets_client("sheets_conn")

SHEET_ID = os.getenv("SHEET_ID")


@autokitteh.activity
def get_sheets_data(sheet_name: str) -> dict:
    """Get data from the specified Google Sheet.

    Args:
        sheet_name (str): The name of the sheet (tab).

    Returns:
        dict: The data from the sheet.
    """
    range_name = f"{sheet_name}!A:D"
    return (
        sheets.spreadsheets()
        .values()
        .get(spreadsheetId=SHEET_ID, range=range_name)
        .execute()
    )


@autokitteh.activity
def append_row_to_sheet(sheet_name: str, values: list):
    """Appends a row to the specified Google Sheet.

    Args:
        spreadsheet_id (str): The Google Spreadsheet ID.
        sheet_name (str): The name of the sheet (tab).
        values (list): List of tuples containing (pr_number, author, body, url).
    """
    range_name = f"{sheet_name}!A:D"  # Use columns A-D for the 4 values.
    # Transform list of tuples into list of lists for the API.
    formatted_values = [
        [str(comment_id), author, body, url] for comment_id, author, body, url in values
    ]
    body = {"values": formatted_values}

    sheets.spreadsheets().values().append(
        spreadsheetId=SHEET_ID,
        range=range_name,
        valueInputOption="RAW",
        insertDataOption="INSERT_ROWS",
        body=body,
    ).execute()


def format_messages_for_slack(rows):
    if not rows or "values" not in rows:
        return "No messages found."

    formatted_messages = []
    for row in rows["values"]:
        comment_id, author, body, url = row
        message = (
            f"*Comment ID:* {comment_id}\n"
            f"*Author:* {author}\n"
            f"*Message:* {body}\n"
            f"*URL:* {url}\n"
            "---"  # Add separator between messages.
        )
        formatted_messages.append(message)

    return "\n".join(formatted_messages)



================================================
FILE: ai_chat_assistant/prompt.txt
================================================
You are an automation assistant that interprets plain-English requests into a structured JSON response.

Your response must be a JSON object with exactly two fields:
- "action": One of the following single-word responses: "list", "schedule", "track", "scan", "error", or "help".
- "message": A short, natural-sounding explanation of why the action was chosen or an error message. The message should be addressed to the user.

### Key Rules:
1. The "action" field must contain exactly one of the approved values.
2. The "message" field should be clear, concise, and slightly conversational to make responses feel more natural.
3. **Implemented actions**: "list", "scan".
   - Respond with the correct action and an appropriate message.
   - Example for "scan":
     {
       "action": "scan",
       "message": "Got it! I'll start scanning now. This might take up to a minute."
     }
   - Example for "list":
     {
       "action": "list",
       "message": "Sure! Here's what I found for you."
     }
   - If the request implies listing or scanning (e.g., "check for unresponded messages" ‚Üí "scan", "show me what I haven't responded to" ‚Üí "list"), interpret it accordingly.
4. **Not implemented actions**: "schedule", "track".
   - Respond with an "error" action:
     {
       "action": "error",
       "message": "Sorry, that feature isn't available yet."
     }
5. **Unrecognized requests**:
   - If the input doesn‚Äôt match a known action or a reasonable variation, respond with:
     {
       "action": "error",
       "message": "I didn‚Äôt quite get that. Try asking for 'list', 'scan', or 'help'."
     }
6. **Help requests**:
   - If the user asks for help, respond with "help" and provide an overview of the available actions:
     {
       "action": "help",
       "message": "I can list items, scan for updates, or provide help. Let me know what you need!"
     }
7. Always return **valid JSON**. Do not include any additional text outside the JSON response.



================================================
FILE: ai_chat_assistant/repo_scanner.py
================================================
"""Find unanswered GitHub PR comments older than 24 hours.

It tracks processed comments with Google Sheets,
and retrieves user information from Slack.
"""

import datetime
import os

from autokitteh import github, google
from autokitteh.slack import slack_client

import helpers


g = github.github_client("github_conn")
slack = slack_client("slack_conn")
sheets = google.google_sheets_client("sheets_conn")


SHEET_ID = os.getenv("SHEET_ID")
SHEET_NAME = os.getenv("SHEET_NAME")


def find_unanswered_comments(
    repo_name: str, user: str
) -> list[tuple[str, str, str, str]]:
    """Entrypoint for finding unanswered comments."""
    print("Finding unanswered messages...")
    sheets_data = helpers.get_sheets_data(SHEET_NAME)
    comment_ids_set = set()
    if "values" in sheets_data:
        for row in sheets_data["values"]:
            comment_ids_set.add(int(row[0]))
    return get_github_comments(comment_ids_set, repo_name, user)


def get_github_comments(
    comment_ids_set: set,
    repo_name: str,
    user: str,
) -> list[tuple[str, str, str, str]]:
    """Get all comments from GitHub that haven't been responded to in over 24 hours."""
    repo = g.get_repo(repo_name)
    pulls = repo.get_pulls(state="open")

    user_email = get_email_by_slack_user_id(user)
    github_user_id = get_github_user_id_by_email(user_email)

    unresponded = []

    # Process each pull request.
    for pr in pulls:
        # Combine issue and inline comments.
        issue_comments = list(pr.get_issue_comments())
        inline_comments = list(pr.get_comments())
        for comments, is_inline in [(issue_comments, False), (inline_comments, True)]:
            process_comments(
                comments,
                comment_ids_set,
                unresponded,
                github_user_id,
                is_inline=is_inline,
            )

    return unresponded


def process_comments(
    comments: list,
    comment_ids_set: set,
    unresponded: list,
    github_user_id: str,
    is_inline: bool = False,
):
    """Process either issue comments (PR discussion) or inline review comments."""
    for comment in comments:
        if should_skip_comment(comment, github_user_id):
            continue

        if has_been_responded_to(comment, comments, is_inline, github_user_id):
            continue

        if comment.id not in comment_ids_set:
            unresponded.append(
                (comment.id, comment.user.login, comment.body, comment.html_url)
            )
            comment_ids_set.add(comment.id)


def has_been_responded_to(
    target_comment, potential_responses, is_inline, github_user_id
):
    # Skip if comment is less than 24 hours old.
    now = datetime.datetime.now(datetime.UTC)
    if now - target_comment.created_at < datetime.timedelta(hours=24):
        return True

    # Check for emoji reactions.
    for reaction in target_comment.get_reactions():
        if reaction.user.login == github_user_id:
            return True

    # Check for comment responses.
    for response in potential_responses:
        if (
            response.created_at > target_comment.created_at
            and response.user.login == github_user_id
        ):
            if is_inline:
                return True

            # For issue comments, check for @ mentions or quotes.
            if has_mention_or_quote(response, target_comment):
                return True

    return False


def should_skip_comment(comment, github_user_id: str):
    return comment.user.login == github_user_id or github_user_id not in comment.body


def has_mention_or_quote(response, original_comment):
    if "@" + original_comment.user.login in response.body:
        return True

    # Check for quote.
    for line in response.body.splitlines():
        if line.strip().startswith(">") and original_comment.body[:30] in line:
            return True

    return False


def get_email_by_slack_user_id(user_id: str):
    return (
        slack.users_info(user=user_id)
        .get("user", {})
        .get("profile", {})
        .get("email", "")
    )


def get_github_user_id_by_email(email: str):
    return g.search_users(query=email)[0].login



================================================
FILE: anthropic_slack_thread_tldr/README.md
================================================
title: Anthropic Slack Thread TLDR
description: Summarizes a Slack thread using Claude
integrations: ["slack"]
categories: ["AI"]
tags: ["user_interactions", "notifications", "webhook_handling"]



================================================
FILE: anthropic_slack_thread_tldr/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh sample project that demonstrates integration with
# Gmail, ChatGPT, and Slack.

version: v2

project:
  name: anthropic_slack_thread_tldr

  vars:
    - name: ANTHROPIC_API_KEY
      secret: true
      # Put here your Anthropic API key.
      value: <your_anthropic_api_key_here>
      description: "Anthropic API Key for accessing Claude models."
    - name: MODEL
      value: "claude-3-5-haiku-20241022"
      description: "The Anthropic model to use."
    - name: MAX_TOKENS
      value: "1000"
      description: "Maximum number of tokens to use per invocation."

  connections:
    - # We use Slack to interact with the users.
      name: slack
      integration: slack
    - # We use Anthropic to summarize Slack threads.
      name: anthropic
      integration: anthropic

  triggers:
    - # Triggered when a Slack message event is a reply in a thread and begins with an exclamation mark (!).
      name: slack_message
      connection: slack
      event_type: message
      filter: "data.thread_ts != '' && data.text.startsWith('!tldr')"
      call: workflow.py:on_slack_thread_message



================================================
FILE: anthropic_slack_thread_tldr/workflow.py
================================================
"""Workflow to summarize Slack threads using Anthropic's API."""

from os import getenv

from autokitteh.anthropic import anthropic_client
from autokitteh.slack import slack_client


_CMD = "!tldr"
_MAX_TOKENS = int(getenv("MAX_TOKENS", "1000"))
_MODEL = getenv("MODEL", "claude-3-5-haiku-20241022")

_slack_client = slack_client("slack")
_anthropic = anthropic_client("anthropic")


def on_slack_thread_message(event):
    text = event.data.text.strip()

    if not (text == _CMD or text.startswith(_CMD + " ")):
        print("irrelevant")
        return

    focus, q = "", text[len(_CMD) :].strip()
    if q:
        focus = f"Focus on: {q}"
        print(focus)

    ch, ts, thread_ts = event.data.channel, event.data.ts, event.data.thread_ts

    try:
        _slack_client.reactions_add(channel=ch, timestamp=ts, name="thinking_face")

        msgs = _slack_client.conversations_replies(channel=ch, ts=thread_ts).get(
            "messages", []
        )

        msgs = "\n".join(f"- {msg['user']}: {msg['text']}" for msg in msgs)

        message = _anthropic.messages.create(
            max_tokens=_MAX_TOKENS,
            model=_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": f"""
Compose a summary of the Slack conversation in this thread.
{focus}

Use Slack mentions, for example: <@U12345678>.

These are the messages in the thread:
{msgs}""",
                }
            ],
        )

        summary = "".join(
            block.text for block in message.content if block.type == "text"
        )

        print(summary)

        _slack_client.reactions_remove(channel=ch, timestamp=ts, name="thinking_face")
        _slack_client.reactions_add(channel=ch, timestamp=ts, name="ok_hand")

        _slack_client.chat_postMessage(
            channel=ch,
            thread_ts=thread_ts,
            text=summary,
        )
    except:
        _slack_client.reactions_add(channel=ch, timestamp=ts, name="scream")
        raise



================================================
FILE: auth0_to_hubspot/README.md
================================================
title: Copy Auth0 Users to HubSpot
description: Periodically add new Auth0 users to HubSpot as contacts
integrations: ["auth0", "hubspot"]
categories: ["CRM"]
tags:
  [
    "data_pipeline",
    "data_processing",
    "error_handling",
    "notifications",
    "scheduled_tasks",
  ]



================================================
FILE: auth0_to_hubspot/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that adds new Auth0 users to HubSpot as contacts.

version: v1

project:
  name: auth0_to_hubspot

  vars:
    - name: HOURS
      value: 24

  connections:
    - name: auth0_conn
      integration: auth0
    - name: hubspot_conn
      integration: hubspot

  triggers:
    - name: daily
      schedule: "@every 24h"
      call: program.py:check_for_new_users



================================================
FILE: auth0_to_hubspot/program.py
================================================
"""This program adds new Auth0 users to HubSpot as contacts."""

from datetime import datetime, timedelta, UTC
import os

from autokitteh.auth0 import auth0_client
from autokitteh.hubspot import hubspot_client
from hubspot.crm.contacts import SimplePublicObjectInput
from hubspot.crm.contacts.exceptions import ApiException


LOOKUP_HOURS = int(os.getenv("HOURS", "24"))

auth0 = auth0_client("auth0_conn")
hubspot = hubspot_client("hubspot_conn")


def check_for_new_users(event):
    """Workflow entrypoint.

    Looks up new Auth0 users in the last `HOURS` hours,
    and adds them to HubSpot as contacts.
    """
    start, end = _get_time_range(LOOKUP_HOURS)
    query = f"created_at:[{start} TO {end}]"
    response = auth0.users.list(q=query, search_engine="v3")
    add_new_users(response["users"])


def _get_time_range(hours):
    """Calculate start and end times for user lookup."""
    now = datetime.now(UTC)
    start_time = now - timedelta(hours=hours)

    start_formatted = start_time.strftime("%Y-%m-%dT%H:%M:%SZ")
    end_formatted = now.strftime("%Y-%m-%dT%H:%M:%SZ")
    return (start_formatted, end_formatted)


def add_new_users(users):
    """Add new Auth0 users to HubSpot as contacts."""
    for user in users:
        contact = _create_hubspot_contact(user)
        try:
            hubspot.crm.contacts.basic_api.create(contact)
            print(f"Added to HubSpot: {user['email']}")
        except ApiException as e:
            if e.status == 409:
                print(f"Contact already exists in HubSpot: {user['email']}")
            else:
                print(f"Failed to add {user['email']} to HubSpot: {e}")
            continue


def _create_hubspot_contact(user):
    """Convert Auth0 user data to HubSpot contact format."""
    first_name, last_name = _extract_name(user)

    user_data = {
        "email": user["email"],
        "firstname": first_name,
        "lastname": last_name,
    }
    return SimplePublicObjectInput(properties=user_data)


def _extract_name(user):
    """Extracts first and last name from user."""
    if "given_name" in user and "family_name" in user:
        return user["given_name"], user["family_name"]

    name_parts = user.get("name", "").split()
    first = name_parts[0] if len(name_parts) > 0 else ""
    last = " ".join(name_parts[1:]) if len(name_parts) > 1 else ""
    return first, last



================================================
FILE: break_glass/README.md
================================================
title: Manage emergency AWS access requests via Slack
description: Submit emergency AWS access requests via Slack, which are then approved or denied based on a set of predefined conditions
integrations: ["slack", "jira"]
categories: ["DevOps"]
tags:
  [
    "approval_workflows",
    "interactive_workflows",
    "user_interactions",
    "activity",
  ]



================================================
FILE: break_glass/approval_message.json.txt
================================================
[
    {
        "type": "header",
        "text": {
            "type":  "plain_text",
            "emoji": true,
            "text":  "Break-Glass Request"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "RequestFromMessage"
        }
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "Ticket"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "Reason"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "actions",
        "elements": [
            {
                "type":  "button",
                "style": "primary",
                "text": {
                    "type":  "plain_text",
                    "emoji": true,
                    "text":  "Approve"
                },
                "value":     "Approve",
                "action_id": "Approve RequesterId IssueKey"
            },
            {
                "type":  "button",
                "style": "danger",
                "text": {
                    "type":  "plain_text",
                    "emoji": true,
                    "text":  "Deny"
                },
                "value":     "Deny",
                "action_id": "Deny RequesterId IssueKey"
            }
        ]
    }
]



================================================
FILE: break_glass/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that orchestrates the request and approval
# process for break glass scenarios.

version: v1

project:
  name: break_glass

  vars:
    - name: APPROVAL_CHANNEL
      value:

  connections:
    - name: jira_connection
      integration: jira
    - name: slack_connection
      integration: slack

  triggers:
    - name: slack_slash_command
      connection: slack_connection
      event_type: slash_command
      call: program.py:on_slack_slash_command
      filter: data.text == "break-glass"
    - name: form_submission
      connection: slack_connection
      event_type: interaction
      filter: data.type == "view_submission"
      call: program.py:on_form_submit
    - name: approve_deny
      connection: slack_connection
      event_type: interaction
      filter: data.type == "block_actions"
      call: program.py:on_approve_deny



================================================
FILE: break_glass/program.py
================================================
"""This program orchestrates the request and approval process for break glass scenarios.

Break glass scenarios occur when a developer needs to access sensitive data or perform
a critical operation that requires elevated permissions beyond their usual access.

Workflow:
    1. A developer initiates the process by using a Slack slash command to request
       break glass approval.
    2. AutoKitteh sends a form to the developer, requesting details about the reason
       for the elevated access.
    3. The developer fills out and submits the form, providing the necessary information
       and justification for the request.
    4. AutoKitteh sends a notification to the SRE (Site Reliability Engineering) team
       with an approve/deny message, including the details of the request.
    5. The SRE team reviews the request and makes a decision to approve or deny the
       request.
    6. AutoKitteh sends a message to the developer with the decision, notifying them
       whether the request was approved or denied.

The program integrates with Jira to verify ticket existence and ensure the requester
is the assignee of the ticket. It also uses Slack for communication and notifications
throughout the process.
"""

import os
from pathlib import Path

import autokitteh
from autokitteh.atlassian import get_base_url, jira_client
from autokitteh.slack import slack_client
from requests.exceptions import HTTPError


APPROVAL_CHANNEL = os.getenv("APPROVAL_CHANNEL")
jira = jira_client("jira_connection")
slack = slack_client("slack_connection")


def on_slack_slash_command(event):
    """Sends a form to request approval for a ticket."""
    trigger_id = event.data["trigger_id"]
    request_modal = Path("request_modal.json.txt").read_text()
    slack.views_open(trigger_id=trigger_id, view=request_modal)


@autokitteh.activity
def on_form_submit(event):
    reason, issue_key, base_url, requester_id = parse_event_data(event)

    if not check_issue_exists(issue_key):
        message = f"Ticket `{issue_key}` does not exist. Please try again."
        slack.chat_postMessage(channel=requester_id, text=message)
        return

    email = slack.users_info(user=requester_id)["user"]["profile"]["email"]
    if not validate_requester(issue_key, email):
        issue_link = f"<{base_url}/browse/{issue_key}|{issue_key}>"
        message = f"You are not the assignee in ticket {issue_link}. Please try again."
        slack.chat_postMessage(channel=requester_id, text=message)
        return

    send_approval_request(reason, issue_key, base_url, requester_id)
    slack.chat_postMessage(channel=requester_id, text="Request sent for approval.")


@autokitteh.activity
def on_approve_deny(event):
    action_id = event.data["actions"][0]["action_id"]
    _, requester, issue_key = action_id.split(" ")
    approver_id = event.data["user"]["id"]
    approver_info = slack.users_info(user=approver_id)

    if event.data["actions"][0]["value"] == "Approve":
        approver_email = approver_info["user"]["profile"]["email"]
        jira.issue_add_comment(issue_key, f"Request approved by: {approver_email}")
        message = f"Request approved by: <@{approver_info['user']['name']}>"
        slack.chat_postMessage(channel=requester, text=message)
    else:
        print(f"Requester: {requester}")
        message = f"Request denied by: <@{approver_info['user']['name']}>"
        slack.chat_postMessage(channel=requester, text=message)


def send_approval_request(reason, issue_key, base_url, requester_id):
    blocks = Path("approval_message.json.txt").read_text()
    changes = [
        ("RequestFromMessage", f"*Request from*: <@{requester_id}>"),
        ("Ticket", f"*Ticket*: <{base_url}/browse/{issue_key}|{issue_key}>"),
        ("Reason", "*Reason for request*: " + reason),
        ("RequesterId", requester_id),
        ("IssueKey", issue_key),
    ]
    for old, new in changes:
        blocks = blocks.replace(old, new)
    slack.chat_postMessage(channel=APPROVAL_CHANNEL, blocks=blocks)


def parse_event_data(event):
    form_data = event.data["view"]["state"]["values"]
    reason = form_data["block_reason"]["reason"]["value"]
    issue_key = form_data["block_issue_key"]["issue_key"]["value"]
    base_url = get_base_url("jira_connection")
    requester_id = event.data["user"]["id"]
    return reason, issue_key, base_url, requester_id


def check_issue_exists(issue_key):
    try:
        jira.issue(issue_key)
        return True
    except HTTPError as e:
        print(f"Error retrieving issue: {e}")
        return False


def validate_requester(issue_key, requester):
    issue = jira.issue(issue_key)
    assignee = issue.get("fields", {}).get("assignee") or {}
    assignee = assignee.get("emailAddress")
    return assignee == requester



================================================
FILE: break_glass/request_modal.json.txt
================================================
{
  "title": {
    "type": "plain_text",
    "text": "My App",
    "emoji": true
  },
  "submit": {
    "type": "plain_text",
    "text": "Submit",
    "emoji": true
  },
  "type": "modal",
  "close": {
    "type": "plain_text",
    "text": "Cancel",
    "emoji": true
  },
  "blocks": [
    {
      "type": "input",
      "block_id": "block_issue_key",
      "element": {
        "type": "plain_text_input",
        "action_id": "issue_key"
      },
      "label": {
        "type": "plain_text",
        "text": "Reference Ticket ID",
        "emoji": true
      }
    },
    {
      "type": "input",
      "block_id": "block_reason",
      "element": {
        "type": "plain_text_input",
        "multiline": true,
        "action_id": "reason"
      },
      "label": {
        "type": "plain_text",
        "text": "Reason",
        "emoji": true
      }
    }
  ]
}



================================================
FILE: carbcat/README.md
================================================
title: CarbCat - AI WhatsApp Carb Tracker
description: AI-powered WhatsApp chatbot that tracks carbohydrate content in food using USDA database
integrations: ["twilio"]
categories: ["AI", "Productivity"]
tags:
  ["user_interactions", "webhook_handling", "data_processing", "notifications"]



================================================
FILE: carbcat/_gendata.sh
================================================
#!/bin/bash

set -euo pipefail

if [ ! -f _raw.json ]; then
       curl https://fdc.nal.usda.gov/fdc-datasets/FoodData_Central_sr_legacy_food_json_2018-04.zip > _raw.zip
       unzip _raw.zip
       mv FoodData_Central_sr_legacy_food_json_2018-04.json _raw.json
fi


jq -r '.SRLegacyFoods | sort_by(.description) | .[] | 
       .description as $food | 
       ((.foodNutrients[] | select(.nutrient.number == "205") | .amount) // "N/A") as $carbs |
       .foodPortions[]? | 
       [$food, $carbs, .amount, .modifier, .gramWeight] | @csv' _raw.json > data.csv

rm -f data.csv.gz

gzip data.csv



================================================
FILE: carbcat/_raw.zip
================================================
[Non-text file]


================================================
FILE: carbcat/ai.py
================================================
"""AI interaction module for food id and carbohydrate calculation using Claude."""

from dataclasses import asdict
from dataclasses import dataclass
import json
from os import getenv
import typing

from anthropic.types.beta import BetaMessageParam

from anthropic import Anthropic
from anthropic import beta_tool
from autokitteh.anthropic import anthropic_client
from autokitteh.errors import ConnectionInitError
from data import find_foods_by_name
from data import Food
from data import get_food_by_index
from data import Portion


_MODEL = getenv("ANTHROPIC_MODEL", "claude-sonnet-4-5-20250929")

try:
    _client = anthropic_client("anthropic")
except ConnectionInitError:
    # Fallback to basic client if no special config is found, e.g. for local testing.
    _client = Anthropic(api_key=getenv("ANTHROPIC_API_KEY"))

_SYSTEM_PROMPT = """
You are a helpful assistant that determines what food item the user is referring to.
You also need to determine how much, in grams, did the user eat.

The food item and the portion size must match one of the items in the database.
To find the food item, use the `find_foods_by_name` tool. This will return a list of
possible foods, along with known portion sizes. You must use this information to
determine the food item and the number of portions that the user are.

If you cannot determine the food item, or if the food item is not in the database,
respond with a message instructing the user to improve their answer.

If the user specifies more than one food item, consider only the main one, and instruct
them to ask separately for each food item.

Use the `update` tool to update the context with the food item index, portion index,
and amount of portions. NEVER tell the user you're updating the context - this is an
internal detail that the user should not be aware of.

The `food_index` is the field `index` in the foods you receive from the
`find_foods_by_name` tool. The `portion_index` is the index of the portion in the
`portions` list in the relevant food item. The `amount` is the number of portions
consumed.

You MUST use the update tool to set `food_index`, `portion_index`, and `amount` to
non-null values, and set `done` to true, when you have determined the food item
and the amount in portions. You MUST NOT set `done` to true unless all the other
fields are set to non-null values.

So far this is what you gathered: {ctx}
"""


@dataclass(frozen=True, kw_only=True)
class _InteractionContext:
    """Agent interaction context."""

    food_index: int | None
    """Index of the food in the database."""

    portion_index: int | None
    """Index of the portion in the food's portions list."""

    amount: float | None
    """Number of portions consumed."""

    done: bool = False
    """Whether the determination is complete. Set this only if all the other fields are set."""  # noqa: E501

    def adopt(self, other: "_InteractionContext") -> "_InteractionContext":
        """Adopt non-None values from another context."""

        def bora(a, b):
            return b if b is not None else a

        return _InteractionContext(
            food_index=bora(self.food_index, other.food_index),
            portion_index=bora(self.portion_index, other.portion_index),
            amount=bora(self.amount, other.amount),
            done=other.done or self.done,
        )

    @property
    def complete(self) -> bool:
        """Whether the context is complete."""
        return (
            self.food_index is not None
            and self.portion_index is not None
            and self.amount is not None
            and self.done
        )  # noqa: E501


@beta_tool
def _find_foods_by_name_tool(name: str) -> str:
    return json.dumps(
        [
            {"food": asdict(food), "score": score}
            for food, score in find_foods_by_name(name)
        ]
    )


def interact(
    q0: str | None,
    get_next: typing.Callable[[], str],
    say: typing.Callable[[str], None],
) -> tuple[Food, Portion, float] | None:
    """Determine the food and grams from the history and current context.

    Args:
        q0: initial message from the user.
        get_next: function to get the next message from the user.
        say: function to say something to the user.

    Returns:
        A tuple of (context, history, response).
    """
    ctx = _InteractionContext(food_index=None, portion_index=None, amount=None)

    @beta_tool
    def update_tool(
        food_index: int | None = None,
        portion_index: int | None = None,
        amount: float | None = None,
        done: bool = False,
    ) -> str:
        """Update the determination context with new information.

        Args:
            ctx: The current determination context.
        """
        nonlocal ctx

        ctx1 = _InteractionContext(
            food_index=food_index,
            portion_index=portion_index,
            amount=amount,
            done=done,
        )

        ctx = ctx.adopt(ctx1) if ctx else ctx1

        return f"Context updated: {ctx}"

    q = q0
    history = []

    while not ctx.complete:
        if ctx.done:
            q = "you marked as done, but you did not set all the fields. please fix."

        if not q:
            q = get_next()

        history.append(BetaMessageParam(role="user", content=q.strip()))

        q = None

        runner = _client.beta.messages.tool_runner(
            model=_MODEL,
            max_tokens=1024,
            system=_SYSTEM_PROMPT.format(ctx=ctx),
            messages=history,
            tools=[_find_foods_by_name_tool, update_tool],
        )

        # Collect all messages from the runner
        # The runner handles tool execution internally and yields messages
        final_message = None

        for msg in runner:
            final_message = msg

            for block in msg.content:
                match block.type:
                    case "text":
                        say(block.text)
                    case "tool_use":
                        match block.name:
                            case "_find_foods_by_name_tool":
                                name = typing.cast(dict, block.input).get("name", "")
                                say(
                                    f"(Looking for {name} in the database...)"  # noqa: E501
                                )
                            case _:
                                pass
                    case _:
                        pass

        # Only add the final assistant message to history
        # Don't add intermediate tool_use/tool_result messages
        if final_message:
            history.append(
                BetaMessageParam(role=final_message.role, content=final_message.content)
            )

    if ctx.food_index is None or ctx.portion_index is None or ctx.amount is None:
        return None

    food = get_food_by_index(ctx.food_index)
    return food, food.portions[ctx.portion_index], ctx.amount



================================================
FILE: carbcat/autokitteh.yaml
================================================
version: v2

project:
  name: carbcat

  vars:
    - name: TWILIO_PHONE_NUMBER
      value: "+14155238886"

  connections:
    - name: twilio
      integration: twilio
    - name: anthropic
      integration: anthropic

  triggers:
    - name: whatsapp_message
      type: webhook
      call: handlers.py:on_whatsapp_message



================================================
FILE: carbcat/data.py
================================================
"""Data module for CarbCat."""

import csv
from dataclasses import dataclass
from dataclasses import replace
import gzip
from io import StringIO
from pathlib import Path
import re

import rapidfuzz


@dataclass(frozen=True, kw_only=True)
class Portion:
    """Class representing a portion size."""

    amount: float
    modifier: str
    gram_weight: float


@dataclass(frozen=True, kw_only=True)
class Food:
    """Class representing a row in the data."""

    index: int
    name: str
    carbs: float  # per 100g
    portions: list[Portion]


_foods: list[Food] = []


def _read() -> StringIO:
    """Load raw compressed data."""
    with Path("data.csv.gz").open("rb") as f:
        compressed = f.read()

    return StringIO(gzip.decompress(compressed).decode("utf-8"))


def _load() -> list[Food]:
    """Load food data from CSV file."""
    global _foods

    if not _foods:
        prev: Food | None = None

        r = csv.reader(_read())

        for i, row in enumerate(r):
            curr = Food(
                index=len(_foods),
                name=row[0],
                carbs=float(row[1]),
                portions=[
                    Portion(
                        amount=float(row[2]),
                        modifier=row[3],
                        gram_weight=float(row[4]),
                    )
                ],
            )

            if prev and prev.name == curr.name:
                if prev.carbs != curr.carbs:
                    raise ValueError(
                        f"line #{i + 1}: duplicate food with different carbs: {prev} != {curr}"  # noqa: E501
                    )

                _foods[-1] = replace(
                    prev,
                    index=prev.index,
                    portions=prev.portions + [curr.portions[0]],
                )
            else:
                prev = curr
                _foods.append(curr)

    return _foods


def get_food_by_index(idx: int) -> Food:
    """Get food by its index in the database.

    Args:
        idx: Index of the food.

    Returns:
        Food object.

    Raises:
        IndexError: If the index is out of range.
    """
    foods = _load()
    if idx < 0 or idx >= len(foods):
        raise IndexError(f"Food index {idx} out of range")
    return foods[idx]


def find_foods_by_name(q: str, top_n=100) -> list[tuple[Food, float]]:
    """Search for foods by name and return top N matches.

    Args:
        q: The food name to search for (str)
        top_n: Number of top matches to return (default: 5)

    Returns:
        List of foods and their associated matching scores
    """
    foods = _load()
    food_names = [food.name for food in foods]

    results = [
        (_calculate_food_name_score(q, name), idx)
        for idx, name in enumerate(food_names)
    ]

    # Sort by combined score
    results.sort(key=lambda x: x[0], reverse=True)

    idxs = _smart_cutoff(results)

    # Create a mapping from food index to score
    idx_to_score = {idx: score for score, idx in results}

    return [(foods[i], idx_to_score[i]) for i in idxs[:top_n]]


def _calculate_food_name_score(query: str, food_name: str) -> float:
    """Calculate relevance score for a food name match.

    Args:
        query: The search query
        food_name: The food name to score

    Returns:
        Combined relevance score
    """
    name_lower = food_name.lower()
    q_lower = query.lower()

    # Multiple scoring factors
    wratio_score = rapidfuzz.fuzz.WRatio(query, food_name)
    ratio_score = rapidfuzz.fuzz.ratio(q_lower, name_lower)
    token_sort = rapidfuzz.fuzz.token_sort_ratio(q_lower, name_lower)

    # Split by common delimiters
    words = re.split(r"[\s,\-\(\)]+", name_lower)

    # Check for exact word match and position
    has_exact_word = False
    is_first_word = False
    word_position = len(words)  # Default to end

    for i, word in enumerate(words):
        if word in [q_lower, q_lower + "s", q_lower + "es", q_lower + "ies"]:
            has_exact_word = True
            word_position = i
            if i == 0:
                is_first_word = True
            break

    # Penalize longer names
    length_penalty = 100 / (1 + len(food_name) / 20)

    # Penalize names with many words
    word_count_penalty = 100 / (1 + len(words) / 3)

    # Position bonus - earlier position = higher score
    # First word is MUCH more important (the food IS that thing)
    # vs later words (the food CONTAINS that thing)
    position_bonus = 0
    if has_exact_word:
        if is_first_word:
            position_bonus = 60  # Huge boost for first word (e.g., "Apples, raw")
        elif word_position == 1:
            position_bonus = 5  # Small boost for second word (e.g., "Strudel, apple")
        elif word_position == 2:
            position_bonus = 2  # Tiny boost for third word

    # Calculate combined score
    if has_exact_word:
        combined_score = (
            wratio_score * 0.25
            + ratio_score * 0.25
            + token_sort * 0.15
            + length_penalty * 0.10
            + word_count_penalty * 0.10
            + position_bonus  # Position is very important!
        )
    else:
        combined_score = wratio_score * 0.5 + ratio_score * 0.3 + token_sort * 0.2

    # Check if it's a substring match but NOT a word match
    is_substring_only = q_lower in name_lower and not has_exact_word
    if is_substring_only:
        combined_score *= 0.5  # Heavy penalty for substring-only matches

    return combined_score


def _smart_cutoff(results: list[tuple[float, int]]) -> list[int]:
    """Intelligently determine where to cut off search results based on score drops.

    Args:
        results: List of tuples (score, index) sorted by score descending

    Returns:
        List of indexes to include in final results
    """
    if not results:
        return []

    # Always include at least the top result
    if len(results) == 1:
        return [results[0][1]]

    top_score = results[0][0]

    # Calculate score drops between consecutive results
    score_drops = []
    for i in range(len(results) - 1):
        drop = results[i][0] - results[i + 1][0]
        score_drops.append((i, drop))

    # Find significant drops (> 2 points)
    significant_drops = [(i, drop) for i, drop in score_drops if drop > 2]

    if significant_drops:
        # Sort by drop size to find the largest
        significant_drops.sort(key=lambda x: x[1], reverse=True)
        largest_drop_idx, largest_drop_size = significant_drops[0]

        # Cut at the largest significant drop if it happens reasonably early
        # and is substantial enough
        if largest_drop_idx < 20 and largest_drop_size > 2:
            cutoff = largest_drop_idx + 1
            return [idx for _, idx in results[:cutoff]]

    # If no significant drops, filter by relative score to top result
    # Cut off results that drop below 85% of top score
    cutoff = len(results)
    for i, (score, _) in enumerate(results):
        # If score drops below 85% of top score, cut there
        # But keep at least 5 results
        if i >= 5 and score < (top_score * 0.85):
            cutoff = i
            break

    return [idx for _, idx in results[:cutoff]]



================================================
FILE: carbcat/handlers.py
================================================
"""Handlers for CarbCat events."""

from os import getenv

import ai
from autokitteh import del_value, Event, get_value, next_event, set_value, subscribe
from autokitteh.twilio import twilio_client


_twilio = twilio_client("twilio")

_TWILIO_PHONE_NUMBER = getenv("TWILIO_PHONE_NUMBER")


def _respond(to: str, msg: str) -> None:
    resp = _twilio.messages.create(
        body=msg,
        from_=f"whatsapp:{_TWILIO_PHONE_NUMBER}",
        to=f"{to}",
    )

    print(f"me: {msg}\n-> twilio: {resp}")


def on_whatsapp_message(event: Event):
    src = event.data.body.form.get("From")
    body = event.data.body.form.get("Body", "").strip()

    print(f"@{src}: {body}")

    if not src:
        print("no source specified.")
        return

    if not body:
        print("no body specified.")
        return

    if body == "/reset":
        del_value(src)
        _respond(src, "‚Ü∫")
        return

    if get_value(src):
        print(f"already processing a request for {src}, ignoring new message")
        return

    set_value(src, True)

    try:
        _handle(body, src)
    except Exception:
        _respond(src, "Error processing your request, please try again later.")
        raise
    finally:
        del_value(src)


def _handle(body: str, to: str) -> None:
    s = subscribe("whatsapp_message", filter=f"data.body.form.From.startsWith('{to}')")

    def get_next() -> str:
        print(f"waiting for next user message from {to}...")
        evt = next_event(s)
        return evt["body"]["form"]["Body"]

    def say(msg: str) -> None:
        return _respond(to, msg)

    resp = ai.interact(body, get_next, say)
    if resp is None:
        say("Could not determine food item. Please try again.")
        return

    food, portion, amount = resp

    total_carbs = amount * food.carbs * (portion.gram_weight / 100.0)

    say(
        f"{amount} x {portion.amount} {portion.modifier} of {food.name} "
        f"({portion.gram_weight}g each) contains approximately "
        f"{total_carbs:.2f}g of carbohydrates."
    )



================================================
FILE: carbcat/Makefile
================================================
UVX=uvx --with-requirements requirements.txt --with pytest

.PHONY: all
all: lint typecheck test format

.PHONY: lint
lint:
	$(UVX) ruff check --config ../pyproject.toml --ignore I001

.PHONY: format
format:
	$(UVX) ruff format --check --config ../pyproject.toml

.PHONY: typecheck
typecheck:
	$(UVX) mypy --follow-untyped-imports  .

.PHONY: test
test:
	$(UVX) pytest -s

.PHONY: data
data:
	./_gendata.sh

.PHONY: deploy
deploy:
	ak deploy --manifest autokitteh.yaml



================================================
FILE: carbcat/requirements.txt
================================================
anthropic==0.71.0
autokitteh
rapidfuzz



================================================
FILE: carbcat/test_ai.py
================================================
"""Tests for ai.py, this is interactive so not run by default."""

import ai
import pytest


@pytest.mark.skip(reason="interactive test, disable skip to play around")
def test_interact():
    # Requires ANTHROPIC_API_KEY defined in env.

    def get_next() -> str:
        return input("> ")

    print(ai.interact("", get_next, print))



================================================
FILE: carbcat/test_data.py
================================================
"""Tests for data module food database loading and search functionality."""

import data


def test_load():
    foods = data._load()
    assert foods
    assert all(foods[i].index == i for i in range(len(foods)))


def test_find_foods_by_name():
    results = data.find_foods_by_name("apple")
    print("\n".join(str(x) for x in results))
    assert results
    assert all(f.name.startswith("Apple") for f, _ in results)



================================================
FILE: categorize_emails/README.md
================================================
title: Email categorization and notification
description: Categorize incoming emails and notify relevant Slack channels
integrations: ["gmail", "chatgpt", "slack"]
categories: ["AI", "Productivity"]
tags: ["activity", "webhook_handling", "long_running", "data_processing", "notifications", "monitoring"]



================================================
FILE: categorize_emails/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh sample project that demonstrates integration with 
# Gmail, ChatGPT, and Slack.

version: v1

project:
  name: categorize_emails

  vars:
    - name: POLL_INTERVAL
      value: 10

  connections:
    - name: my_chatgpt
      integration: chatgpt
    - name: my_gmail
      integration: gmail
    - name: my_slack
      integration: slack

  triggers:
    - name: receive_http_get
      type: webhook
      call: program.py:on_http_get



================================================
FILE: categorize_emails/program.py
================================================
"""A real-life workflow that integrates Gmail, ChatGPT, and Slack:

1. Trigger: Detect a new email in Gmail.
2. Categorize: Use ChatGPT to read and categorize the email
   (e.g., technical work, marketing, sales).
3. Notify: Send a message to the corresponding Slack channel based on the category.
4. Label: Add a label to the email in Gmail.
"""

import base64
from datetime import datetime, UTC
import os
import time

import autokitteh
from autokitteh.google import gmail_client
from autokitteh.openai import openai_client
from autokitteh.slack import slack_client


POLL_INTERVAL = float(os.getenv("POLL_INTERVAL"))
SLACK_CHANNELS = ["demos", "engineering", "ui"]


gmail = gmail_client("my_gmail").users()
slack = slack_client("my_slack")
processed_message_ids = set()
start_time = datetime.now(UTC).timestamp()


def on_http_get(event):
    while True:
        _poll_inbox()
        time.sleep(POLL_INTERVAL)


def _poll_inbox():
    current_message_ids = set()
    results = get_new_inbox_messages()
    current_message_ids.update({msg["id"] for msg in results.get("messages", [])})
    new_message_ids = current_message_ids - processed_message_ids

    for message_id in new_message_ids:
        _process_email(message_id, start_time)

    processed_message_ids.update(new_message_ids)


def _process_email(message_id: str, start_time: datetime):
    message = gmail.messages().get(userId="me", id=message_id).execute()
    email_timestamp = float(message["internalDate"]) / 1000

    if email_timestamp < start_time:
        return

    email_content = _parse_email(message)

    if not email_content:
        print("Email content not found.")
        return

    channel = _categorize_email(email_content)

    if not channel:
        print("Could not categorize email.")
        return

    slack.chat_postMessage(channel=channel, text=email_content)

    # Add label to email
    label_id = _get_label_id(channel) or _create_label(channel)
    if not label_id:
        return

    body = {"addLabelIds": [label_id]}
    gmail.messages().modify(userId="me", id=message_id, body=body).execute()


def _parse_email(message: dict):
    payload = message["payload"]
    parts = payload.get("parts", [])
    for part in parts:
        if part.get("mimeType") == "text/plain":
            email_body = base64.urlsafe_b64decode(part["body"]["data"]).decode("utf-8")
            return email_body
    return None


def _create_label(label_name: str) -> str:
    """Create a new label in the user's gmail account.

    https://developers.google.com/gmail/api/reference/rest/v1/users.labels#Label
    """
    label = {
        "labelListVisibility": "labelShow",
        "messageListVisibility": "show",
        "name": label_name,
    }
    created_label = gmail.labels().create(userId="me", body=label).execute()
    return created_label.get("id", None)


def _get_label_id(label_name: str) -> str:
    labels_response = gmail.labels().list(userId="me").execute()
    labels = labels_response.get("labels", [])
    for label in labels:
        if label["name"] == label_name:
            return label["id"]
    return None


def get_new_inbox_messages():
    query = "in:inbox -in:drafts"
    return gmail.messages().list(userId="me", q=query, maxResults=10).execute()


@autokitteh.activity
def _categorize_email(email_content: str) -> str:
    """Prompt ChatGPT to categorize an email based on its content.

    Returns:
        The name of the Slack channel to send a message to as a string.
        If the channel is not in the provided list, returns None.
    """
    client = openai_client("my_chatgpt")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {
                "role": "user",
                "content": (
                    "Categorize the following email based on its topic and suggest a "
                    "channel to post it in from the provided list. The output should "
                    "be one of the channels in {SLACK_CHANNELS} and nothing else, "
                    "for example: {SLACK_CHANNELS[0]}\n\nEmail content: {email_content}"
                ),
            },
        ],
    )
    channel = response.choices[0].message.content
    return channel if channel in SLACK_CHANNELS else None



================================================
FILE: confluence_to_slack/README.md
================================================
title: Slack notify on Confluence page created
description: When Confluence page is created the user will be notified on Slack
integrations: ["confluence", "slack"]
categories: ["DevOps"]
tags: ["webhook_handling", "notifications", "data_processing", "event_filtering"]



================================================
FILE: confluence_to_slack/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that announces new Confluence pages in Slack.

version: v1

project:
  name: confluence_to_slack

  vars:
    - name: FILTER_LABEL
      value:
    - name: SLACK_CHANNEL_NAME_OR_ID
      value:
    - name: SNIPPET_LENGTH
      value: 150

  connections:
    - name: confluence_connection
      integration: confluence
    - name: slack_connection
      integration: slack

  triggers:
    - name: confluence_page_created
      connection: confluence_connection
      event_type: page_created
      filter: data.page.spaceKey == "CONFLUENCE_SPACE_KEY"
      call: program.py:on_confluence_page_created



================================================
FILE: confluence_to_slack/program.py
================================================
"""A real-life workflow that integrates Confluence and Slack.

Workflow:
    1. Trigger: a new page is created in Confluence
    2. Static filter: the page is in a specific Confluence space
       (specified in the "autokitteh.yaml" manifest file)
    3. Runtime filter: check if the page has a specific label
    4. Notify: send a message to a Slack channel with a snippet of the page
"""

import os

from autokitteh.atlassian import confluence_client
from autokitteh.slack import slack_client


def on_confluence_page_created(event):
    """Workflow's entry-point."""
    confluence = confluence_client("confluence_connection")
    page_id = event.data.page.id

    # Ignore pages without the filter label, if specified.
    page_labels = confluence.get_page_labels(page_id)["results"]
    label_names = [label["name"] for label in page_labels]
    if os.getenv("FILTER_LABEL") not in label_names + [""]:
        print(f"Filter label not found in page: {label_names}")
        return

    # Read the page body.
    res = confluence.get_page_by_id(page_id, expand="body.view")
    html_body = res["body"]["view"]["value"]

    _send_slack_message(event.data.page, html_body)


def _send_slack_message(page, html_body):
    snippet_length = int(os.getenv("SNIPPET_LENGTH"))
    message = f"""
    A new page has been created in the `{page.spaceKey}` space.
    *Title*: {page.title}
    *Snippet*: ```{html_body[:snippet_length]}\n```
    <{page.self}|Link to page>
    """

    slack = slack_client("slack_connection")
    channel = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")
    slack.chat_postMessage(channel=channel, text=message)



================================================
FILE: data_pipeline/README.md
================================================
title: ETL Pipeline From S3 to SQLite
description: Processes GPX files from S3 and inserts them into a SQLite database, creating a data pipeline from cloud to structured data
integrations: ["aws"]
categories: ["DevOps"]
tags:
  [
    "data_pipeline",
    "webhook_handling",
    "activity",
    "data_processing",
    "essential",
  ]



================================================
FILE: data_pipeline/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that parses GPX files when uploaded to
# an S3 bucket, and inserts the data into a SQLite database.

version: v1

project:
  name: pipeline

  vars:
    - name: CREATE_DB
      value: false
    - name: DB_DSN
      secret: true
      value:

  connections:
    - name: aws_conn
      integration: aws

  triggers:
    - name: new_s3_object
      type: webhook
      event_type: post
      call: pipeline.py:on_new_s3_object



================================================
FILE: data_pipeline/bucket_event.json
================================================
{
  "Records": [
    {
      "eventVersion": "2.1",
      "eventSource": "aws:s3",
      "awsRegion": "us-west-2",
      "eventTime": "1970-01-01T00:00:00.000Z",
      "eventName": "ObjectCreated:Put",
      "userIdentity": {
        "principalId": "AIDAJDPLRKLG7UEXAMPLE"
      },
      "requestParameters": {
        "sourceIPAddress": "127.0.0.1"
      },
      "responseElements": {
        "x-amz-request-id": "C3D13FE58DE4C810",
        "x-amz-id-2": "FMyUVURIY8/IgAtTv8xRjskZQpcIZ9KG4V5Wp6S7S/JRWeUWerMUE5JgHvANOjpD"
      },
      "s3": {
        "s3SchemaVersion": "1.0",
        "configurationId": "testConfigRule",
        "bucket": {
          "name": "mybucket",
          "ownerIdentity": {
            "principalId": "A3NL1KOZZKExample"
          },
          "arn": "arn:aws:s3:::mybucket"
        },
        "object": {
          "key": "HappyFace.jpg",
          "size": 1024,
          "eTag": "d41d8cd98f00b204e9800998ecf8427e",
          "versionId": "096fKKXTRTtl3on89fVO.nfljtsv6qko",
          "sequencer": "0055AED6DCD90281E5"
        }
      }
    }
  ]
}



================================================
FILE: data_pipeline/example-sns-event.json
================================================
{
  "Type": "Notification",
  "MessageId": "7db2e638-a87f-5e63-8faa-b8cc6d8b294d",
  "TopicArn": "arn:aws:sns:eu-north-1:975050051518:hikes",
  "Subject": "Amazon S3 Notification",
  "Message": "{\"Records\":[{\"eventVersion\":\"2.1\",\"eventSource\":\"aws:s3\",\"awsRegion\":\"eu-north-1\",\"eventTime\":\"2024-06-25T13:18:43.193Z\",\"eventName\":\"ObjectCreated:Put\",\"userIdentity\":{\"principalId\":\"AWS:AROA6GBMDB67DH6QBEE75:miki\"},\"requestParameters\":{\"sourceIPAddress\":\"62.0.134.40\"},\"responseElements\":{\"x-amz-request-id\":\"396RJHM7A05CBDFX\",\"x-amz-id-2\":\"le/wihJ5KVdyKCdYy91HNlBerbBaTtOIEnUFvnWBIUyFRmy75S4IB3IX9dIHZ033RE+mOOMWzN4OwcVBvbZw3jpVYiT6uDiYvTUaXewfDwk=\"},\"s3\":{\"s3SchemaVersion\":\"1.0\",\"configurationId\":\"new\",\"bucket\":{\"name\":\"ak-miki-hikes\",\"ownerIdentity\":{\"principalId\":\"A3RBVIBHMVQI0T\"},\"arn\":\"arn:aws:s3:::ak-miki-hikes\"},\"object\":{\"key\":\"simple.tar.gz\",\"size\":758,\"eTag\":\"d6805ceca3d89e3f784a5c6ec9a5a483\",\"sequencer\":\"00667AC3B32730E451\"}}}]}",
  "Timestamp": "2024-06-25T13:18:44.098Z",
  "SignatureVersion": "1",
  "Signature": "WJUHeHE5DIvKDRkSIe0mjHBCbt4WdAdR68s72w5GOUI4/G5Me1r1ZI1KWYLYPbMECucH6PKFW2XfgSERlOtpUdZkFkf0gdy3TqVB+Jmrm1x4MjLTrEHGQ27GFApj3MRTLiFOBJFUNo1KE9hNpJuZKcX3g0VjD7+xFc3uYqJT4KHTBY+2rpt3BnKBfIZEswhajFBWZ9Ro1izfXBYl2NYPBvGMC1xd2l6IQqMDfjev0pkIUcq9lAFXbwpCWW+SV5kW4Tut0Pso8EHzu2lGzmbBSlpQXC8ZCHBz07PtuVL5Cy0Uc5KvEd2XepVmu4OtzZwRNye9C1mQKh2WRQLuDEB/5A==",
  "SigningCertURL": "https://sns.eu-north-1.amazonaws.com/SimpleNotificationService-60eadc530605d63b8e62a523676ef735.pem",
  "UnsubscribeURL": "https://sns.eu-north-1.amazonaws.com/?Action=Unsubscribe&SubscriptionArn=arn:aws:sns:eu-north-1:975050051518:hikes:18b9ba01-43f1-4a6f-a5a1-95c76a68f760"
}



================================================
FILE: data_pipeline/Makefile
================================================
# Automation of some common operations for local development

all:
	$(error please pick a target)

init-db:
	sqlite3 hikes.db < schema.sql

deploy:
	ak deploy --manifest ./autokitteh.yaml --file pipeline.py

logs:
	ak session log --prints-only



================================================
FILE: data_pipeline/pipeline.py
================================================
"""Parse GPX files when uploaded to an S3 bucket, and insert into a SQLite database."""

from contextlib import closing
from io import BytesIO
import json
import os
from pathlib import Path
import sqlite3
import xml.etree.ElementTree as Xml

import autokitteh
from autokitteh.aws import boto3_client


DB_DSN = os.getenv("DB_DSN", "")  # Secret
CREATE_DB = os.getenv("CREATE_DB", "no").lower() in {"y", "yes", "true"}

INSERT_SQL = """
INSERT INTO points
	(track_id, n, lat, lng, height)
VALUES
	(:track_id, :n, :lat, :lng, :height)
;
"""


def on_new_s3_object(event):
    if not event.data.body.json:
        print("Unexpected (non-JSON) content type:", event)
        return

    if CREATE_DB:
        create_db(DB_DSN)

    event = event.data.body.json
    print("event:", event)
    if url := event.get("SubscribeURL"):
        print("SNS Subscribe URL:", url)
        return

    # SNS events encode the `Message` field in JSON
    s3_event = json.loads(event.get("Message", {}))
    for record in s3_event.get("Records", []):
        bucket = record["s3"]["bucket"]["name"]
        key = record["s3"]["object"]["key"]
        print(f"getting {bucket}/{key}")
        data = get_s3_object(bucket, key)
        records = parse_gpx(key, data)
        count = insert_records(DB_DSN, records)
        print(f"inserted {count} records")


@autokitteh.activity
def get_s3_object(bucket, key):
    response = boto3_client("aws_conn", "s3").get_object(Bucket=bucket, Key=key)
    return response["Body"].read()


@autokitteh.activity
def insert_records(db_dsn, records):
    with closing(sqlite3.connect(db_dsn)) as conn:
        cur = conn.executemany(INSERT_SQL, records)
        conn.commit()
    return cur.rowcount


@autokitteh.activity
def create_db(db_dsn):
    code_dir = Path(__file__).absolute().parent
    schema_file = code_dir / "schema.sql"
    schema_sql = schema_file.read_text()

    with closing(sqlite3.connect(db_dsn)) as conn, conn:
        conn.executescript(schema_sql)


trkpt_tag = "{http://www.topografix.com/GPX/1/1}trkpt"


@autokitteh.activity
def parse_gpx(track_id, data):
    io = BytesIO(data)
    root = Xml.parse(io).getroot()
    records = []

    for i, elem in enumerate(root.findall(".//" + trkpt_tag)):
        records.append(
            {
                "track_id": track_id,
                "n": i,
                "lat": float(elem.get("lat", "0")),
                "lng": float(elem.get("lon", "0")),
                "height": float(elem.findtext(".//") or "0"),
            }
        )

    return records



================================================
FILE: data_pipeline/schema.sql
================================================
-- Schema for the points table

CREATE TABLE IF NOT EXISTS points (
	track_id VARCHAR(255) NOT NULL,
	n INTEGER NOT NULL,
	lat REAL NOT NULL,
	lng REAL NOT NULL,
	height REAL NOT NULL
);

CREATE INDEX IF NOT EXISTS points_track_id_idx ON points(track_id);




================================================
FILE: data_pipeline/subscription-event.json
================================================
{
  "Type": "SubscriptionConfirmation",
  "MessageId": "XXXXXXXX-1ee3-4de3-9c69-XXXXXXXXXXXX",
  "Token": "SECRET_TOKEN",
  "TopicArn": "arn:aws:sns:us-west-2:XXXXXXXXXXXX:ses-test",
  "Message": "You have chosen to subscribe to the topic arn:aws:sns:us-west-2:XXXXXXXXXXXX:ses-test. To confirm the subscription, visit the SubscribeURL included in this message.",
  "SubscribeURL": "https://sns.us-west-2.amazonaws.com/?Action=ConfirmSubscription&TopicArn=arn:aws:sns:us-west-2:XXXXXXXXXXXX:ses-test&Token=SECRET_TOKEN",
  "Timestamp": "2018-11-21T19:48:08.170Z",
  "SignatureVersion": "1",
  "Signature": "SECRET",
  "SigningCertURL": "https://sns.us-west-2.amazonaws.com/SimpleNotificationService-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.pem"
}



================================================
FILE: devops/github_issue_alert/README.md
================================================
title: GitHub issue alert
description: Send GitHub issue comments to Slack
integrations: ["github", "slack"]
categories: ["DevOps"]
tags: ["webhook_handling", "notifications", "data_processing"]



================================================
FILE: devops/github_issue_alert/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that monitors comments on GitHub issues.

version: v1

project:
  name: github_issue_alert

  vars:
    - name: SLACK_CHANNEL_NAME_OR_ID
      value: github-issues

  connections:
    - name: slack_conn
      integration: slack
    - name: github_conn
      integration: github

  triggers:
    - name: on_issue_comment
      event_type: issue_comment
      connection: github_conn
      call: program.py:on_issue_comment
    - name: on_issue_event
      event_type: issues
      connection: github_conn
      call: program.py:on_issue_event



================================================
FILE: devops/github_issue_alert/program.py
================================================
"""Monitors GitHub issue creation and comment activity."""

import os

from autokitteh.slack import slack_client


SLACK_CHANNEL = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")

slack = slack_client("slack_conn")


def on_issue_comment(event):
    """Processes a GitHub issue comment event and sends a message to Slack.

    Supported actions: created, edited, deleted

    For more details on the payload structure, visit:
    https://docs.github.com/en/webhooks/webhook-events-and-payloads#issue_comment
    """
    comment_url = event.data.comment.html_url
    comment_body = event.data.comment.body
    comment_action = event.data.action
    comment_author = event.data.comment.user.login or "Unknown user"
    issue_title = event.data.issue.title

    text = (
        f"{comment_author} {comment_action} a comment on issue '{issue_title}': "
        f"{comment_body}\n. "
    )
    text += f"View the comment here: {comment_url}."

    slack.chat_postMessage(channel=SLACK_CHANNEL, text=text)


def on_issue_event(event):
    """Processes a GitHub issue event and sends a message to Slack.

    Supported actions: opened, reopened, closed

    For more details on the payload structure, visit:
    https://docs.github.com/en/webhooks/webhook-events-and-payloads#issues
    """
    issue_title = event.data.issue.title
    issue_author = event.data.issue.user.login
    issue_action = event.data.action
    issue_url = event.data.issue.html_url

    text = f"{issue_author} {issue_action} an issue: '{issue_title}', "
    text += f"View the issue here: {issue_url}."

    slack.chat_postMessage(channel=SLACK_CHANNEL, text=text)



================================================
FILE: devops/github_workflows/README.md
================================================
title: GitHub workflow orchestration
description: Orchestrate GitHub workflows using advanced scenarios across multiple repositories
integrations: ["github"]
categories: ["DevOps"]
tags: ["webhook_handling", "parallel_processing", "monitoring", "notifications"]



================================================
FILE: devops/github_workflows/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that orchestrates GitHub workflows using
# advanced scenarios across multiple repositories.

version: v1

project:
  name: github_actions

  vars:
    - name: REPO_A
      value: owner/repo-1
    - name: REPO_B
      value: owner/repo-2
    - name: REPO_C
      value: owner/repo-3

    - name: WORKFLOW_A
      value: .github/workflows/workflow-1.yml
    - name: WORKFLOW_B
      value: .github/workflows/workflow-2.yml
    - name: WORKFLOW_C
      value: .github/workflows/workflow-3.yml

  connections:
    - name: github_conn
      integration: github

  triggers:
    - name: cross_repo
      type: webhook
      event_type: get
      call: program.py:cross_repo

    - name: fan_out
      type: webhook
      event_type: get
      call: program.py:fan_out

    - name: or_reduction
      type: webhook
      event_type: get
      call: program.py:or_reduction

    - name: fan_in
      type: webhook
      event_type: get
      call: program.py:fan_in

    - name: long_sequence
      type: webhook
      event_type: get
      call: program.py:long_sequence



================================================
FILE: devops/github_workflows/program.py
================================================
"""Orchestrate GitHub workflows using advanced scenarios across repositories.

See the configuration and deployment instructions in the README.md file.
"""

import os

import autokitteh
from autokitteh.github import github_client
import github


# Indexes in the following lists, used throughout this module.
A = 0
B = 1
C = 2

# GitHub repositories (e.g. "autokitteh/kittehub").
REPOS = [
    os.getenv("REPO_A", ""),
    os.getenv("REPO_B", ""),
    os.getenv("REPO_C", ""),
]

# GitHub workflow file paths (e.g. ".github/workflows/ci.yml").
WORKFLOWS = [
    os.getenv("WORKFLOW_A", ""),
    os.getenv("WORKFLOW_B", ""),
    os.getenv("WORKFLOW_C", ""),
]

gh = github_client("github_conn")


def dispatch_workflow_manually(event: dict[str, str]) -> None:
    """Dispatch a workflow manually, for testing purposes.

    You may specify an optional index (default = 0 = workflow A).
    """
    _dispatch_workflow(int(event.get("index", A)))


def cross_repo(_) -> None:
    """Cross-repo demo (A --> B)."""
    sub = _subscribe_to_events(A)
    print("Waiting until workflow A completes")
    autokitteh.next_event(sub)
    print("Workflow A completed")
    _dispatch_workflow(B)


def fan_out(_) -> None:
    """Fan-out demo (A --> B and C in parallel)."""
    sub = _subscribe_to_events(A)
    print("Waiting until workflow A completes")
    autokitteh.next_event(sub)
    print("Workflow A completed")
    _dispatch_workflow(B)
    _dispatch_workflow(C)


def or_reduction(_) -> None:
    """Any-to-one reduction demo (first of A or B --> C)."""
    subs = [_subscribe_to_events(A), _subscribe_to_events(B)]
    print("Waiting until either workflow A or B complete (whichever comes first)")
    data = autokitteh.next_event(subs)
    print(f"Workflow completed: {data.repository.name}/{data.workflow.path}")
    _dispatch_workflow(C)


def fan_in(_) -> None:
    """All-to-one fan-in demo (A and B --> C)."""
    subs = [_subscribe_to_events(A), _subscribe_to_events(B)]

    # Wait until both workflows A and B complete.
    completed_workflows = set()
    while len(completed_workflows) < 2:
        data = autokitteh.next_event(subs)
        path = f"{data.repository.name}/{data.workflow.path}"
        print(f"Workflow completed: {path}")
        completed_workflows.add(path)

    _dispatch_workflow(C)


def long_sequence(_) -> None:
    """Long sequence demo (A --> B --> C --> A --> B --> C).

    Note: GitHub cannot chain more than 4 workflows (when using `workflow_run` events),
    so this AutoKitteh demo is useful even within a single repository. See details here:
    https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#workflow_run
    """
    sub = _subscribe_to_events(A)
    print("Waiting until workflow A completes")
    autokitteh.next_event(sub)
    autokitteh.unsubscribe(sub)
    print("Workflow A completed")

    for wf in [B, C, A, B, C]:
        sub = _subscribe_to_events(wf)
        _dispatch_workflow(wf)
        print(f"Waiting until workflow {_index2char(wf)(wf)} completes")
        autokitteh.next_event(sub)
        autokitteh.unsubscribe(sub)
        print(f"Workflow {_index2char(wf)(wf)} completed")


def _subscribe_to_events(wf: int, conclusion: str = "success") -> str:
    """Intercept specific GitHub "workflow_run" events.

    API documentation:
    - https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#workflow_run
    - https://docs.github.com/en/webhooks/webhook-events-and-payloads#workflow_run

    Args:
        wf: Workflow index (0-2).
        conclusion: Workflow completion result: "action_required",
            "cancelled", "failure", "neutral", "skipped", "stale",
            "success", "timed_out", "startup_failure", or None.

    Returns:
        AutoKitteh event subscription UUID.
    """
    conditions = [
        "event_type == 'workflow_run'",
        "data.action == 'completed'",
        f"data.workflow_run.conclusion == '{conclusion}'",
        f"data.repository.full_name == '{REPOS[wf]}'",
        f"data.workflow.path == '{WORKFLOWS[wf]}'",
    ]
    return autokitteh.subscribe("github_conn", " && ".join(conditions))


def _dispatch_workflow(wf: int, ref: str = "main", inputs: dict = None) -> None:
    """Start a specific GitHub workflow.

    API documentation:
    - https://docs.github.com/en/rest/actions/workflows#create-a-workflow-dispatch-event
    - https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#workflow_dispatch

    Args:
        wf: Workflow index (0-2).
        ref: Git reference, should be the default branch (e.g. "main").
        inputs: Keys and values configured in the workflow file. The maximum
            number of properties is 10. Any default properties configured in
            the workflow file will be used when inputs are omitted.
    """
    repo = gh.get_repo(REPOS[wf])
    workflow = _get_workflow(repo, WORKFLOWS[wf])
    if workflow.create_dispatch(ref, inputs or {}):
        print(f"Workflow {_index2char(wf)(wf)} dispatched")
    else:
        print("Failed to create a 'workflow_dispatch' event")


def _get_workflow(repo: github.Repository, path: str) -> github.Workflow:
    """Return the GitHub workflow instance with the given file path."""
    for workflow in repo.get_workflows():
        if workflow.path == path:
            return workflow

    raise RuntimeError(f"Workflow file not found: {path}")


def _index2char(index: int) -> str:
    """Convert an index (0-2) to a workflow identifier (A-C)."""
    return chr(65 + index)



================================================
FILE: devops/postgresql/README.md
================================================
title: PostgreSQL connection
description: Project showing how to connect to PostgreSQL database
integrations: []
categories: ["DevOps"]
tags: ["database"]



================================================
FILE: devops/postgresql/autokitteh.yaml
================================================
# This is an example configuration file for a PostgreSQL sample project using Autokitteh.
# It defines the project name, variables for database connection, and a trigger for executing a query
# via a webhook.

version: v1

project:
  name: postgresql_sample

  vars:
    - name: DSN
      value: "postgresql://your_username:your_password@localhost:5432/your_database_name"

  triggers:
    - name: database_query
      type: webhook
      call: program.py:on_trigger



================================================
FILE: devops/postgresql/program.py
================================================
"""PostgreSQL connection example for AutoKitteh."""

import os

import autokitteh
import psycopg2


DSN = os.getenv("DSN")


# Required: database operations only work in activities (for workflow reliability).
@autokitteh.activity
def on_trigger(_):
    conn = psycopg2.connect(DSN)

    try:
        with conn.cursor() as cur:
            # Your database operations here.
            cur.execute("SELECT * FROM users")
            results = cur.fetchall()
            print(results)
    finally:
        conn.close()



================================================
FILE: devops/postgresql/requirements.txt
================================================
psycopg2



================================================
FILE: devops/purrr/README.md
================================================
title: Pull Request Review Reminder (Purrr)
description: Streamline code reviews and cut down turnaround time to merge pull requests
integrations: ["github", "googlesheets", "slack"]
categories: ["DevOps"]
tags: ["event_loops", "long_running", "subscribe", "unsubscribe", "next_event", "event_filtering", "essential"]



================================================
FILE: devops/purrr/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of the AutoKitteh project "Pull Request Review Reminder" (Purrr).
# Purrr integrates GitHub and Slack seamlessly, to streamline code
# reviews and cut down the turnaround time to merge pull requests.

version: v1

project:
  name: purrr

  vars:
    # Temporary (easy to debug, but not scalable) replacement for Redis/Valkey.
    - name: DATA_SHEET_URL
      value: TODO
    # PR channel names in Slack: "<prefix>_<number>_<title>".
    - name: SLACK_CHANNEL_PREFIX
      value: _pr
    # Visibility of PR channels in Slack: "public" (default) or "private".
    - name: SLACK_CHANNEL_VISIBILITY
      value: public
    # Create this channel / replace with your own / set to "" to disable it.
    - name: SLACK_DEBUG_CHANNEL
      value: purrr-debug
    # TTL for GitHub/Slack mappings = 30 days (to forget stale PRs).
    - name: STATE_TTL
      value: 720h

  connections:
    - name: github_conn
      integration: github
    - name: sheets_conn
      integration: googlesheets
    - name: slack_conn
      integration: slack

  triggers:
    # - name: github_issue_comment
    #   connection: github_conn
    #   event_type: issue_comment
    #   call: github_issue_comment.py:on_github_issue_comment
    - name: github_pull_request
      connection: github_conn
      event_type: pull_request
      call: github_pr.py:on_github_pull_request
    # - name: github_pull_request_review
    #   connection: github_conn
    #   event_type: pull_request_review
    #   call: github_pr_review.py:on_github_pull_request_review
    # - name: github_pull_request_review_comment
    #   connection: github_conn
    #   event_type: pull_request_review_comment
    #   call: github_review_comment.py:on_github_pull_request_review_comment
    # - name: github_pull_request_review_thread
    #   connection: github_conn
    #   event_type: pull_request_review_thread
    #   call: github_thread.py:on_github_pull_request_review_thread

    # - name: slack_message
    #   connection: slack_conn
    #   event_type: message
    #   call: slack_message.py:on_slack_message
    # - name: slack_reaction_added
    #   connection: slack_conn
    #   event_type: reaction_added
    #   call: slack_reaction.py:on_slack_reaction_added
    - name: slack_slash_command
      connection: slack_conn
      event_type: slash_command
      call: slack_cmd.py:on_slack_slash_command



================================================
FILE: devops/purrr/data_helper.py
================================================
"""Thin wrapper over the Google Sheets API for data management and caching.

Redis/Valkey would be a better choice, but are not available at this time.
"""

from datetime import datetime


# Some read functions wait up to 5 seconds for data to exist,
# because GitHub events are asynchronous. For example: when a
# PR review is submitted with file/line comments, some "child"
# comment events may arrive before the "parent" review event.
_GET_TIMEOUT = 5

# Cache user lookup results for a day, to reduce the amount
# of API calls (especially to Slack), to avoid throttling.
_USER_CACHE_TTL = "24h"


def cache_github_reference(slack_user_id: str, github_ref: str) -> None:
    """Map a Slack user ID to a GitHub user reference/name, for a day.

    This helps reduce the amount of lookup API calls, to avoid throttling.
    """
    return  # TODO: Implement this function.


def cached_github_reference(slack_user_id: str) -> str:
    """Return the GitHub user reference/name mapped to a Slack user ID, or "".

    This helps reduce the amount of lookup API calls, to avoid throttling.
    """
    return ""  # TODO: Implement this function.


def cache_slack_user_id(github_username: str, slack_user_id: str) -> None:
    """Map a GitHub username to a Slack user ID, for a day.

    This helps reduce the amount of Slack lookup API calls, to avoid throttling.
    """
    return  # TODO: Implement this function.


def cached_slack_user_id(github_username: str) -> str:
    """Return the Slack user ID mapped to a GitHub user, or "" if not cached yet.

    This helps reduce the amount of Slack lookup API calls, to avoid throttling.
    """
    return ""  # TODO: Implement this function.


def lookup_github_link_details(github_link: str) -> str | None:
    """Return the Slack message thread timestamp mapped to a GitHub PR link, or None.

    This function waits up to a few seconds for the mapping to exist, because
    GitHub events are asynchronous. For example: when a PR review is submitted
    with file/line comments, some "child" comment events may arrive before the
    "parent" review event.
    """
    if not github_link:
        return None

    return None  # TODO: Implement this function (with "wait=True").


def slack_opt_in(user_id: str) -> None:
    """Delete the opt-out timestamp for a Slack user."""
    return  # TODO: Implement this function.


def slack_opt_out(user_id: str) -> None:
    """Return the opt-out timestamp for a Slack user, or None if they're opted-in."""
    return  # TODO: Implement this function.


def slack_opted_out(user_id: str) -> datetime | None:
    """Return the opt-out timestamp for a Slack user, or None if they're opted-in."""
    return None  # TODO: Implement this function.



================================================
FILE: devops/purrr/debug.py
================================================
"""Simple utility functions for debugging and reporting errors in Slack.

Decoupled from the "slack_helper" module, to avoid circular imports.
"""

import os
import re
import traceback

from autokitteh.slack import slack_client
from slack_sdk.errors import SlackApiError


_DEBUG_CHANNEL = os.getenv("SLACK_DEBUG_CHANNEL")

slack = slack_client("slack_conn")


def log(msg: str) -> None:
    """Post a debug message to a predefined Slack channel, if defined.

    Also post a filtered traceback, as replies to that message.
    """
    if not _DEBUG_CHANNEL or not msg:
        return

    print("DEBUG:", msg)
    try:
        resp = slack.chat_postMessage(channel=_DEBUG_CHANNEL, text=msg)
        ts = resp["ts"]

        for msg in _stack_messages():
            slack.chat_postMessage(channel=_DEBUG_CHANNEL, thread_ts=ts, text=msg)

    except SlackApiError as e:
        print(f"DEBUG ERROR: {e}")


def _stack_messages() -> list[str]:
    msgs = []
    for file, line, func, text in traceback.extract_stack():
        # Log only frame summaries relating to this project, up to this function.
        if "/ak-user-" not in file:
            continue

        # Display shorter and cleaner paths.
        file = re.sub(r"^.+/ak-user-.+?/", "", file)
        msgs.append(f"```File: {file}, line {line}\nFunc: {func}\n{text}```")

    return msgs[:-2]  # Skip the last 2 frames (i.e. this module).



================================================
FILE: devops/purrr/github_helper.py
================================================
"""Thin layer of logic on top of the GitHub API."""

import os

from autokitteh.github import github_client


ORG_NAME = os.getenv("github_conn__target_name", "")

shared_client = github_client("github_conn")



================================================
FILE: devops/purrr/github_pr.py
================================================
"""Handler for GitHub "pull_request" events."""

import autokitteh
from autokitteh.slack import normalize_channel_name

import data_helper
import slack_channel
import slack_helper
import text_utils
import users


def on_github_pull_request(event) -> None:
    """Entry-point for AutoKitteh sessions triggered by GitHub "pull_request" events.

    Args:
        event: GitHub event data.
    """
    _parse_github_pr_event(event.data)


def _parse_github_pr_event(data) -> None:
    """Parse a GitHub "pull_request" event and dispatch the appropriate handler.

    About GitHub pull requests and these events:
    - https://docs.github.com/webhooks/webhook-events-and-payloads#pull_request
    - https://docs.github.com/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests

    Args:
        data: GitHub event data.
    """
    match data.action:
        # A new pull request was created.
        case "opened":
            _on_pr_opened(data.action, data.pull_request, data.sender)
        # A pull request was closed.
        case "closed":
            _on_pr_closed(data.action, data.pull_request, data.sender)
        # A previously closed pull request was reopened.
        case "reopened":
            _on_pr_reopened(data.action, data.pull_request, data.sender)

        # A pull request was converted to a draft.
        case "converted_to_draft":
            _on_pr_converted_to_draft(data.action, data.pull_request, data.sender)
        # A draft pull request was marked as ready for review.
        case "ready_for_review":
            _on_pr_ready_for_review(data.action, data.pull_request, data.sender)

        # Review by a person or team was requested for a pull request.
        case "review_requested":
            _on_pr_review_requested(data)
        # A request for review by a person or team was removed from a pull request.
        case "review_request_removed":
            _on_pr_review_request_removed(data)

        # A pull request was assigned to a user.
        case "assigned":
            _on_pr_assigned(data)
        # A user was unassigned from a pull request.
        case "unassigned":
            _on_pr_unassigned(data)

        # The title or body of a pull request was edited,
        # or the base branch was changed.
        case "edited":
            _on_pr_edited(data.action, data.pull_request, data.changes, data.sender)
        # A pull request's head branch was updated.
        case "synchronize":
            _on_pr_synchronized(data.action, data.pull_request, data.sender)

        # TODO: locked, unlocked

        # Ignored actions:
        # - auto_merge_enabled, auto_merge_disabled
        # - enqueued, dequeued
        # - labeled, unlabeled
        # - milestoned, demilestoned


def _on_pr_opened(action: str, pr, sender) -> None:
    """A new pull request was created (or reopened, or marked as ready for review).

    See also the functions "_on_pr_reopened" and "_on_pr_ready_for_review".

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    # Ignore drafts until they're marked as ready for review.
    if pr.draft:
        return

    channel = slack_channel.initialize_for_github_pr(action, pr, sender)

    # Intercept relevant GitHub and Slack events.
    filter = f"event_type == 'pull_request' && data.number == {pr.number}"
    subs = [autokitteh.subscribe("github_conn", filter=filter)]

    filter = "(event_type == 'message' || event_type.startswith('member_'))"
    filter += f" && data.event.channel == {channel}"
    subs.append(autokitteh.subscribe("slack_conn", filter=filter))

    filter = f"event_type == 'reaction_added' && data.event.item.channel == {channel}"
    subs.append(autokitteh.subscribe("slack_conn", filter=filter))

    # Keep this AutoKitteh session running to handle them until the PR is closed.
    while True:
        data = autokitteh.next_event(subs)

        # GitHub PR event.
        if hasattr(data, "action"):
            print("Received GitHub PR event:", data.action)
            if data.action in ("closed", "converted_to_draft"):
                for sub in subs:
                    autokitteh.unsubscribe(sub)
                break

        # Slack event.
        else:
            print("Received Slack event:", data.event.type)


def _on_pr_closed(action: str, pr, sender) -> None:
    """A pull request (possibly a draft) was closed.

    If "merged" is false in the webhook payload, the pull request was
    closed with unmerged commits. If "merged" is true in the webhook
    payload, the pull request was merged.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    # Ignore drafts - they don't have an active Slack channel anyway.
    if pr.draft:
        return

    slack_channel.archive(action, pr, sender)


def _on_pr_reopened(action: str, pr, sender) -> None:
    """A previously closed pull request (possibly a draft) was reopened.

    Slack bug alert from https://api.slack.com/methods/conversations.unarchive:
    bot tokens ("xoxb-...") cannot currently be used to unarchive conversations.
    For now, please use a user token ("xoxp-...") to unarchive the conversation
    rather than a bot token.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    # Ignore drafts - they don't have an active Slack channel anyway.
    if pr.draft:
        return

    # Workaround for the Slack unarchive bug: treat this as a new PR.
    _on_pr_opened(action, pr, sender)


def _on_pr_converted_to_draft(action: str, pr, sender) -> None:
    """A pull request was converted to a draft.

    For more information, see "Changing the stage of a pull request":
    https://docs.github.com/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-stage-of-a-pull-request

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    slack_channel.archive(action, pr, sender)


def _on_pr_ready_for_review(action: str, pr, sender) -> None:
    """A draft pull request was marked as ready for review.

    For more information, see "Changing the stage of a pull request":
    https://docs.github.com/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-stage-of-a-pull-request

    Slack bug alert from https://api.slack.com/methods/conversations.unarchive:
    bot tokens ("xoxb-...") cannot currently be used to unarchive conversations.
    For now, please use a user token ("xoxp-...") to unarchive the conversation
    rather than a bot token.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    # Workaround for the Slack unarchive bug: treat this as a new PR.
    _on_pr_opened(action, pr, sender)


def _on_pr_review_requested(data) -> None:
    """Review by a person or team was requested for a pull request.

    For more information, see "Requesting a pull request review":
    https://docs.github.com/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/requesting-a-pull-request-review

    Args:
        data: GitHub event data.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(data.pull_request, data.action)
    if not channel:
        return

    if data.requested_reviewer:
        reviewer = data.requested_reviewer
        _on_pr_review_requested_person(reviewer, data.sender, channel, "reviewer")
    if data.requested_team:
        _on_pr_review_requested_team(data.requested_team, data.sender, channel)


def _on_pr_review_requested_person(reviewer, sender, channel: str, role: str) -> None:
    """Review by a person was requested for a pull request.

    Args:
        reviewer: GitHub user requested as a reviewer.
        sender: GitHub user who triggered the event.
        channel: PR's Slack channel ID.
        role: "reviewer" or "assignee".
    """
    slack_reviewer = users.format_github_user_for_slack(reviewer)
    self_added = reviewer.login == sender.login
    person = "themselves" if self_added else slack_reviewer
    article = "a" if role == "reviewer" else "an"  # "assignee"

    msg = f"{{}} added {person} as {article} {role}"
    slack_helper.mention_in_message(channel, sender, msg)

    if not slack_reviewer.startswith("<@"):
        return  # Not a real Slack user ID.

    # Remove the "<@" and ">" affixes from the Slack user mention to get the user ID.
    slack_reviewer = slack_reviewer[2:-1]

    if data_helper.slack_opted_out(slack_reviewer):
        return

    slack_channel.add_users(channel, [reviewer.login])

    if self_added:
        return

    # DM the reviewer a reference to the Slack channel.
    msg = f"{{}} added you as {article} {role} to a PR: <#{channel}>"
    slack_helper.mention_in_message(slack_reviewer, sender, msg)


def _on_pr_review_requested_team(team, sender, channel: str) -> None:
    """Review by a team was requested for a pull request.

    Args:
        team: GitHub team requested as a reviewer.
        sender: GitHub user who triggered the event.
        channel: PR's Slack channel ID.
    """
    msg = f"{{}} added the <{team.html_url}|{team.name}> team as a reviewer"
    slack_helper.mention_in_message(channel, sender, msg)


def _on_pr_review_request_removed(data) -> None:
    """A request for review by a person or team was removed from a pull request.

    Args:
        data: GitHub event data.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(data.pull_request, data.action)
    if not channel:
        return

    if data.requested_reviewer:
        reviewer = data.requested_reviewer
        _on_pr_review_request_removed_person(reviewer, data.sender, channel, "reviewer")
    if data.requested_team:
        _on_pr_review_request_removed_team(data.requested_team, data.sender, channel)


def _on_pr_review_request_removed_person(
    reviewer, sender, channel: str, role: str
) -> None:
    """A request for review by a person was removed from a pull request.

    Args:
        reviewer: GitHub user requested as a reviewer.
        sender: GitHub user who triggered the event.
        channel: PR's Slack channel ID.
        role: "reviewer" or "assignee".
    """
    slack_reviewer = users.format_github_user_for_slack(reviewer)
    self_added = reviewer.login == sender.login
    person = "themselves" if self_added else slack_reviewer
    article = "a" if role == "reviewer" else "an"  # "assignee"

    msg = f"{{}} removed {person} as {article} {role}"
    slack_helper.mention_in_message(channel, sender, msg)

    if not slack_reviewer.startswith("<@"):
        return  # Not a real Slack user ID.

    # Remove the "<@" and ">" affixes from the Slack user mention to get the user ID.
    slack_reviewer = slack_reviewer[2:-1]

    if data_helper.slack_opted_out(slack_reviewer):
        return

    # TODO: Remove the reviewer from the Slack channel.

    # TODO: Remove the review request DM.


def _on_pr_review_request_removed_team(team, sender, channel: str) -> None:
    """A request for review by a team was removed from a pull request.

    Args:
        team: GitHub team that was requested as a reviewer.
        sender: GitHub user who triggered the event.
        channel: PR's Slack channel ID.
    """
    msg = f"removed the <{team.html_url}|{team.name}> team as a reviewer"
    slack_helper.mention_in_message(channel, sender, "{} " + msg)


def _on_pr_assigned(data) -> None:
    """A pull request was assigned to a user.

    Args:
        data: GitHub event data.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(data.pull_request, data.action)
    if not channel:
        return

    _on_pr_review_requested_person(data.assignee, data.sender, channel, "assignee")


def _on_pr_unassigned(data) -> None:
    """A user was unassigned from a pull request.

    Args:
        data: GitHub event data.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(data.pull_request, data.action)
    if not channel:
        return

    assignee, sender = data.assignee, data.sender
    _on_pr_review_request_removed_person(assignee, sender, channel, "assignee")


def _on_pr_edited(action: str, pr, changes, sender) -> None:
    """The title or body of a pull request was edited, or the base branch was changed.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        changes: Changed title/body in the PR.
        sender: GitHub user who triggered the event.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(pr, action)
    if not channel:
        return

    # PR base branch was changed.
    if "base" in changes:
        msg = "{} changed the base branch from "
        msg += "`{changes.base.ref}` to `{pr.base.ref}`"
        slack_helper.mention_in_message(channel, sender, msg)

    # PR description was changed.
    if "body" in changes:
        if pr.body:
            msg = "{} updated the PR description:\n\n"
            msg += text_utils.github_to_slack(pr.body, pr.html_url)
        else:
            msg = "{} deleted the PR description"

        slack_helper.mention_in_message(channel, sender, msg)

    # PR title was changed.
    if "title" in changes:
        msg = f"{{}} edited the PR title to: `{pr.title}`"
        slack_helper.mention_in_message(channel, sender, msg)

        name = f"{pr.number}_{normalize_channel_name(pr.title)}"
        slack_helper.rename_channel(channel, name)


def _on_pr_synchronized(action: str, pr, sender) -> None:
    """A pull request's head branch was updated.

    For example, the head branch was updated from the base
    branch or new commits were pushed to the head branch.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    # Don't do anything if there isn't an active Slack channel anyway.
    channel = _lookup_channel(pr, action)
    if not channel:
        return

    msg = "{} updated the head branch (see the [PR commits]({pr.url}/commits))"
    slack_helper.mention_in_message(channel, sender, msg)


def _lookup_channel(pr, action: str) -> str | None:
    """Return the ID of a Slack channel that represents a GitHub PR.

    Return None the PR is inactive or the channel ID is not found.
    """
    if pr.draft or pr.state != "open":
        return None

    return slack_helper.lookup_channel(pr.html_url, action)



================================================
FILE: devops/purrr/github_pr_test.py
================================================
"""Unit tests for the "github_pr" module."""

import collections

from autokitteh import github, slack
import pytest


@pytest.fixture(autouse=True)
def setup_mock_github_and_slack_clients(mocker):
    mocker.patch.object(github, "github_client", autospec=True)
    mocker.patch.object(slack, "slack_client", autospec=True)


@pytest.fixture
def mock_slack_user_id(mocker):
    import users

    return mocker.patch.object(users, "github_username_to_slack_user_id", autospec=True)


FakeGithubUser = collections.namedtuple("FakeGithubUser", ["login"])


class TestOnPRReviewRequestedPerson:
    """Unit tests for the "_on_pr_review_requested_person" function."""

    def test_reviewer(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = [
            "reviewer",  # _on_pr_review_requested_person: message to channel
            "sender",  # mention_in_reply: mention in message to channel
            "reviewer",  # add_users: invite reviewer to channel
            "sender",  # mention_in_reply: mention in DM to reviewer
        ]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_requested_person(
            FakeGithubUser("reviewer"), FakeGithubUser("sender"), "C987", "reviewer"
        )

        slack_helper.shared_client.chat_postMessage.assert_any_call(
            channel="C987",
            text="<@sender> added <@reviewer> as a reviewer",
            thread_ts=None,
        )
        slack_helper.shared_client.chat_postMessage.assert_called_with(
            channel="reviewer",
            text="<@sender> added you as a reviewer to a PR: <#C987>",
            thread_ts=None,
        )

    def test_self_reviewer(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = ["U123", "U123", "U123"]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_requested_person(
            FakeGithubUser("sender"), FakeGithubUser("sender"), "C987", "reviewer"
        )

        slack_helper.shared_client.chat_postMessage.assert_called_with(
            channel="C987",
            text="<@U123> added themselves as a reviewer",
            thread_ts=None,
        )

    def test_assignee(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = [
            "assignee",  # _on_pr_review_requested_person: message to channel
            "sender",  # mention_in_reply: mention in message to channel
            "assignee",  # add_users: invite reviewer to channel
            "sender",  # mention_in_reply: mention in DM to reviewer
        ]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_requested_person(
            FakeGithubUser("assignee"), FakeGithubUser("sender"), "C987", "assignee"
        )

        slack_helper.shared_client.chat_postMessage.assert_any_call(
            channel="C987",
            text="<@sender> added <@assignee> as an assignee",
            thread_ts=None,
        )
        slack_helper.shared_client.chat_postMessage.assert_called_with(
            channel="assignee",
            text="<@sender> added you as an assignee to a PR: <#C987>",
            thread_ts=None,
        )

    def test_self_assignee(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = ["U123", "U123", "U123"]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_requested_person(
            FakeGithubUser("sender"), FakeGithubUser("sender"), "C987", "assignee"
        )

        slack_helper.shared_client.chat_postMessage.assert_called_once_with(
            channel="C987",
            text="<@U123> added themselves as an assignee",
            thread_ts=None,
        )


class TestOnPRReviewRequestRemovedPerson:
    """Unit tests for the "_on_pr_review_request_removed_person" function."""

    def test_reviewer(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = [
            "reviewer",  # _on_pr_review_requested_person: message to channel
            "sender",  # mention_in_reply: mention in message to channel
        ]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_request_removed_person(
            FakeGithubUser("reviewer"), FakeGithubUser("sender"), "C987", "reviewer"
        )

        slack_helper.shared_client.chat_postMessage.assert_any_call(
            channel="C987",
            text="<@sender> removed <@reviewer> as a reviewer",
            thread_ts=None,
        )

    def test_self_reviewer(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = ["U123", "U123"]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_request_removed_person(
            FakeGithubUser("sender"), FakeGithubUser("sender"), "C987", "reviewer"
        )

        slack_helper.shared_client.chat_postMessage.assert_called_with(
            channel="C987",
            text="<@U123> removed themselves as a reviewer",
            thread_ts=None,
        )

    def test_assignee(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = [
            "assignee",  # _on_pr_review_requested_person: message to channel
            "sender",  # mention_in_reply: mention in message to channel
        ]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_request_removed_person(
            FakeGithubUser("assignee"), FakeGithubUser("sender"), "C987", "assignee"
        )

        slack_helper.shared_client.chat_postMessage.assert_any_call(
            channel="C987",
            text="<@sender> removed <@assignee> as an assignee",
            thread_ts=None,
        )

    def test_self_assignee(self, mock_slack_user_id):
        import github_pr
        import slack_helper

        mock_slack_user_id.side_effect = ["U123", "U123"]
        slack_helper.shared_client.chat_postMessage.reset_mock()

        github_pr._on_pr_review_request_removed_person(
            FakeGithubUser("sender"), FakeGithubUser("sender"), "C987", "assignee"
        )

        slack_helper.shared_client.chat_postMessage.assert_called_once_with(
            channel="C987",
            text="<@U123> removed themselves as an assignee",
            thread_ts=None,
        )



================================================
FILE: devops/purrr/markdown_test.py
================================================
"""Unit tests for the "markdown" module."""

import collections

from autokitteh import github, slack
import pytest


@pytest.fixture(autouse=True)
def setup_mock_github_and_slack_clients(mocker):
    mocker.patch.object(github, "github_client", autospec=True)
    mocker.patch.object(slack, "slack_client", autospec=True)


class TestGithubToSlack:
    """Unit tests for the "github_to_slack" function."""

    def test_trivial(self):
        import text_utils

        assert text_utils.github_to_slack("", "") == ""

    def test_basic_headers(self):
        import text_utils

        assert text_utils.github_to_slack("# H1", "") == "*H1*"
        assert text_utils.github_to_slack("## H2", "") == "*H2*"
        assert text_utils.github_to_slack("### H3", "") == "*H3*"

    def test_multiple_headers(self):
        import text_utils

        a = text_utils.github_to_slack("# Title 1\n\nFoo\n\n## Subtitle 2\nBar", "")
        assert a == "*Title 1*\n\nFoo\n\n*Subtitle 2*\nBar"

    def test_basic_text_style(self):
        import text_utils

        assert text_utils.github_to_slack("_italic_", "") == "_italic_"
        assert text_utils.github_to_slack("*italic*", "") == "_italic_"
        assert text_utils.github_to_slack("__bold__", "") == "*bold*"
        assert text_utils.github_to_slack("**bold**", "") == "*bold*"
        assert text_utils.github_to_slack("~~strikethrough~~", "") == "~strikethrough~"

    def test_advanced_text_style(self):
        import text_utils

        assert text_utils.github_to_slack("***both***", "") == "_*both*_"
        actual = text_utils.github_to_slack("**this _is_ nested**", "")
        assert actual == "*this _is_ nested*"
        actual = text_utils.github_to_slack("**this *is* nested**", "")
        assert actual == "*this _is_ nested*"
        actual = text_utils.github_to_slack("__this _is_ nested__", "")
        assert actual == "*this _is_ nested*"
        actual = text_utils.github_to_slack("_this **is** nested_", "")
        assert actual == "_this *is* nested_"
        # TODO:
        # actual = text_utils.github_to_slack("*this **is** nested*", "")
        # assert actual == "_this *is* nested_"

    def test_quote_blocks(self):
        import text_utils

        actual = text_utils.github_to_slack("111\n>222\n> 333\n444", "")
        assert actual == "111\n>222\n> 333\n444"

    def test_code_blocks(self):
        import text_utils

        assert text_utils.github_to_slack("`inline`", "") == "`inline`"
        actual = text_utils.github_to_slack("```\nmulti\nline\n```", "")
        assert actual == "```\nmulti\nline\n```"

    def test_links(self):
        import text_utils

        assert text_utils.github_to_slack("[text](url)", "") == "<url|text>"
        actual = text_utils.github_to_slack("!<url maybe with text>", "")
        assert actual == "Image: <url maybe with text>"

    def test_simple_lists(self):
        import text_utils

        expected = "  ‚Ä¢  111\n  ‚Ä¢  222\n  ‚Ä¢  333"
        assert text_utils.github_to_slack("- 111\n- 222\n- 333", "") == expected
        assert text_utils.github_to_slack("+ 111\n+ 222\n+ 333", "") == expected
        # TODO: assert ...github_to_slack("* 111\n* 222\n* 333", "") == expected

    def test_nested_lists(self):
        import text_utils

        exp = "  ‚Ä¢  111\n          ‚ó¶   222\n          ‚ó¶   333\n  ‚Ä¢  444"
        assert text_utils.github_to_slack("- 111\n  - 222\n  - 333\n- 444", "") == exp
        assert text_utils.github_to_slack("+ 111\n  + 222\n  + 333\n+ 444", "") == exp
        # TODO: assert ...github_to_slack("* 111\n  * 222\n  * 333\n* 444", "") == exp

    def test_user_mentions(self, mocker):
        import text_utils
        import users

        pr = "https://github.com/org/repo/pull/123"
        id = mocker.patch.object(
            users, "github_username_to_slack_user_id", autospec=True
        )
        id.side_effect = ["U123", None, None]

        # Slack user found.
        assert text_utils.github_to_slack("@user", pr) == "<@U123>"
        # Slack user not found.
        actual = text_utils.github_to_slack("@user", pr)
        assert actual == "<https://github.com/user|@user>"
        # Team not found.
        actual = text_utils.github_to_slack("@org/team", pr)
        assert actual == "<https://github.com/org/teams/team|@org/team>"

    def test_pr_references(self):
        import text_utils

        pr = "https://github.com/org/repo/pull/987"
        actual = text_utils.github_to_slack("#123", pr)
        assert actual == "<https://github.com/org/repo/pull/123|#123>"

    def test_html_comments(self):
        import text_utils

        actual = text_utils.github_to_slack("Blah\n<!-- hidden -->\nBlah blah", "")
        assert actual == "Blah\n\nBlah blah"


class TestSlackToGithub:
    """Unit tests for the "slack_to_github" function."""

    def test_trivial(self):
        import text_utils

        assert text_utils.slack_to_github("") == ""

    def test_text_style(self):
        import text_utils

        assert text_utils.slack_to_github("_italic_") == "_italic_"
        assert text_utils.slack_to_github("*bold*") == "**bold**"
        assert text_utils.slack_to_github("_*both*_") == "***both***"
        assert text_utils.slack_to_github("~strikethrough~") == "~~strikethrough~~"

        # Not needed, but good to have just in case someone
        # sends a non-Slack-markdown message programmatically:
        assert text_utils.slack_to_github("__italic__") == "_italic_"
        assert text_utils.slack_to_github("**bold**") == "**bold**"
        assert text_utils.slack_to_github("*_both_*") == "***both***"
        assert text_utils.slack_to_github("***both***") == "***both***"
        assert text_utils.slack_to_github("~~strikethrough~~") == "~~strikethrough~~"

    def test_quote_blocks(self):
        import text_utils

        actual = text_utils.slack_to_github("111\n&gt;222\n&gt; 333\n444")
        assert actual == "111\n>222\n> 333\n444"
        actual = text_utils.slack_to_github("111\n>222\n> 333\n444")
        assert actual == "111\n>222\n> 333\n444"

    def test_code_blocks(self):
        import text_utils

        assert text_utils.slack_to_github("`inline`") == "`inline`"
        assert text_utils.slack_to_github("```mult\nline```") == "```\nmult\nline\n```"

    def test_lists(self):
        import text_utils

        assert text_utils.slack_to_github("‚Ä¢ X\n‚Ä¢ Y\n‚Ä¢ Z") == "- X\n- Y\n- Z"
        actual = text_utils.slack_to_github(
            "‚Ä¢ X\n    ‚ó¶ Y\n        ‚ñ™Ô∏é Z\n            ‚Ä¢ A\n                ‚ó¶ B"
        )
        assert actual == "- X\n  - Y\n    - Z\n      - A\n        - B"

    def test_links(self):
        import text_utils

        assert text_utils.slack_to_github("<url|text>") == "[text](url)"
        assert text_utils.slack_to_github("<url|>"), "[](url)"
        assert text_utils.slack_to_github("<url>"), "<url>"

    def test_channel(self, mocker):
        import text_utils

        channel = mocker.patch.object(text_utils, "_slack_channel_name", autospec=True)
        channel.return_value = "CHANNEL_NAME"
        team = mocker.patch.object(text_utils, "_slack_team_id", autospec=True)
        team.return_value = "TEAM_ID"

        expected = "[#CHANNEL_NAME](slack://channel?team=TEAM_ID&id=C123)"
        assert text_utils.slack_to_github("<#C123>") == expected
        assert text_utils.slack_to_github("<#C123|>") == expected

        actual = text_utils.slack_to_github("<#C123|custom-name>")
        assert actual == "[#custom-name](slack://channel?team=TEAM_ID&id=C123)"


FakeGithubUser = collections.namedtuple("FakeGithubUser", ["name", "login"])


class TestSlackToGithubUserMentions:
    """Unit tests for user mentions in the "slack_to_github" function."""

    @pytest.fixture
    def mock_github_user_id(self, mocker):
        import users

        return mocker.patch.object(users, "_email_to_github_user_id", autospec=True)

    @pytest.fixture
    def mock_github_users(self, mocker):
        import users

        return mocker.patch.object(users, "_github_users", autospec=True)

    @pytest.fixture
    def mock_slack_user_info(self, mocker):
        import users

        return mocker.patch.object(users, "_slack_user_info", autospec=True)

    def test_slack_user_info_error(self, mock_slack_user_info):
        import text_utils

        mock_slack_user_info.return_value = {}
        assert text_utils.slack_to_github("<@U123>") == "Someone"

    def test_email_and_name_not_found_in_slack_profile(self, mock_slack_user_info):
        import text_utils

        mock_slack_user_info.return_value = {"profile": {"foo": "bar"}}
        assert text_utils.slack_to_github("<@U123>") == "Someone"

    def test_named_and_unnamed_slack_apps(self, mock_slack_user_info):
        import text_utils

        mock_slack_user_info.side_effect = [
            {"is_bot": True, "profile": {"real_name": "Mr. Robot"}},
            {"is_bot": True},
        ]
        assert text_utils.slack_to_github("<@U123>") == "Mr. Robot"
        assert text_utils.slack_to_github("<@U123>") == "Some Slack app"

    def test_match_by_email(self, mock_github_user_id, mock_slack_user_info):
        import text_utils

        mock_github_user_id.return_value = "username"
        mock_slack_user_info.return_value = {"profile": {"email": "me@test.com"}}
        assert text_utils.slack_to_github("<@U123>") == "@username"

    def test_match_by_name(
        self, mock_github_user_id, mock_github_users, mock_slack_user_info
    ):
        import text_utils

        mock_github_user_id.return_value = ""
        mock_github_users.return_value = [FakeGithubUser("John Doe", "username")]
        mock_slack_user_info.return_value = {
            "profile": {"email": "me@test.com", "real_name": "John Doe"}
        }
        assert text_utils.slack_to_github("<@U123>") == "@username"

    def test_no_matches_by_name(
        self, mock_github_user_id, mock_github_users, mock_slack_user_info
    ):
        import text_utils

        mock_github_user_id.return_value = ""
        mock_github_users.return_value = []
        mock_slack_user_info.return_value = {
            "profile": {"email": "me@test.com", "real_name": "John Doe"}
        }
        assert text_utils.slack_to_github("<@U123>") == "John Doe"

    def test_too_many_matches_by_name(
        self, mock_github_user_id, mock_github_users, mock_slack_user_info
    ):
        import text_utils

        mock_github_user_id.return_value = ""
        mock_github_users.return_value = [
            FakeGithubUser("John Doe", "username1"),
            FakeGithubUser("john doe", "username2"),
            FakeGithubUser("JOHN DOE", "username3"),
        ]
        mock_slack_user_info.return_value = {
            "profile": {"email": "me@test.com", "real_name": "John Doe"}
        }
        assert text_utils.slack_to_github("<@U123>") == "John Doe"



================================================
FILE: devops/purrr/slack_channel.py
================================================
"""Create and manage Slack channels."""

import json
import time

from autokitteh.slack import normalize_channel_name
from slack_sdk.errors import SlackApiError

import data_helper
import debug
import slack_helper
import text_utils
import users


# Character limit for topics and descriptions of Slack channels.
_MAX_METADATA_LENGTH = 250

# Wait for a few seconds to handle other asynchronous events
# (e.g. a PR closure comment) before archiving the channel.
_PR_CLOSE_DELAY = 5


slack = slack_helper.shared_client


def initialize_for_github_pr(action: str, pr, sender) -> str:
    """Initialize a Slack channel that represents a GitHub PR.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user object of the PR sender.

    Returns:
        ID of the created Slack channel.
    """
    print(f"Creating Slack channel for {pr.html_url} (PR event action: {action})")
    print(json.dumps(pr, indent=4, sort_keys=True))

    name = f"{pr.number}_{normalize_channel_name(pr.title)}"
    channel_id = slack_helper.create_channel(name)
    if not channel_id:
        _report_creation_error(pr, sender.login)

    _set_topic(pr, channel_id)
    _set_description(pr, channel_id)
    _set_bookmarks(pr, channel_id)
    _post_messages(action, pr, sender, channel_id)

    # TODO: Map between the GitHub PR and the Slack channel ID, for 2-way event syncs.

    add_users(channel_id, users.github_pr_participants(pr))
    return channel_id


def _report_creation_error(pr, github_username) -> None:
    """Report to the PR sender that a Slack channel wasn't created for it, and abort."""
    error = "Failed to create Slack channel for " + pr.html_url
    debug.log(error)

    user_id = users.github_username_to_slack_user_id(github_username)
    if user_id and not data_helper.slack_opted_out(user_id):
        slack.chat_postMessage(channel=user_id, text=error)

    raise RuntimeError(error)


def _set_topic(pr, channel_id: str) -> None:
    """Set the topic of a Slack channel to a GitHub PR URL."""
    topic = pr.html_url
    if len(topic) > _MAX_METADATA_LENGTH:
        topic = topic[: _MAX_METADATA_LENGTH - 4] + " ..."
    try:
        slack.conversations_setTopic(channel=channel_id, topic=topic)
    except SlackApiError as e:
        error = f"Failed to set the topic of <#{channel_id}> to `{topic}`"
        debug.log(f"{error}: `{e.response['error']}`")


def _set_description(pr, channel_id: str) -> None:
    """Set the description of a Slack channel to a GitHub PR title."""
    title = f"`{pr.title}`"
    if len(title) > _MAX_METADATA_LENGTH:
        title = title[: _MAX_METADATA_LENGTH - 4] + "`..."
    try:
        slack.conversations_setPurpose(channel=channel_id, purpose=title)
    except SlackApiError as e:
        error = f"Failed to set the purpose of <#{channel_id}> to `{title}`"
        debug.log(f"{error}: `{e.response['error']}`")


def _set_bookmarks(pr, channel_id: str) -> None:
    """Set the bookmarks of a Slack channel to important GitHub PR links.

    Bookmark titles are also updated later based on relevant GitHub events.
    """
    pass  # TODO: Implement this function.


def _post_messages(action: str, pr, sender, channel_id: str) -> None:
    """Post initial messages to a Slack channel, describing a GitHub PR."""
    if action == "ready_for_review":
        action = "marked as ready for review"

    msg = f"{{}} {action} {pr.html_url}: `{pr.title}`"

    if pr.body:
        msg += "\n\n" + text_utils.github_to_slack(pr.body, pr.html_url)

    slack_helper.mention_in_message(channel_id, sender, msg)

    # TODO: Also post a message summarizing check states (updated
    # later based on "workflow_job" and "workflow_run" events).


def add_users(channel_id: str, github_users: list[str]) -> None:
    """Invite all the participants in a GitHub PR to a Slack channel."""
    slack_users = [users.github_username_to_slack_user_id(u) for u in github_users]
    slack_users = [user for user in slack_users if user]  # Ignore unrecognized users.

    # Also ignore users who opted out of Purrr. They will still be mentioned
    # in the channel, but as non-members they won't be notified about it.
    slack_users = [u for u in slack_users if not data_helper.slack_opted_out(u)]
    if not slack_users:
        return

    # Limit the number of users per https://api.slack.com/methods/conversations.invite
    if len(slack_users) > 1000:
        slack_users = slack_users[:1000]

    user_ids = ",".join(slack_users)
    try:
        slack.conversations_invite(channel=channel_id, users=user_ids, force=True)
    except SlackApiError as e:
        if e.response["error"] == "already_in_channel":
            return

        error = f"Failed to add {len(slack_users)} Slack user(s) to channel "
        error += f"<#{channel_id}>: `{e.response['error']}`"
        for err in e.response.get("errors", []):
            error += f"\n- <@{err.user}> - `{err.error}`"
        debug.log(error)


def archive(action: str, pr, sender) -> None:
    """Archive a Slack channel that represents a GitHub PR.

    This function is called when a PR is closed or converted to a draft.

    Args:
        action: GitHub PR event action.
        pr: GitHub PR data.
        sender: GitHub user who triggered the event.
    """
    channel_id = slack_helper.lookup_channel(pr.html_url, action)
    if not channel_id:
        # Unrecoverable error, but no need to report/debug it:
        # if we're not tracking it, there's nothing to fix.
        return

    # Wait for a few seconds to handle other asynchronous events
    # (e.g. a PR closure comment) before archiving the channel.
    time.sleep(_PR_CLOSE_DELAY)

    if action == "closed this PR":
        if pr.merged:
            action = "merged this PR"
    else:
        action = "converted this PR to a draft"

    slack_helper.mention_in_message(channel_id, sender, f"{{}} {action}")

    try:
        slack.conversations_archive(channel=channel_id)
    except SlackApiError as e:
        action = action.replace(" this PR", "")
        error = f"{pr.html_url} is `{action}`, but failed to archive <#{channel_id}>"
        debug.log(f"{error}: `{e.response['error']}`")



================================================
FILE: devops/purrr/slack_cmd.py
================================================
"""Handler for Slack slash-command events."""

import collections

import data_helper
import slack_helper


slack = slack_helper.shared_client


def on_slack_slash_command(event):
    """Entry-point for AutoKitteh sessions triggered by Slack slash-command events.

    - /purrr help
    - /purrr opt-in
    - /purrr opt-out
    - /purrr list
    - /purrr status [PR]
    - /purrr approve [PR]

    About slash commands: https://api.slack.com/interactivity/slash-commands
    See also: https://api.slack.com/interactivity/handling#message_responses

    Args:
        event: Slack event data.
    """
    # Split the command into normalized arguments.
    data = event.data
    args = str(data.text).lower().split()

    # Route further processing to the appropriate command handler.
    if not args or "help" in args:
        _help(data, args)
        return

    if args[0] in _COMMANDS:
        _COMMANDS[args[0]].handler(data, args)
        return

    error = f"Error: unrecognized Purrr command: `{args[0]}`"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=error)


def _error(data, cmd: str, msg: str):
    """Send a private error message to the user about their command."""
    error = f"Error in `{data.command} {cmd}`: {msg}"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=error)


def _help(data, args: list[str]):
    """Send a private message to the user to list all the available Purrr commands."""
    if len(args) > 2:
        # TODO: Support per-command help too, in the future.
        _error(data, "help", "this command doesn't accept extra arguments")
        return

    # General help message: a list of all the available commands.
    text = _help_text(data)
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=text)


def _help_text(data) -> str:
    text = ":wave: *GitHub Pull Request Review Reminder (Purrr)* :wave:\n\n"
    text += "Available slash commands:"
    for cmd in _COMMANDS.values():
        text += f"\n  ‚Ä¢  `{data.command} {cmd.label}` - {cmd.description}"
    return text


def _opt_in(data, args: list[str]):
    """User opt-in command handler (this is the default user state)."""
    if len(args) > 1:
        _error(data, args[0], "this command doesn't accept extra arguments")
        return

    if not data_helper.slack_opted_out(data.user_id):
        msg = ":bell: You're already opted into Purrr"
        slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=msg)
        return

    data_helper.slack_opt_in(data.user_id)
    msg = ":bell: You are now opted into Purrr"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=msg)


def _opt_out(data, args: list[str]):
    """User opt-out: don't use Purrr even in a Slack workspace that installed it."""
    if len(args) > 1:
        _error(data, args[0], "this command doesn't accept extra arguments")
        return

    opt_out_time = data_helper.slack_opted_out(data.user_id)
    if opt_out_time:
        msg = f":no_bell: You're already opted out of Purrr since: {opt_out_time}"
        slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=msg)
        return

    data_helper.slack_opt_out(data.user_id)
    msg = ":no_bell: You are now opted out of Purrr"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=msg)


def _list(data, args: list[str]):
    """PR list command handler."""
    if len(args) > 1:
        _error(data, args[0], "this command doesn't accept extra arguments")
        return

    error = "Sorry, this command is not implemented yet"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=error)


def _status(data, args: list[str]):
    """PR status command handler."""
    # TODO: If the Slack channel belongs to a PR, the arg is optional.
    if len(args) != 2:
        msg = "when called outside of a PR channel, this command requires exactly "
        msg += "1 argument - an ID of a GitHub PR (`<org>/<repo>/<number>`), "
        _error(data, args[0], msg + "or the PR's full URL")
        return

    error = "Sorry, this command is not implemented yet"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=error)


def _approve(data, args: list[str]):
    """Approve command."""
    # TODO: If the Slack channel belongs to a PR, the arg is optional.
    if len(args) != 2:
        msg = "when called outside of a PR channel, this command requires exactly "
        msg += "1 argument - an ID of a GitHub PR (`<org>/<repo>/<number>`), "
        _error(data, args[0], msg + "or the PR's full URL")
        return

    error = "Sorry, this command is not implemented yet"
    slack.chat_postEphemeral(channel=data.channel_id, user=data.user_id, text=error)


_Command = collections.namedtuple("Command", ["label", "handler", "description"])

_COMMANDS = {
    "opt-in": _Command("opt-in", _opt_in, "Opt into receiving notifications"),
    "opt-out": _Command("opt-out", _opt_out, "Opt out of receiving notifications"),
    "list": _Command("list", _list, "List all PRs you should pay attention to"),
    "status": _Command("status [PR]", _status, "Check the status of a specific PR"),
    "approve": _Command("approve [PR]", _approve, "Approve a specific PR"),
}



================================================
FILE: devops/purrr/slack_cmd_test.py
================================================
"""Unit tests for the "slack_cmd" module."""

from datetime import datetime, UTC

import autokitteh
from autokitteh import github, slack
import pytest


MIN_UTC = datetime.min.replace(tzinfo=UTC)


@pytest.fixture(autouse=True)
def setup_mock_github_and_slack_clients(mocker):
    mocker.patch.object(github, "github_client", autospec=True)
    mocker.patch.object(slack, "slack_client", autospec=True)


@pytest.fixture
def mock_data_helper(mocker):
    import slack_cmd

    return mocker.patch.object(slack_cmd, "data_helper", autospec=True)


fake_data = {
    "channel_id": "purr-debug",
    "user_id": "user",
    "command": "/purrr",
}


def test_help_text():
    import slack_cmd

    data = autokitteh.AttrDict(fake_data)
    text = slack_cmd._help_text(data)

    for cmd in slack_cmd._COMMANDS.values():
        assert cmd.label in text
        assert cmd.description in text


def test_on_slack_slash_command_without_text():
    import slack_cmd

    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": ""}})
    slack_cmd.on_slack_slash_command(event)

    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=slack_cmd._help_text(event.data),
    )


def test_on_slack_slash_command_with_help():
    import slack_cmd

    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": "help"}})
    slack_cmd.on_slack_slash_command(event)

    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=slack_cmd._help_text(event.data),
    )


def test_on_slack_slash_command_with_noop_opt_in(mock_data_helper):
    import slack_cmd

    mock_data_helper.slack_opted_out.return_value = ""
    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": "opt-in"}})
    slack_cmd.on_slack_slash_command(event)

    mock_data_helper.slack_opted_out.assert_called_once_with(event.data.user_id)
    mock_data_helper.slack_opt_in.assert_not_called()
    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=":bell: You're already opted into Purrr",
    )


def test_on_slack_slash_command_with_actual_opt_in(mock_data_helper):
    import slack_cmd

    mock_data_helper.slack_opted_out.return_value = MIN_UTC
    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": "opt-in"}})
    slack_cmd.on_slack_slash_command(event)

    mock_data_helper.slack_opted_out.assert_called_once_with(event.data.user_id)
    mock_data_helper.slack_opt_in.assert_called_once_with(event.data.user_id)
    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=":bell: You are now opted into Purrr",
    )


def test_on_slack_slash_command_with_noop_opt_out(mock_data_helper):
    import slack_cmd

    mock_data_helper.slack_opted_out.return_value = MIN_UTC
    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": "opt-out"}})
    slack_cmd.on_slack_slash_command(event)

    mock_data_helper.slack_opted_out.assert_called_once_with(event.data.user_id)
    mock_data_helper.slack_opt_out.assert_not_called()
    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=":no_bell: You're already opted out of Purrr since: "
        "0001-01-01 00:00:00+00:00",
    )


def test_on_slack_slash_command_with_second_opt_out(mock_data_helper):
    import slack_cmd

    mock_data_helper.slack_opted_out.return_value = ""
    slack_cmd.slack.chat_postEphemeral.reset_mock()

    event = autokitteh.AttrDict({"data": fake_data | {"text": "opt-out"}})
    slack_cmd.on_slack_slash_command(event)

    mock_data_helper.slack_opted_out.assert_called_once_with(event.data.user_id)
    mock_data_helper.slack_opt_out.assert_called_once_with(event.data.user_id)
    slack_cmd.slack.chat_postEphemeral.assert_called_once_with(
        channel=event.data.channel_id,
        user=event.data.user_id,
        text=":no_bell: You are now opted out of Purrr",
    )



================================================
FILE: devops/purrr/slack_helper.py
================================================
"""Thin layer of logic on top of the Slack API."""

import os

from autokitteh.slack import slack_client
from slack_sdk.errors import SlackApiError

import data_helper
import debug
import users


# PR channel names in Slack: "<prefix>_<number>_<title>".
_CHANNEL_PREFIX = os.getenv("SLACK_CHANNEL_PREFIX", "_pr")

# Visibility of PR channels in Slack: "public" (default) or "private".
_IS_PRIVATE = os.getenv("SLACK_CHANNEL_VISIBILITY", "")

shared_client = slack_client("slack_conn")


def create_channel(name: str) -> str:
    """Create a public or private Slack channel.

    If the name is already taken, add a numeric suffix to it.

    Args:
        name: Desired (and valid) name of the channel.

    Returns:
        Channel ID, or an empty string in case of an error.
    """
    is_private = _IS_PRIVATE.lower().strip() == "private"
    visibility = "private" if is_private else "public"
    suffix = 0

    while True:
        suffix += 1
        n = _CHANNEL_PREFIX + "_" + name if suffix == 1 else f"{name}_{suffix}"
        try:
            resp = shared_client.conversations_create(name=n, is_private=is_private)
            channel_id = resp["channel"]["id"]
            print(f"Created {visibility} Slack channel {n!r} ({channel_id})")
            return channel_id
        except SlackApiError as e:
            if e.response["error"] != "name_taken":
                error = f"Failed to create {visibility} Slack channel `{n}`"
                debug.log(f"{error}: `{e.response['error']}`")
                return ""


def rename_channel(channel_id: str, name: str) -> None:
    """Safely rename a Slack channel.

    If the name is already taken, add a numeric suffix to it.

    Args:
        channel_id: Slack channel ID.
        name: Desired (and valid) name of the channel.
    """
    suffix = 0
    while True:
        suffix += 1
        n = _CHANNEL_PREFIX + "_" + name if suffix == 1 else f"{name}_{suffix}"
        try:
            shared_client.conversations_rename(channel=channel_id, name=n)
            print(f"Renamed Slack channel to {n!r} ({channel_id})")
            return
        except SlackApiError as e:
            if e.response["error"] != "name_taken":
                error = f"Failed to rename Slack channel <#{channel_id}> to `{n}`"
                debug.log(f"{error}: `{e.response['error']}`")
                return


def impersonate_in_message(channel_id: str, github_user, msg: str) -> str:
    """Post a message to a Slack channel, on behalf of a GitHub user.

    Similar functions:
    - impersonate_in_reply
    - mention_in_message
    - mention_in_reply

    Args:
        channel_id: ID of the channel to send the message to.
        github_user: GitHub user object of the impersonated user.
        msg: Message to send.

    Returns:
        Message's thread timestamp, or "" in case of an error.
    """
    return impersonate_in_reply(channel_id, "", github_user, msg)


def impersonate_in_reply(
    channel_id: str, comment_url: str, github_user, msg: str
) -> str:
    """Post a reply to a Slack thread, on behalf of a GitHub user.

    Similar functions:
    - impersonate_in_message
    - mention_in_message
    - mention_in_reply

    Args:
        channel_id: ID of the channel to send the message to.
        comment_url: URL of the GitHub PR comment to reply to.
        github_user: GitHub user object of the impersonated user.
        msg: Message to send.

    Returns:
        Message's thread timestamp, or "" in case of an error.
    """
    # TODO: Is this check needed?
    # if not channel_id:
    #     return ""

    user = users.github_username_to_slack_user(github_user.login)
    if not user:
        return ""

    profile = user.get("profile", {})
    icon = profile.get("image_48")
    name = profile.get("real_name")
    ts = _lookup_message(comment_url)

    try:
        resp = shared_client.chat_postMessage(
            channel=channel_id, text=msg, thread_ts=ts, icon_url=icon, username=name
        )
        return resp["ts"]
    except SlackApiError as e:
        error = f"Failed to post {'reply' if ts else 'message'} "
        error += f"as <@{user['id']}> in <#{channel_id}>"
        debug.log(f"{error}: `{e.response['error']}`")
        return ""


def lookup_channel(pr_url: str, action: str) -> str | None:
    """Return the ID of a Slack channel that represents a GitHub PR.

    This function waits up to a few seconds for the PR's Slack message to exist,
    because GitHub events are asynchronous. For example: when a PR is re/opened,
    some "review_requested" events may arrive before the "opened" event.

    Args:
        pr_url: URL of the GitHub PR.
        action: GitHub PR event action.

    Returns:
        Channel ID, or None if not found.
    """
    channel_id = data_helper.lookup_github_link_details(pr_url)
    if not channel_id:
        debug.log(f"{pr_url} is `{action}`, but its Slack channel ID not found")
    return channel_id


def _lookup_message(comment_url: str) -> str | None:
    """Return the ID (timestamp) of a Slack message that represents a GitHub PR review.

    This function waits up to a few seconds for the PR review's Slack message
    to exist, because GitHub events are asynchronous. For example: when a PR
    review is submitted with file and line comments, some "child" comment
    events may arrive before the "parent" review event.

    Args:
        comment_url: URL of the GitHub PR comment to reply to.

    Returns:
        Message's thread timestamp, or None if not found.
    """
    thread_ts = data_helper.lookup_github_link_details(comment_url)
    if not thread_ts:
        debug.log(f"Slack message mapping for {comment_url} not found")
    return thread_ts


def mention_in_message(channel_id: str, github_user, msg: str) -> str:
    """Post a message to a Slack channel, mentioning a GitHub user.

    Similar functions:
    - impersonate_user_in_message
    - impersonate_user_in_reply
    - mention_user_in_reply

    Args:
        channel_id: ID of the channel to send the message to.
        github_user: GitHub user object of the mentioned user.
        msg: Message to send, containing a single "{}" placeholder.

    Returns:
        Message's thread timestamp, or "" in case of an error.
    """
    return mention_in_reply(channel_id, "", github_user, msg)


def mention_in_reply(channel_id: str, comment_url: str, github_user, msg: str) -> str:
    """Post a reply to a Slack thread, mentioning a GitHub user.

    Similar functions:
    - impersonate_user_in_message
    - impersonate_user_in_reply
    - mention_user_in_message

    Args:
        channel_id: ID of the channel to send the message to.
        comment_url: URL of the GitHub PR comment to reply to.
        github_user: GitHub user object of the mentioned user.
        msg: Message to send, containing a single "{}" placeholder.

    Returns:
        Message's thread timestamp, or "" in case of an error.
    """
    # TODO: Is this check needed?
    # if not channel_id:
    #     return ""

    m = msg.format(users.format_github_user_for_slack(github_user))
    ts = _lookup_message(comment_url)

    try:
        resp = shared_client.chat_postMessage(channel=channel_id, text=m, thread_ts=ts)
        return resp["ts"]
    except SlackApiError as e:
        error = f"Failed to post {'reply' if ts else 'message'} in <#{channel_id}>"
        debug.log(f"{error}: `{e.response['error']}`")
        return ""



================================================
FILE: devops/purrr/text_utils.py
================================================
"""Markdown-related helper functions across GitHub and Slack."""

import collections
import re
from urllib.parse import urlparse

from slack_sdk.errors import SlackApiError

import debug
import slack_helper
import users


_GithubUser = collections.namedtuple("GithubUser", ["login", "html_url"])
_SlackChannel = collections.namedtuple("SlackChannel", ["name", "id"])
_SlackUser = collections.namedtuple("SlackUser", ["link", "id"])


slack = slack_helper.shared_client


def github_to_slack(text: str, pr_url: str) -> str:
    """Convert GitHub markdown text to Slack markdown text.

    References:
    - https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax
    - https://api.slack.com/reference/surfaces/formatting

    Args:
        text: Text body, possibly containing GitHub markdown.
        pr_url: URL of the PR we're working on, used to convert
            other PR references in the text ("#123") to links.

    Returns:
        Slack markdown text.
    """
    # Header lines --> bold lines.
    text = re.sub(r"^#+\s+(.+)", r"**\1**", text, flags=re.MULTILINE)

    # Bold and italic text together: "*** ... ***" --> "_* ... *_".
    text = re.sub(r"\*\*\*(.+?)\*\*\*", r"_**\1**_", text)

    # Italic text: "*" --> "_" ("_" -> "_" is a no-op).
    text = re.sub(r"(^|[^*])\*([^*]+?)\*", r"\1_\2_", text)

    # Bold text: "**" or "__" --> "*".
    text = re.sub(r"\*\*(.+?)\*\*", r"*\1*", text)
    text = re.sub(r"__(.+?)__", r"*\1*", text)

    # Strikethrough text: "~~" --> "~" ("~" -> "~" is a no-op).
    text = re.sub(r"~~(.+?)~~", r"~\1~", text)

    # Links: "[text](url)" --> "<url|text>".
    # Images: "![text](url)" --> "!<url|text>" --> "Image: <url|text>".
    text = re.sub(r"\[(.*?)\]\((.*?)\)", r"<\2|\1>", text)
    text = re.sub(r"!<(.*?)>", r"Image: <\1>", text)

    # Lists (up to 2 levels): "-" or "*" or "+" --> "‚Ä¢" and "‚ó¶".
    for bullet in ("-", r"\+"):
        text = re.sub(rf"^{bullet}\s*", "  ‚Ä¢  ", text, flags=re.MULTILINE)
        text = re.sub(
            rf"^\s{{2,4}}{bullet}\s*", r"          ‚ó¶   ", text, flags=re.MULTILINE
        )

    # Mentions: "@user" --> "<@U123>" or "<https://github.com/user|@user>",
    # "@org/team" --> "<https://github.com/org/teams/team|@org/team>".
    for github_user in re.findall(r"@[\w/-]+", text):
        parsed = urlparse(pr_url)
        url_suffix = github_user[1:]
        if "/" in url_suffix:
            url_suffix = url_suffix.replace("/", "/teams/")
        profile_link = f"{parsed.scheme}://{parsed.netloc}/{url_suffix}"
        user_obj = _GithubUser(login=github_user[1:], html_url=profile_link)
        slack_user = users.format_github_user_for_slack(user_obj)
        text = text.replace(github_user, slack_user)

    # PR references: "#123" --> "<PR URL|#123>" (works for issues too).
    url_base = re.sub(r"/pull/\d+$", "/pull", pr_url)
    text = re.sub(r"#(\d+)", rf"<{url_base}/\1|#\1>", text)

    # Hide HTML comments.
    text = re.sub(r"<!--.+?-->", "", text, flags=re.DOTALL)

    return text


def slack_to_github(text: str) -> str:
    """Convert Slack markdown text to GitHub markdown text.

    References:
    - https://api.slack.com/reference/surfaces/formatting
    - https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax

    Args:
        text: Text body, possibly containing Slack markdown.

    Returns:
        GitHub markdown text.
    """
    # Bold and italic text together: "_*" or "*_" --> "***".
    text = re.sub(r"_\*(.+?)\*_", r"***\1***", text)
    text = re.sub(r"\*_(.+?)_\*", r"***\1***", text)

    # Bold text: "*" --> "**" (italic text is a no-op: "_" --> "_").
    text = re.sub(r"(^|[^*])\*([^*]+?)\*", r"\1**\2**", text)

    # Italic text: "__" --> "_".
    text = re.sub(r"__(.+?)__", r"_\1_", text)

    # Strikethrough text: "~" --> "~~" ("~~" -> "~~" is a no-op).
    text = re.sub(r"(^|[^~])~([^~]+?)~", r"\1~~\2~~", text)

    # Block quotes: "&gt; aaa" --> "> aaa".
    text = re.sub(r"^&gt;(.*)", r">\1", text, flags=re.MULTILINE)

    # Multiline code blocks: ```aaa\nbbb``` --> ```\naaa\nbbb\n```.
    text = re.sub(r"```(.+?)```", r"```\n\1\n```", text, flags=re.DOTALL)

    # Lists (up to 5 levels): "‚Ä¢", "‚ó¶", and "‚ñ™Ô∏é" --> "-".
    text = re.sub(r"^‚Ä¢", "-", text, flags=re.MULTILINE)
    text = re.sub(r"^    ‚ó¶", "  -", text, flags=re.MULTILINE)
    text = re.sub(r"^        ‚ñ™Ô∏é", "    -", text, flags=re.MULTILINE)
    text = re.sub(r"^            ‚Ä¢", "      -", text, flags=re.MULTILINE)
    text = re.sub(r"^                ‚ó¶", "        -", text, flags=re.MULTILINE)

    # Links: "<url|text>" or "<@...>" or "<#...>" --> "[text](url)".
    text = re.sub(r"<(.*?)\|(.*?)>", r"[\2](\1)", text)
    text = re.sub(r"<([@#][A-Z0-9]+)>", r"[](\1)", text)

    # Channel references: "<#...>" or "<#...|name>" --> "[name](#...)" -->
    # "[#name](slack://channel?team={TEAM_ID}&id={CHANNEL_ID})"
    # (see https://api.slack.com/reference/deep-linking).
    for channel in re.findall(r"\[(.*?)\]\(#([A-Z0-9]+)\)", text):
        channel = _SlackChannel(*channel)
        old = f"[{channel.name}](#{channel.id})"
        if not channel.name:
            channel = _SlackChannel(_slack_channel_name(channel.id), channel.id)
        team_id = _slack_team_id()
        new = f"[#{channel.name}](slack://channel?team={team_id}&id={channel.id})"
        text = text.replace(old, new)

    # User mentions: "<@...>" --> "[](@...)" --> "@github-user" or "Full Name".
    for slack_user in re.findall(r"(\[.*?\]\(@([A-Z0-9]+)\))", text):
        slack_user = _SlackUser(*slack_user)
        github_user = users.format_slack_user_for_github(slack_user.id)
        text = text.replace(slack_user.link, github_user)

    return text


def _slack_channel_name(id: str) -> str:
    """Return the name of a Slack channel based on its ID."""
    try:
        resp = slack.conversations_info(channel=id)
        return resp.get("channel", {}).get("name", "")
    except SlackApiError as e:
        error = f"Failed to get Slack channel info for <#{id}>"
        debug.log(f"{error}: `{e.response['error']}`")
        return ""


def _slack_team_id() -> str:
    """Return the Slack app's team ID."""
    try:
        return slack.auth_test().get("team_id", "")
    except SlackApiError as e:
        debug.log(f"Slack auth test failed: `{e.response['error']}`")
        return ""



================================================
FILE: devops/purrr/users.py
================================================
"""User-related helper functions across GitHub and Slack."""

from autokitteh.slack import slack_client
from github import GithubException
from github import NamedUser
from slack_sdk.errors import SlackApiError

import data_helper
import debug
import github_helper


gh = github_helper.shared_client
slack = slack_client("slack_conn")


def _email_to_github_user_id(email: str) -> str:
    """Convert an email address to a GitHub user ID, or "" if not found."""
    users = gh.search_users(email + " in:email")
    if users.totalCount == 1:
        return users[0].login
    else:
        error = f"GitHub user search results: {users.totalCount} users"
        debug.log(f"{error} with the email address `{email}`")
        return ""


def _email_to_slack_user_id(email: str) -> str:
    """Convert an email address to a Slack user ID, or "" if not found."""
    try:
        resp = slack.users_lookupByEmail(email=email)
        return resp.get("user", {}).get("id", "")
    except SlackApiError as e:
        error = f"Failed to look-up Slack user by email {email}"
        debug.log(f"{error}: `{e.response['error']}`")
        return ""


def format_github_user_for_slack(github_user) -> str:
    """Convert a GitHub user or team to a linkified reference in Slack.

    Args:
        github_user: GitHub user object.

    Returns:
        Slack user reference, or GitHub profile link.
        Used for mentioning users in Slack messages.
    """
    slack_user_id = github_username_to_slack_user_id(github_user.login)
    if slack_user_id:
        # Mention the user by their Slack ID, if possible.
        return f"<@{slack_user_id}>"
    else:
        # Otherwise, fall-back to their GitHub profile link.
        return f"<{github_user.html_url}|@{github_user.login}>"


def format_slack_user_for_github(slack_user_id: str) -> str:
    """Convert a Slack user ID to a GitHub user reference/name.

    This function also caches both successful and failed results for
    a day, to reduce the amount of API calls, especially to Slack.

    Args:
        slack_user_id: Slack user ID.

    Returns:
        GitHub user reference, or the Slack user's full name, or "Someone".
        Used for mentioning users in GitHub reviews and comments.
    """
    if not slack_user_id:
        debug.log("Required input not found: Slack user ID")
        return "Someone"

    # Optimization: if we already have it cached, no need to look it up.
    github_ref = data_helper.cached_github_reference(slack_user_id)
    if github_ref:
        return github_ref

    user = _slack_user_info(slack_user_id)
    if not user:
        # This is never OK, don't cache it in order to keep retrying.
        return "Someone"

    profile = user.get("profile", {})

    # Special case: Slack apps/bots can't have GitHub identities.
    if user.get("is_bot"):
        bot_name = profile.get("real_name", "Some Slack app")
        data_helper.cache_github_reference(slack_user_id, bot_name)
        return bot_name

    # Try to match by the email address first.
    email = profile.get("email", "")
    if not email:
        debug.log(f"Email address not set for Slack user <@{slack_user_id}>")
    else:
        github_id = _email_to_github_user_id(email)
        if github_id:
            github_ref = "@" + github_id
            data_helper.cache_github_reference(slack_user_id, github_ref)
            return github_ref

    # Otherwise, try to match by the user's full name.
    slack_name = profile.get("real_name", "").lower()
    if not slack_name:
        debug.log(f"Slack user <@{slack_user_id}>: `real_name` not found in profile")
        return "Someone"

    users = []
    for user in _github_users():
        if user.name and user.name.lower() == slack_name:
            users.append(user)

    if len(users) == 1:
        github_ref = "@" + users[0].login
        data_helper.cache_github_reference(slack_user_id, github_ref)
        return github_ref

    # Optimization: cache unsuccessful results too (i.e. external collaborators).
    error = f"Slack user <@{slack_user_id}>: found {len(users)}"
    debug.log(f"{error} GitHub org members with the same full name")
    data_helper.cache_github_reference(slack_user_id, profile["real_name"])

    # If all else fails, return the Slack user's full name.
    return profile["real_name"]


def _github_users() -> list[NamedUser.NamedUser]:
    """Return a list of all GitHub users in the organization."""
    try:
        return list(gh.get_organization(github_helper.ORG_NAME).get_members())
    except GithubException as e:
        error = "Failed to list GitHub members in the organization"
        debug.log(f"{error} `{github_helper.ORG_NAME}`:\n```{e}```")
        return []


def github_pr_participants(pr) -> list[str]:
    """Return all the participants in the given GitHub PR.

    Args:
        pr: GitHub PR data.

    Returns:
        List of usernames (author/reviewers/assignees),
        guaranteed to be sorted and without repetitions.
    """
    usernames = []

    # Author.
    if pr.user.type == "User":
        usernames.append(pr.user.login)

    # Specific reviewers (not teams) + assignees.
    for user in pr.requested_reviewers + pr.assignees:
        if user.type == "User" and user.login not in usernames:
            usernames.append(user.login)

    return sorted(usernames)


def github_username_to_slack_user(github_username: str) -> dict:
    """Convert a GitHub username to Slack user data (empty in case of errors)."""
    slack_user_id = github_username_to_slack_user_id(github_username)
    return _slack_user_info(slack_user_id) if slack_user_id else {}


def github_username_to_slack_user_id(github_username: str) -> str:
    """Convert a GitHub username to a Slack user ID, or "" if not found.

    This function tries to match the email address first, and then
    falls back to matching the user's full name (case-insensitive).

    This function also caches both successful and failed results for
    a day, to reduce the amount of API calls, especially to Slack.
    """
    # Don't even check GitHub teams, only individual users.
    if "/" in github_username:
        return ""

    # Optimization: if we already have it cached, no need to look it up.
    slack_user_id = data_helper.cached_slack_user_id(github_username)
    if slack_user_id in ("bot", "not found"):
        return ""
    elif slack_user_id:
        return slack_user_id

    user = gh.get_user(github_username)
    gh_user_link = f"<{user.html_url}|{github_username}>"

    # Special case: GitHub bots can't have Slack identities.
    if user.type == "Bot":
        data_helper.cache_slack_user_id(github_username, "bot")
        return ""

    # Try to match by the email address first.
    if not user.email:
        debug.log(f"GitHub user {gh_user_link}: email address not found")
    else:
        slack_user_id = _email_to_slack_user_id(user.email)
        if slack_user_id:
            data_helper.cache_slack_user_id(github_username, slack_user_id)
            return slack_user_id

    # Otherwise, try to match by the user's full name.
    github_name = (user.name or "").lower()
    if not github_name:
        debug.log(f"GitHub user {gh_user_link}: full name not found")
        return ""

    for user in _slack_users():
        profile = user.get("profile", {})
        real_name = profile.get("real_name", "").lower()
        normalized_name = profile.get("real_name_normalized", "").lower()
        if github_name in (real_name, normalized_name):
            slack_user_id = user.get("id", "")
            data_helper.cache_slack_user_id(github_username, slack_user_id)
            return slack_user_id

    # Optimization: cache unsuccessful results too (i.e. external users).
    debug.log(f"GitHub user {gh_user_link}: email & name not found in Slack")
    data_helper.cache_slack_user_id(github_username, "not found")
    return ""


def _slack_user_info(slack_user_id: str) -> dict:
    """Return all the details of a Slack user based on their ID."""
    try:
        resp = slack.users_info(user=slack_user_id)
        return resp.get("user", {})
    except SlackApiError as e:
        error = f"Failed to get Slack user info for <@{slack_user_id}>"
        debug.log(f"{error}: `{e.response['error']}`")
        return {}


def _slack_users() -> list[dict]:
    """Return a list of all Slack users in the workspace."""
    users = []
    next_cursor = None
    while next_cursor != "":
        try:
            resp = slack.users_list(cursor=next_cursor, limit=100)
            users += resp.get("members", [])
            next_cursor = resp.get("response_metadata", {}).get("next_cursor", "")
        except SlackApiError as e:
            debug.log(f"Failed to list Slack users: `{e.response['error']}`")
            next_cursor = ""

    return users



================================================
FILE: devops/reviewkitteh/README.md
================================================
title: ReviewKitteh
description: Monitor a GitHub PR in Slack until it's closed
integrations: ["github", "googlesheets", "slack"]
categories: ["DevOps"]
tags: ["webhook_handling", "long_running", "monitoring", "notifications", "data_processing"]



================================================
FILE: devops/reviewkitteh/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that integrates GitHub, Google Sheets, and Slack.

version: v1

project:
  name: reviewkitteh

  vars:
    - name: SLACK_CHANNEL_ID
      value:
    - name: GOOGLE_SHEET_ID
      value:
    - name: ORG_DOMAIN
      value:

  connections:
    - name: github_conn
      integration: github
    - name: googlesheets_conn
      integration: googlesheets
    - name: slack_conn
      integration: slack

  triggers:
    - name: github_pull_request
      connection: github_conn
      event_type: pull_request
      filter: data.action == "opened" || data.action == "reopened"
      call: program.py:on_github_pull_request



================================================
FILE: devops/reviewkitteh/program.py
================================================
"""Listen for GitHub pull requests and meow at random people.

This program listens for GitHub pull request events and posts a message
to a Slack channel when a pull request is opened or reopened. It then polls
the pull request until it is closed or merged, updating the message with the
current state of the pull request. Every 15 seconds, it also reads a random
name from a Google Sheet and pages that person in the Slack channel.
"""

from datetime import datetime, UTC
import os
import random
import time

from autokitteh.github import github_client
from autokitteh.google import google_sheets_client
from autokitteh.slack import slack_client


CHANNEL_ID = os.getenv("SLACK_CHANNEL_ID", "")
SHEET_ID = os.getenv("GOOGLE_SHEET_ID", "")
ORG_DOMAIN = os.getenv("ORG_DOMAIN", "")

github = github_client("github_conn")
googlesheets = google_sheets_client("googlesheets_conn").spreadsheets().values()
slack = slack_client("slack_conn")


def on_github_pull_request(event):
    """Workflow's entry-point."""
    pr = event.data.pull_request
    msg = f"{pr.html_url} [{pr.state}]"
    ts = slack.chat_postMessage(channel=CHANNEL_ID, text=msg)["ts"]

    i = 0

    while pr.state not in ("closed", "merged"):
        _log(f"Polling #{i}")
        time.sleep(5)

        repo = github.get_repo(event.data.repository.full_name)
        pr = repo.get_pull(pr.number)
        msg = f"{pr.html_url} meow [{pr.state}]"
        slack.chat_update(channel=CHANNEL_ID, ts=ts, text=msg)

        i += 1

        if i % 3 == 0:
            # Spreadsheet contains a list of usernames.
            result = googlesheets.get(spreadsheetId=SHEET_ID, range="A1:A5").execute()
            rows = result.get("values", [])
            the_chosen_one = random.choice(rows)[0]
            _log(f"Meowing at {the_chosen_one}")

            user_email = f"{the_chosen_one}@{ORG_DOMAIN}"
            user = slack.users_lookupByEmail(email=user_email)["user"]
            msg = f"Paging <@{user['id']}>"
            slack.chat_postMessage(channel=CHANNEL_ID, text=msg, thread_ts=ts)


def _log(msg):
    print(f"[{datetime.now(UTC)}] {msg}")



================================================
FILE: devops/sftp/README.md
================================================
title: SFTP demo
description: Trigger a file transfer from SFTP to HTTP on webhook call
integrations: []
categories: ["DevOps"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: devops/sftp/autokitteh.yaml
================================================
# This is a YAML file that describes the minimal setup of an AutoKitteh SFTP project.

version: v1

project:
  name: SFTP_demo

  triggers:
    - name: webhook
      type: webhook
      event_type: get
      call: program.py:on_webhook_call

  vars:
    - name: HTTP_TARGET
      value: ""



================================================
FILE: devops/sftp/program.py
================================================
"""Download a file via SFTP, remove spaces and upload it."""

from io import BytesIO
import os

import autokitteh
import paramiko
import requests


SFTP_CONFIG = {
    "host": "test.rebex.net",
    "port": 22,
    "username": "demo",
    "password": "password",
    "remote_path": "/readme.txt",
}


HTTP_TARGET = os.getenv("HTTP_TARGET")


def download_sftp_file(host, port, username, password, remote_path):
    transport = paramiko.Transport((host, port))
    transport.connect(username=username, password=password)
    sftp = paramiko.SFTPClient.from_transport(transport)

    file_io = BytesIO()
    sftp.getfo(remote_path, file_io)
    file_io.seek(0)

    sftp.close()
    transport.close()
    return file_io


def remove_spaces(file_io):
    content = file_io.read().decode("utf-8").replace(" ", "")
    return BytesIO(content.encode("utf-8"))


def send_file_http(file_io, filename, url):
    file_io.seek(0)
    files = {"file": (filename, file_io)}
    response = requests.post(url, files=files, timeout=10)
    return response.status_code, response.text


# Use a single activity to avoid Temporal's data serialization between steps.
# - big files boundary.
# - Keeps a stream (not serializable) in-process.
@autokitteh.activity
def on_webhook_call(_):
    """Download a file via SFTP, remove spaces and upload it."""
    print("Downloading from SFTP...")
    file_io = download_sftp_file(**SFTP_CONFIG)

    processed = remove_spaces(file_io)

    print(f"Sending to {HTTP_TARGET}...")
    status, msg = send_file_http(processed, "readme.txt", HTTP_TARGET)
    print(f"Upload status: {status}, Message: {msg}")



================================================
FILE: devops/sftp/requirements.txt
================================================
paramiko


================================================
FILE: discord_to_spreadsheet/README.md
================================================
title: Discord to Spreadsheet Workflow
description: Log Discord messages to a Google Sheets document automatically
integrations: ["discord", "googlesheets"]
categories: ["Productivity"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: discord_to_spreadsheet/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that logs messages from Discord to a
# Google Sheets document.

version: v1

project:
  name: discord_to_spreadsheet

  vars:
    - name: RANGE_NAME
      value: Sheet1!A1
    - name: SPREADSHEET_ID
      value:

  connections:
    - name: discord_conn
      integration: discord
    - name: googlesheets_conn
      integration: googlesheets

  triggers:
    - name: on_discord_message
      connection: discord_conn
      event_type: message_create
      call: program.py:on_discord_message



================================================
FILE: discord_to_spreadsheet/program.py
================================================
"""Log Discord message events and the author's username into a Google Sheet."""

import os

from autokitteh.google import google_sheets_client


SPREADSHEET_ID = os.getenv("SPREADSHEET_ID")
RANGE_NAME = os.getenv("RANGE_NAME")

sheet = google_sheets_client("googlesheets_conn").spreadsheets().values()


def on_discord_message(event):
    values = [[event.data["author"]["username"], event.data["content"]]]
    sheet.append(
        spreadsheetId=SPREADSHEET_ID,
        range=RANGE_NAME,
        valueInputOption="USER_ENTERED",
        body={"values": values},
    ).execute()



================================================
FILE: github_copilot_seats/README.md
================================================
title: Cancel GitHub Copilot access for inactive users
description: If Copilot was not used in a preceding period by users, unsubscribe and notify them in Slack. Users can ask for their subscription to be reinstated.
integrations: ["github", "slack"]
categories: ["DevOps"]
tags:
  [
    "child_sessions",
    "interactive_workflows",
    "user_interactions",
    "start",
    "subscribe",
    "next_event",
    "essential",
  ]



================================================
FILE: github_copilot_seats/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that manages GitHub Copilot subscriptions.

version: v1

project:
  name: github_copilot_seats

  vars:
    - name: IDLE_HOURS_THRESHOLD
      value: 72
    # Optional: manage GitHub Copilot subscriptions only for these users, separated by commas.
    - name: MANAGED_LOGINS
      value:
    # Optional: Slack channel name or ID, for debugging.
    - name: SLACK_LOG_CHANNEL
      value:

  connections:
    - name: github_conn
      integration: github
    - name: slack_conn
      integration: slack

  triggers:
    - name: check_daily
      schedule: "@daily"
      call: triggers.py:on_schedule
    - name: check_now
      connection: slack_conn
      event_type: slash_command
      call: triggers.py:on_slack_slash_command



================================================
FILE: github_copilot_seats/message.json
================================================
{
	"blocks": [
		{
			"type": "header",
			"text": {
				"type": "plain_text",
				"text": "You have been removed from the Copilot program due to inactivity",
				"emoji": true
			}
		},
		{
			"type": "section",
			"text": {
				"type": "mrkdwn",
				"text": "Please select an option:"
			}
		},
		{
			"type": "actions",
			"elements": [
				{
					"type": "button",
					"text": {
						"type": "plain_text",
						"text": ":repeat: Reinstate",
						"emoji": true
					},
					"value": "reinstate",
					"action_id": "reinstate-action"
				},
				{
					"type": "button",
					"text": {
						"type": "plain_text",
						"text": ":relieved: OK",
						"emoji": true
					},
					"value": "ok",
					"action_id": "ok-action"
				}
			]
		}
	]
}



================================================
FILE: github_copilot_seats/seats.py
================================================
"""Manage GitHub Copilot seat assignments within an organization.

It identifies inactive users and prunes their seats,
but allow the users to get them back via Slack.
"""

from datetime import datetime, timedelta, UTC
import json
import os
from pathlib import Path

import autokitteh
from autokitteh.github import github_client
from autokitteh.slack import slack_client

from users import github_username_to_slack_user_id


GITHUB_ORG_NAME = os.getenv("github_conn__target_name", "")
IDLE_HOURS_THRESHOLD = int(os.getenv("IDLE_HOURS_THRESHOLD", "72"))
MANAGED_LOGINS = os.getenv("MANAGED_LOGINS")

github = github_client("github_conn")
org = github.get_organization(GITHUB_ORG_NAME)
copilot = org.get_copilot()

slack = slack_client("slack_conn")


def find_idle_seats(*, prune: bool = False) -> list[dict[str, str]]:
    """Identifies idle GitHub Copilot users based on their last activity time.

    If `prune` is set to `True`, it also cancels their seat assignments and
    interacts with the users asynchronously to confirm this action.
    """
    idle_seats = []
    for seat in copilot.get_seats():
        # If the project is limited to specific org users, ignore the rest.
        managed_logins = MANAGED_LOGINS.split(",") if MANAGED_LOGINS else []
        if managed_logins and seat.assignee.login not in managed_logins:
            print(f"Skipping unmanaged user: {seat.assignee.login}")
            continue

        # Was the assigned seat being used recently?
        now = datetime.now(UTC)
        delta = now - seat.last_activity_at
        is_active = delta < timedelta(hours=IDLE_HOURS_THRESHOLD)

        comparison = "<" if is_active else ">="
        status = f"{seat.assignee.login}: {now} - {seat.last_activity_at} = "
        status += f"{delta} {comparison} {IDLE_HOURS_THRESHOLD} hours"
        print(status)

        if is_active:
            continue

        # Convert the non-serializable "CopilotSeat" object into a simple dictionary.
        simple_seat = {
            "assignee_login": seat.assignee.login,
            "last_activity_at": seat.last_activity_at.isoformat(),
        }
        idle_seats.append(simple_seat)

        # Interact with the user asynchronously in a child workflow.
        if prune:
            autokitteh.start(loc="seats.py:prune_idle_seat", data=simple_seat)

    return idle_seats


def prune_idle_seat(seat: dict[str, str]) -> None:
    """Interacts via Slack with a GitHub user assigned to an idle Copilot seat.

    Note:
        This function is designed to run as a child workflow, by calling:
        autokitteh.start(loc="seats.py:prune_idle_seat", data={...})

    Args:
        seat: Username and last activity timestamp of the GitHub user to which
            the Copilot seat is assigned.
    """
    github_login = seat.data["assignee_login"]
    report(github_login, "removing seat")
    copilot.remove_seats([github_login])

    slack_id = github_username_to_slack_user_id(github_login)
    if not slack_id:
        print(f"No Slack user found for GitHub user {github_login}")
        return

    report(github_login, "notifying user")

    # Load a blocks-based interactive message template
    # from a JSON file and post it to the user's Slack.
    blocks = json.loads(Path("message.json").read_text())["blocks"]
    slack.chat_postMessage(channel=slack_id, blocks=blocks)

    # Subscribe to Slack interaction events, waiting for the user's response.
    filter = f"event_type == 'interaction' && data.user.id == '{slack_id}'"
    subscription = autokitteh.subscribe("slack_conn", filter)

    # Retrieve the value from the user's response in the Slack event.
    value = autokitteh.next_event(subscription)["actions"][0]["value"]

    # The user's response either confirms the action or reinstates the seat.
    match value:
        case "ok":
            report(github_login, "ok")
            msg = "Okey dokey!"
        case "reinstate":
            report(github_login, "reinstate")
            copilot.add_seats([github_login])
            msg = "You have been reinstated to the Copilot program."
        case _:
            report(github_login, f"weird response: {value}")
            msg = f"Response: `{value}` not recognized."

    slack.chat_postMessage(channel=slack_id, text=msg)


def report(github_login: str, msg: str) -> None:
    channel = os.getenv("SLACK_LOG_CHANNEL")
    if channel:
        slack.chat_postMessage(channel=channel, text=f"{github_login}: {msg}")



================================================
FILE: github_copilot_seats/triggers.py
================================================
"""Manage scheduled tasks and Slack commands for idle seat management."""

from autokitteh.slack import slack_client

import seats


def on_schedule() -> None:
    for seat in seats.find_idle_seats(prune=True):
        print(seat)


def on_slack_slash_command(event) -> None:
    find_seats = True
    match event.data.text.lower():
        case "prune-idle-copilot-seats":
            prune = True
        case "find-idle-copilot-seats":
            prune = False
        case _:
            find_seats = False

    if find_seats:
        idle_seats = seats.find_idle_seats(prune=prune)
        action = "Pruned" if prune else "Found"
        msg = f"{action} {len(idle_seats)} idle seats for these users: "
        msg += ", ".join(_get_logins(idle_seats))
    else:
        msg = "Error: unrecognized command"

    slack_client("slack_conn").chat_postEphemeral(
        channel=event.data.channel_id, user=event.data.user_id, text=msg
    )


def _get_logins(idle_seats: list[dict[str, str]]) -> list[str]:
    return [seat["assignee_login"] for seat in idle_seats]



================================================
FILE: github_copilot_seats/users.py
================================================
"""User-related helper functions across GitHub and Slack.

Based on: https://github.com/autokitteh/kittehub/blob/main/purrr/users.py
"""

from autokitteh.github import github_client
from autokitteh.slack import slack_client
from slack_sdk.errors import SlackApiError


github = github_client("github_conn")
slack = slack_client("slack_conn")


def github_username_to_slack_user_id(github_username: str) -> str:
    """Convert a GitHub username to a Slack user ID, or "" if not found.

    This function tries to match the email address first, and then
    falls back to matching the user's full name (case-insensitive).
    """
    user = github.get_user(github_username)

    # Special case: GitHub bots can't have Slack identities.
    if user.type == "Bot":
        return ""

    # Try to match by the email address first.
    if user.email:
        slack_user_id = _email_to_slack_user_id(user.email)
        if slack_user_id:
            return slack_user_id

    # Otherwise, try to match by the user's full name.
    github_name = (user.name or "").lower()
    if not github_name:
        return ""

    for user in _slack_users():
        profile = user.get("profile", {})
        real_name = profile.get("real_name", "").lower()
        normalized_name = profile.get("real_name_normalized", "").lower()
        if github_name in (real_name, normalized_name):
            return user.get("id", "")

    return ""


def _email_to_slack_user_id(email: str) -> str:
    """Convert an email address to a Slack user ID, or "" if not found."""
    try:
        resp = slack.users_lookupByEmail(email=email)
        return resp.get("user", {}).get("id", "")
    except SlackApiError:
        return ""


def _slack_users() -> list[dict]:
    """Return a list of all Slack users in the workspace."""
    users = []
    next_cursor = None
    while next_cursor != "":
        try:
            resp = slack.users_list(cursor=next_cursor, limit=100)
            users += resp.get("members", [])
            next_cursor = resp.get("response_metadata", {}).get("next_cursor", "")
        except SlackApiError:
            next_cursor = ""

    return users



================================================
FILE: github_marketplace_to_slack/README.md
================================================
title: GitHub Marketplace to Slack
description: Forward GitHub Marketplace notifications to Slack
integrations: ["github", "slack"]
categories: ["CRM"]
tags: ["webhook_handling", "notifications", "data_processing"]



================================================
FILE: github_marketplace_to_slack/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that forwards GitHub Marketplace webhook
# notifications to a Slack channel.

version: v1

project:
  name: github_marketplace_to_slack

  vars:
    - name: GITHUB_WEBHOOK_SECRET
      secret: true
      value:
    - name: SLACK_CHANNEL_NAME_OR_ID
      value: github-marketplace

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: webhook_notification
      type: webhook
      event_type: post
      call: program.py:on_webhook_notification



================================================
FILE: github_marketplace_to_slack/program.py
================================================
"""Forward GitHub Marketplace webhook notifications to a Slack channel.

GitHub API documentation:
- https://docs.github.com/en/apps/github-marketplace/listing-an-app-on-github-marketplace/configuring-a-webhook-to-notify-you-of-plan-changes
- https://docs.github.com/en/webhooks/webhook-events-and-payloads#marketplace_purchase
- https://docs.github.com/en/webhooks/webhook-events-and-payloads#ping
"""

import hashlib
import hmac
import json
import os

import autokitteh
from autokitteh.slack import slack_client


def on_webhook_notification(event):
    """Handle GitHub Marketplace webhook notifications.

    Args:
        event: Incoming HTTP request data.
    """
    headers = event.data.headers

    secret = os.getenv("GITHUB_WEBHOOK_SECRET", "")
    signature = headers.get("X-Hub-Signature-256", "")
    _verify_signature(event.data.body.bytes, secret, signature)

    # https://docs.github.com/en/webhooks/webhook-events-and-payloads#delivery-headers
    msg = f"*GitHub Marketplace event:* `{headers.get('X-Github-Event', '???')}`\n"
    msg += f"(Resource ID `{headers.get('X-Github-Hook-Installation-Target-Id')}`, "
    msg += f"webhook ID `{headers.get('X-Github-Hook-Id')}`, "
    msg += f"event ID `{headers.get('X-Github-Delivery')}`)\n"

    # https://docs.github.com/en/webhooks/webhook-events-and-payloads#marketplace_purchase
    # https://docs.github.com/en/webhooks/webhook-events-and-payloads#ping
    msg += f"```{json.dumps(event.data.body.json, indent=4)}```"

    channel = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")
    slack_client("slack_conn").chat_postMessage(channel=channel, text=msg)


@autokitteh.activity
def _verify_signature(payload: bytes, secret: str, signature: str):
    """Verify that the payload was sent from GitHub by validating its SHA-256 signature.

    Based on:
    https://docs.github.com/en/webhooks/using-webhooks/validating-webhook-deliveries

    Args:
        payload: Original request body to verify.
        secret: GitHub Marketplace webhook secret of the GitHub app.
        signature: HTTP header received from GitHub ("X-Hub-Signature-256").

    Raises:
        RuntimeError: If the signature is missing or doesn't match the expected value.
    """
    if not signature:
        raise RuntimeError("'X-Hub-Signature-256' HTTP header is missing!")

    hash = hmac.new(secret.encode("utf-8"), msg=payload, digestmod=hashlib.sha256)
    expected = "sha256=" + hash.hexdigest()
    if not hmac.compare_digest(expected, signature):
        raise RuntimeError("Request signatures didn't match!")



================================================
FILE: gocat/README.md
================================================
title: Gocat - URL Shortener & Redirector
description: Simple URL shortener using Google Sheets as a data store with webhook-based redirection
integrations: ["googlesheets"]
categories: ["Productivity"]
tags: ["webhook_handling", "sync_responses"]



================================================
FILE: gocat/autokitteh.yaml
================================================
version: v2

project:
  name: gocat

  vars:
    - name: GOOGLE_SPREADSHEET_ID
      value: ""
      description: >
        The ID of the Google Spreadsheet to read the directory data from.
        You can find this ID in the URL of the spreadsheet.
    - name: DIRECTORY_SHEET_NAME
      value: ""
      description: >
        The name of the sheet within the Google Spreadsheet that contains the directory data.
        If empty, the first sheet will be used.

  connections:
    - name: gsheets
      integration: googlesheets

  triggers:
    - name: webhook
      type: webhook
      call: handlers.py:on_webhook
      event_type: get
      is_sync: true



================================================
FILE: gocat/handlers.py
================================================
"""gocat handlers.

This module provides webhook handlers for the gocat URL shortener/redirector service.
It processes incoming webhook requests and redirects them to stored URLs based on path
matching.
"""

from urllib.parse import urljoin

from autokitteh import Event, http_outcome
import store


def _extract_suffix(path: str) -> str:
    """Extract the suffix portion from a webhook path.

    The expected path format is: /webhooks/<slug>/<suffix>
    This function extracts and returns the <suffix> part.

    >>> _extract_suffix("/webhooks/myslug/docs/api")
    "docs/api"
    >>> _extract_suffix("/webhooks/myslug")
    ""

    Args:
        path: The full URL path from the webhook request

    Returns:
        The suffix portion of the path (everything after the slug), or empty string if
        no suffix

    Raises:
        ValueError: If the path doesn't have at least 2 parts when split by '/'
    """
    # Remove leading slash if present
    if path.startswith("/"):
        path = path[1:]

    # Split path into parts: ['webhooks', '<slug>', '<suffix>']
    parts = path.split("/", 2)
    if len(parts) < 2:
        raise ValueError("Invalid path, expecting /webhooks/<slug>/<suffix>")

    # Return suffix (third part) if it exists, otherwise empty string
    return parts[2] if len(parts) > 2 else ""


def on_webhook(event: Event):
    """Handle incoming webhook events and redirect to stored URLs.

    This is the main webhook handler that processes incoming requests and performs
    URL lookups and redirections based on the path suffix.

    Behavior:
    - No suffix: Redirects to the Google Spreadsheet (302)
    - One match: Redirects to the matched URL (302)
    - Multiple matches: Returns an HTML page with all matching links (200)
    - No matches: Returns 404 error
    """
    # Extract the suffix from the URL path (everything after the slug)
    suffix = _extract_suffix(event.data.url.path)

    print(f"path suffix: '{suffix}'")

    if not suffix:
        # Redirect to the spreadsheet URL if no suffix is provided.
        loc = store.spreadsheet_url()
        print(f"no suffix provided, redirecting to {loc}")
        http_outcome(302, headers={"Location": loc})
        return

    # Split the suffix into first part (search key) and remaining path
    parts = suffix.split("/", 1)

    # first = the search key to look up in the store
    # second = any additional path to append to the matched URL
    first, second = parts[0], parts[1] if len(parts) > 1 else ""

    # Search for matching URLs in the store
    results = store.find(first)

    match results:
        case []:
            print("no matches found")
            http_outcome(404, body="No matches found")
            return

        case [result]:
            # If there's an additional path, append it to the result URL
            if second:
                # Ensure the base URL ends with a slash before joining
                if not result.endswith("/"):
                    result += "/"
                loc = urljoin(result, second)
            else:
                loc = result

            print(f"single match found: {result} -> {loc}")

            http_outcome(302, headers={"Location": loc})
            return

        case _:
            print("multiple matches found:\n- " + "\n- ".join(results))

            links = "\n\t\t".join(
                f'<li><a href="{url}">{url}</a></li>' for url in results
            )

            body = f"""<html>
    <head>
        <title>Multiple matches</title>
    </head>
    <body>
        <h1>Multiple matches for '{first}'</h1>
        <ul>
            {links}
        </ul>
    </body>
</html>"""

            http_outcome(200, body=body, headers={"Content-Type": "text/html"})
            return



================================================
FILE: gocat/Makefile
================================================
UVX=uvx --with autokitteh --with gspread

.PHONY: all
all: lint typecheck format

.PHONY: lint
lint:
	$(UVX) ruff check --config ../pyproject.toml --ignore I001

.PHONY: format
format:
	$(UVX) ruff format --check --config ../pyproject.toml

.PHONY: typecheck
typecheck:
	$(UVX) mypy --follow-untyped-imports  .


.PHONY: deploy
deploy:
	ak deploy --manifest autokitteh.yaml



================================================
FILE: gocat/store.py
================================================
"""Store module for managing URL mappings in Google Sheets.

This module provides an interface to a Google Spreadsheet that acts as a data store
for URL mappings. It reads short keys from column 1 and their corresponding full URLs
from column 2.

Required environment variables:
- GOOGLE_SPREADSHEET_ID: The ID of the Google Spreadsheet to use as the data store
- DIRECTORY_SHEET_NAME: (Optional) The name of the sheet to use. Defaults to the first
  sheet.
"""

from os import getenv

from autokitteh.google import gspread_client
import gspread


# Get the Google Spreadsheet ID from environment variable (required)
_GOOGLE_SPREADSHEET_ID = getenv("GOOGLE_SPREADSHEET_ID")
if not _GOOGLE_SPREADSHEET_ID:
    raise RuntimeError("GOOGLE_SPREADSHEET_ID not set")

# Get the sheet name from environment variable (optional, defaults to first sheet)
_DIRECTORY_SHEET_NAME = getenv("DIRECTORY_SHEET_NAME")

# Initialize the Google Sheets client and open the spreadsheet
_client = gspread_client("gsheets").open_by_key(_GOOGLE_SPREADSHEET_ID)


def spreadsheet_url() -> str:
    """Get the URL of the Google Spreadsheet."""
    return f"https://docs.google.com/spreadsheets/d/{_GOOGLE_SPREADSHEET_ID}"


def _index_sheet() -> gspread.Worksheet:
    """Get the index sheet containing the URL mappings.

    Returns the worksheet specified by DIRECTORY_SHEET_NAME environment variable,
    or the first sheet if not specified.
    """
    return (
        _client.worksheet(_DIRECTORY_SHEET_NAME)
        if _DIRECTORY_SHEET_NAME
        else _client.sheet1
    )


def find(path: str) -> list[str]:
    """Find all matching URLs for the given path in the index sheet.

    Searches column 1 of the sheet for cells matching the given path, then returns
    the corresponding URLs from column 2.

    The spreadsheet format should be:
    - Column 1: Short keys/identifiers
    - Column 2: Full URLs

    Args:
        path: The search key to look up in column 1

    Returns:
        A list of matching URLs from column 2. Empty list if no matches found.
        Filters out any None or empty values.

    Example:
        If the sheet contains:
        | docs | https://example.com/docs |
        | docs | https://example.org/docs |

        Then find("docs") returns:
        ["https://example.com/docs", "https://example.org/docs"]
    """
    sheet = _index_sheet()
    rows = [cell.row for cell in sheet.findall(path, in_column=1)]
    cells = [sheet.cell(row, 2) for row in rows]
    results = [cell.value for cell in cells if cell]
    return [r for r in results if r]



================================================
FILE: gocat/_extension/README.md
================================================



================================================
FILE: gocat/_extension/background.js
================================================
// Get the base URL from storage (no default)
async function getBaseUrl() {
  const result = await chrome.storage.sync.get(["baseUrl"]);
  return result.baseUrl; // Will be undefined if not set
}

// Check if extension is configured
async function isConfigured() {
  const baseUrl = await getBaseUrl();
  return baseUrl && baseUrl.trim() !== "";
}

// Show setup notification
function showSetupNotification() {
  chrome.notifications.create({
    type: "basic",
    iconUrl:
      "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDgiIGhlaWdodD0iNDgiIHZpZXdCb3g9IjAgMCA0OCA0OCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMjQiIGN5PSIyNCIgcj0iMjAiIGZpbGw9IiM0Mjg1ZjQiLz4KPHN2ZyB3aWR0aD0iNDgiIGhlaWdodD0iNDgiIHZpZXdCb3g9IjAgMCA0OCA0OCIgZmlsbD0ibm9uZSI+CjxwYXRoIGQ9Ik0yNCAzNlYyNE0yNCAyNEwyNCAyNE0yNCAyNEwyNCAyNE0yNCAyNEwyNCAyNE0yNCAyNEwyNCAyNCIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KPC9zdmc+",
    title: "Go Links Setup Required",
    message: "Please configure your base URL in the extension options first.",
  });
}

// Update redirect rules when base URL changes
async function updateRedirectRules() {
  const baseUrl = await getBaseUrl();

  // Remove existing rules
  const existingRules = await chrome.declarativeNetRequest.getDynamicRules();
  const ruleIdsToRemove = existingRules.map((rule) => rule.id);

  await chrome.declarativeNetRequest.updateDynamicRules({
    removeRuleIds: ruleIdsToRemove,
    addRules: [], // Remove all rules initially
  });

  // Only add rule if baseUrl is configured
  if (baseUrl && baseUrl.trim() !== "") {
    const newRules = [
      {
        id: 1,
        priority: 1,
        action: {
          type: "redirect",
          redirect: {
            regexSubstitution: baseUrl + "\\1",
          },
        },
        condition: {
          regexFilter: "^https?://go/(.*)$",
          resourceTypes: ["main_frame", "sub_frame"],
        },
      },
    ];

    await chrome.declarativeNetRequest.updateDynamicRules({
      removeRuleIds: [],
      addRules: newRules,
    });
  }
}

// Handle omnibox input (for "go<space>whatever" in address bar)
chrome.omnibox.onInputEntered.addListener(async function (text) {
  const configured = await isConfigured();

  if (!configured) {
    // Open options page if not configured
    chrome.runtime.openOptionsPage();
    return;
  }

  const baseUrl = await getBaseUrl();
  const redirectUrl = baseUrl + text;
  chrome.tabs.update({ url: redirectUrl });
});

// Handle extension icon clicks to open options if not configured
chrome.action.onClicked.addListener(async function () {
  const configured = await isConfigured();

  if (!configured) {
    chrome.runtime.openOptionsPage();
  } else {
    // Could show a popup or just open options anyway
    chrome.runtime.openOptionsPage();
  }
});

// Initialize rules on startup
chrome.runtime.onStartup.addListener(updateRedirectRules);
chrome.runtime.onInstalled.addListener(async function (details) {
  await updateRedirectRules();

  // Show setup notification on first install
  if (details.reason === "install") {
    const configured = await isConfigured();
    if (!configured) {
      chrome.runtime.openOptionsPage();
    }
  }
});

// Listen for storage changes to update rules
chrome.storage.onChanged.addListener((changes, namespace) => {
  if (namespace === "sync" && changes.baseUrl) {
    updateRedirectRules();
  }
});



================================================
FILE: gocat/_extension/manifest.json
================================================
{
  "manifest_version": 3,
  "name": "GoCat Links",
  "version": "1.0",
  "description": "Personal go links for quick navigation",
  "permissions": ["storage", "declarativeNetRequest", "notifications"],
  "host_permissions": ["http://go/*", "https://go/*"],
  "omnibox": { "keyword": "go" },
  "background": {
    "service_worker": "background.js"
  },
  "action": {},
  "options_ui": {
    "page": "options.html",
    "open_in_tab": true
  },
  "declarative_net_request": {
    "rule_resources": [
      {
        "id": "go_links_rules",
        "enabled": true,
        "path": "rules.json"
      }
    ]
  }
}



================================================
FILE: gocat/_extension/options.html
================================================
<!DOCTYPE html>
<html>
  <head>
    <title>Go Links Options</title>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          sans-serif;
        max-width: 600px;
        margin: 20px auto;
        padding: 20px;
        line-height: 1.6;
      }
      .container {
        background: #f9f9f9;
        padding: 20px;
        border-radius: 8px;
        border: 1px solid #ddd;
      }
      .setup-required {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 15px;
        border-radius: 4px;
        margin-bottom: 20px;
      }
      label {
        display: block;
        margin-bottom: 8px;
        font-weight: 500;
      }
      input[type="url"] {
        width: 100%;
        padding: 10px;
        border: 1px solid #ccc;
        border-radius: 4px;
        font-size: 14px;
        box-sizing: border-box;
      }
      button {
        background: #4285f4;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 4px;
        cursor: pointer;
        font-size: 14px;
        margin-top: 10px;
      }
      button:hover {
        background: #3367d6;
      }
      button:disabled {
        background: #ccc;
        cursor: not-allowed;
      }
      .status {
        margin-top: 10px;
        padding: 8px;
        border-radius: 4px;
        display: none;
      }
      .status.success {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
      }
      .status.error {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
      }
      .examples {
        margin-top: 20px;
        padding: 15px;
        background: #e8f4f8;
        border-radius: 4px;
      }
      .examples h3 {
        margin-top: 0;
      }
      .examples code {
        background: #f1f1f1;
        padding: 2px 4px;
        border-radius: 3px;
      }
      .current-config {
        margin-top: 15px;
        padding: 10px;
        background: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 4px;
      }
      .current-config.not-configured {
        background: #f8d7da;
        border: 1px solid #f5c6cb;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Go Links Setup</h1>

      <div id="setupRequired" class="setup-required">
        <strong>‚ö†Ô∏è Setup Required:</strong> You must configure a base URL before
        Go Links will work.
      </div>

      <div id="currentConfig" class="current-config not-configured">
        <strong>Status:</strong> <span id="configStatus">Not configured</span>
      </div>

      <label for="baseUrl">Base URL (required):</label>
      <input
        type="url"
        id="baseUrl"
        placeholder="https://wiki.company.com/"
        required
      />

      <button id="save">Save Settings</button>

      <div id="status" class="status"></div>

      <div class="examples">
        <h3>Examples:</h3>
        <p>
          <strong>Company Wiki:</strong> <code>https://wiki.company.com/</code>
        </p>
        <p>
          <strong>Development Server:</strong>
          <code>https://localhost:3000/</code>
        </p>
        <p>
          <strong>Internal Tools:</strong>
          <code>https://internal.company.com/tools/</code>
        </p>

        <h3>How it works:</h3>
        <p>With base URL <code>https://wiki.company.com/</code>:</p>
        <ul>
          <li>
            <code>http://go/docs</code> ‚Üí
            <code>https://wiki.company.com/docs</code>
          </li>
          <li>
            <code>go api</code> (in address bar) ‚Üí
            <code>https://wiki.company.com/api</code>
          </li>
        </ul>
      </div>
    </div>

    <script src="options.js"></script>
  </body>
</html>



================================================
FILE: gocat/_extension/options.js
================================================
// Load saved settings and update UI
document.addEventListener("DOMContentLoaded", async function () {
  const result = await chrome.storage.sync.get(["baseUrl"]);
  const baseUrl = result.baseUrl;

  const baseUrlInput = document.getElementById("baseUrl");
  const setupRequired = document.getElementById("setupRequired");
  const currentConfig = document.getElementById("currentConfig");
  const configStatus = document.getElementById("configStatus");

  if (baseUrl && baseUrl.trim() !== "") {
    baseUrlInput.value = baseUrl;
    setupRequired.style.display = "none";
    currentConfig.className = "current-config";
    configStatus.textContent = `Configured: ${baseUrl}`;
  } else {
    setupRequired.style.display = "block";
    currentConfig.className = "current-config not-configured";
    configStatus.textContent = "Not configured - Go Links will not work";
  }
});

// Save settings
document.getElementById("save").addEventListener("click", async function () {
  const baseUrl = document.getElementById("baseUrl").value.trim();

  // Validation
  if (!baseUrl) {
    showStatus("Please enter a base URL", false);
    return;
  }

  try {
    new URL(baseUrl); // Validate URL format
  } catch (e) {
    showStatus("Please enter a valid URL (including https://)", false);
    return;
  }

  // Ensure URL ends with /
  const finalUrl = baseUrl.endsWith("/") ? baseUrl : baseUrl + "/";

  // Save to storage
  await chrome.storage.sync.set({ baseUrl: finalUrl });

  // Update UI
  const setupRequired = document.getElementById("setupRequired");
  const currentConfig = document.getElementById("currentConfig");
  const configStatus = document.getElementById("configStatus");

  setupRequired.style.display = "none";
  currentConfig.className = "current-config";
  configStatus.textContent = `Configured: ${finalUrl}`;

  showStatus("Settings saved successfully! Go Links is now active.", true);
});

// Handle Enter key in input field
document.getElementById("baseUrl").addEventListener("keypress", function (e) {
  if (e.key === "Enter") {
    document.getElementById("save").click();
  }
});

function showStatus(message, isSuccess) {
  const status = document.getElementById("status");
  status.textContent = message;
  status.className = `status ${isSuccess ? "success" : "error"}`;
  status.style.display = "block";

  // Hide after 3 seconds
  setTimeout(() => {
    status.style.display = "none";
  }, 3000);
}



================================================
FILE: gocat/_extension/rules.json
================================================
[]



================================================
FILE: google_cal_to_asana/README.md
================================================
title: Google Calendar To Asana
description: Creates Asana tasks based on Google Calendar events
integrations: ["googlecalendar", "asana"]
categories: ["Productivity"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: google_cal_to_asana/autokitteh.yaml
================================================
# This YAML file defines a declarative manifest for an AutoKitteh project that
# creates Asana tasks from Google Calendar events.

version: v1

project:
  name: google_cal_to_asana

  vars:
    - name: ASANA_PROJECT_GID
      value:

  connections:
    - name: asana_conn
      integration: asana
    - name: google_conn
      integration: googlecalendar

  triggers:
    - name: gcal_event_created
      connection: google_conn
      event_type: event_created
      call: program.py:on_calendar_event_created



================================================
FILE: google_cal_to_asana/program.py
================================================
"""Create a new Asana task when a new event is created in Google Calendar."""

import os

import asana
from asana.rest import ApiException
from autokitteh.asana import asana_client


ASANA_PROJECT_GID = os.getenv("ASANA_PROJECT_GID")

api_client = asana_client("asana_conn")
tasks_api_instance = asana.TasksApi(api_client)


def on_calendar_event_created(event):
    """This is the workflow entry point."""
    # Extract relevant information from the Google Calendar event.
    task_name = event.data.get("summary", "New Task")
    due_date = event.data.get("start", {}).get("date_time")
    description = event.data.get("description", "")

    create_asana_task(task_name, due_date, description)


def create_asana_task(task_name, due_date, description):
    """Create a new task in Asana.

    See:
        https://github.com/Asana/python-asana/blob/v5.0.10/docs/TasksApi.md#create_task
    """
    body = {
        "data": {
            "name": task_name,
            "projects": [ASANA_PROJECT_GID],  # More than one project can be added.
            "due_on": due_date,
            "notes": description,
        }
    }

    opts = {"opt_fields": "name,assignee.name,due_on,created_at,projects.name,notes"}

    try:
        task = tasks_api_instance.create_task(body, opts)
        print(task)
    except ApiException as e:
        print(f"Exception when calling TasksApi->create_task: {e}")



================================================
FILE: google_forms_to_jira/README.md
================================================
title: Create Jira ticket from Google form
description: Create and update Jira tickets automatically from Google Forms responses
integrations: ["googleforms", "jira"]
categories: ["DevOps"]
tags: ["webhook_handling", "data_processing", "state_management", "notifications"]



================================================
FILE: google_forms_to_jira/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of an
# AutoKitteh project that creates Jira issues based on Google Forms responses.

version: v1

project:
  name: google_forms_to_jira
  vars:
    - name: JIRA_PROJECT_KEY
      value:

  connections:
    - name: forms_conn
      integration: googleforms
    - name: jira_conn
      integration: jira

  triggers:
    - name: google_forms_response
      connection: forms_conn
      event_type: responses
      call: program.py:on_form_response



================================================
FILE: google_forms_to_jira/program.py
================================================
"""Create Jira issues based on Google Forms responses.

Atlassian Jira API documentation:
- https://docs.autokitteh.com/integrations/atlassian/jira/python

Google Forms API documentation:
- https://docs.autokitteh.com/integrations/google/forms/events
"""

import os

from autokitteh import google
from autokitteh.atlassian import jira_client


JIRA_PROJECT_KEY = os.getenv("JIRA_PROJECT_KEY")

jira = jira_client("jira_conn")


def on_form_response(event):
    print("Form response submitted:", event.data)
    response_id = event.data.response.response_id

    forms = google.google_forms_client("forms_conn").forms()
    questions = forms.get(formId=event.data.form_id).execute().get("items", [])

    answers = _summarize_form_response(event.data.response.answers, questions)

    # Check if a Jira issue already exists for this response (i.e. response edited).
    query = f"project = {JIRA_PROJECT_KEY} AND description ~ {response_id}"
    issues = jira.jql(query + " ORDER BY created DESC")
    if issues.get("total", 0) == 0:
        _create_jira_issue(answers, response_id)
    else:
        _update_jira_issue(issues["issues"][0], answers, response_id)


def _summarize_form_response(answers, questions):
    """Extract answers from response, and match with form questions."""
    summary = []
    for i, question in enumerate(questions, start=1):
        question_id = question["questionItem"]["question"]["questionId"]
        title = question.get("title", "Untitled question")

        if question_id not in answers:
            summary.append(f"{i}. {title}:\nNot answered")
        else:
            answer = answers[question_id]["text_answers"]["answers"][0]["value"]
            summary.append(f"{i}. {title}:\n{answer}")

    return summary


def _create_jira_issue(answers, response_id):
    fields = {
        "project": {"key": JIRA_PROJECT_KEY},
        "issuetype": {"name": "Task"},
        "summary": "Response to Google Form",
        "description": "\n\n".join(answers) + f"\n\n(Response ID: {response_id})",
    }
    issue = jira.create_issue(fields=fields)
    print("Created Jira issue:", issue["key"])


def _update_jira_issue(issue, answers, response_id):
    description = "\n\n".join(answers) + f"\n\n(Response ID: {response_id})"
    jira.update_issue_field(issue["key"], fields={"description": description})
    print("Updated Jira issue:", issue["key"])



================================================
FILE: hackernews/README.md
================================================
title: Hacker News alerts in Slack
description: Track Hacker News articles by topic and send updates to Slack
integrations: ["slack"]
categories: ["Productivity"]
tags: ["user_interactions", "long_running", "data_processing", "notifications", "monitoring", "webhook_handling"]



================================================
FILE: hackernews/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that monitors Hacker News for a specific topic.

version: v1

project:
  name: hackernews_alert

  vars:
    - name: POLLING_INTERVAL_SECS
      value: 120

  connections:
    - name: slack_connection
      integration: slack

  triggers:
    - name: slack_slash_command
      connection: slack_connection
      event_type: app_mention
      call: program.py:on_slack_command



================================================
FILE: hackernews/program.py
================================================
"""Monitor Hacker News for new articles on a specific topic, post updates to Slack."""

import os
import time
import urllib.parse

from autokitteh.slack import slack_client
import requests


API_URL = "http://hn.algolia.com/api/v1/search_by_date?tags=story&page=0&query="
POLLING_INTERVAL_SECS = int(os.getenv("POLLING_INTERVAL_SECS", "120"))

slack = slack_client("slack_connection")


def on_slack_command(event):
    """Workflow's entry-point.

    Extracts a topic from a Slack command, monitors for new articles,
    and posts updates to the same Slack channel.
    """
    topic = event.data.text.split(" ", 1)[-1].strip()
    slack.chat_postMessage(
        channel=event.data.channel,
        text=f"Waiting for new articles on the topic: `{topic}`.",
    )
    current_articles = set()
    fetch_articles(topic, current_articles)

    # NOTE: For low-traffic topics, it might take a while for new articles to
    # be published, so users may experience delays in receiving notifications.
    while True:
        all_articles = set(current_articles)
        fetch_articles(topic, all_articles)
        new_articles = all_articles - current_articles

        for article in new_articles:
            _, title, url = article
            slack_message = f"Title: {title}, URL: {url if url else 'No URL'}"
            slack.chat_postMessage(channel=event.data.channel, text=slack_message)
        current_articles.update(new_articles)

        time.sleep(POLLING_INTERVAL_SECS)


def fetch_articles(topic, all_articles):
    encoded_query = urllib.parse.quote(topic)
    full_url = f"{API_URL}{encoded_query}"
    hits = requests.get(full_url, timeout=10).json().get("hits", [])

    # Extract some of the article fields from the API response.
    for article in hits:
        object_id = article["objectID"]
        title = article["title"]
        url = article.get("url")
        all_articles.add((object_id, title, url))



================================================
FILE: invoice_processing/README.md
================================================
title: Invoice processing system
description: Process emails for invoices, extract data, and generate reports
integrations: ["gmail", "chatgpt"]
categories: ["AI", "Productivity"]
tags: ["next_event", "subscribe", "webhook_handling", "long_running", "data_processing", "timeout_handling", "notifications"]



================================================
FILE: invoice_processing/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that processes emails to detect invoices
# and generate structured reports.

version: v1

project:
  name: invoice_project

  vars:
    - name: POLLING_INTERVAL_MINUTES
      value: 30
    - name: START_DATE
      value:

  connections:
    - name: gmail_conn
      integration: gmail
    - name: openai_conn
      integration: chatgpt

  triggers:
    - name: process_invoices
      type: webhook
      call: program.py:main
    - name: send_mail
      type: webhook



================================================
FILE: invoice_processing/openAI_handling.py
================================================
"""Functions to create AI files, create threads, and send requests to the OpenAI API."""

import base64
import binascii
import io
import time

import autokitteh
from autokitteh.openai import openai_client
import requests


chatgpt = openai_client("openai_conn")


def create_ai_file(attachment, vector_store_id):
    """Create an AI file from an attachment for OpenAI processing."""
    try:
        if attachment["data"].startswith("data:"):
            # Extract base64 data after the comma.
            _, data = attachment["data"].split(",", 1)
            file_data = base64.b64decode(data)
        else:
            # Handle regular base64 data.
            file_data = base64.b64decode(attachment["data"])

        file_stream = io.BytesIO(file_data)
        file_stream.name = attachment["filename"]

        file_stream.seek(0)

        # Create file for assistant.
        message_file = chatgpt.files.create(file=file_stream, purpose="assistants")
        file_stream.close()
        return message_file

    except ValueError as e:
        print(f"Error creating AI file: {str(e)}")
        return None


def create_thread(content, attachments, assistant, response_schema):
    """Create an OpenAI thread, run the assistant, and get the response."""
    try:
        # Create thread with user message.
        thread = chatgpt.beta.threads.create(
            messages=[
                {
                    "role": "user",
                    "content": content,
                    "attachments": attachments,
                }
            ]
        )

        # Run the assistant on the thread.
        run = chatgpt.beta.threads.runs.create(
            thread_id=thread.id,
            assistant_id=assistant.id,
            response_format=response_schema,
        )

        # Poll for completion.
        while True:
            run_status = chatgpt.beta.threads.runs.retrieve(
                thread_id=thread.id, run_id=run.id
            )
            if run_status.status == "completed":
                break
            elif run_status.status in ["failed", "cancelled", "expired"]:
                print(f"Run failed - {run_status.status}")
                return None

            time.sleep(5)  # Reduced polling interval.

        # Get the assistant's response.
        ai_messages = chatgpt.beta.threads.messages.list(thread_id=thread.id)

        assistant_message = next(
            (msg for msg in ai_messages.data if msg.role == "assistant"), None
        )

        if assistant_message and assistant_message.content:
            return assistant_message.content[0].text.value

    except requests.exceptions.RequestException as e:
        print(f"Network error: {str(e)}")

    return None


@autokitteh.activity
def send_ai_request(
    message_body, message_attachments, message_images, ai_request, response_schema
):
    """Send a request to the OpenAI API with message content and attachments"""
    # Early return if no content to analyze.
    if not message_body and not message_attachments and not message_images:
        print("No content to analyze")
        return False

    # Create a temporary file from the message body.
    temp_file_path = f"message_{int(time.time())}.txt"
    temp_file = {
        "filename": temp_file_path,
        "data": base64.b64encode(message_body.encode("utf-8")).decode("utf-8"),
    }

    # Create assistant with explicit model version.
    assistant = chatgpt.beta.assistants.create(
        name="Document Analyzer",
        instructions=ai_request,
        model="gpt-4o",  # Use latest model.
        tools=[{"type": "file_search"}],
    )

    # Create vector store for file search.
    vector_store = chatgpt.vector_stores.create(name="Invoice Analysis")

    # Process all files (message body and attachments).
    messages = []

    temp_ai_file = create_ai_file(temp_file, vector_store.id)
    if temp_ai_file:
        messages.append(temp_ai_file)

    for attachment in message_attachments:
        ai_file = create_ai_file(attachment, vector_store.id)
        if ai_file:
            messages.append(ai_file)

    attachments = [
        {"file_id": file.id, "tools": [{"type": "file_search"}]} for file in messages
    ]

    # Prepare content array with instructions.
    content = [{"type": "text", "text": ai_request}]

    # Handle image processing if present.
    if message_images and len(message_images) > 0:
        try:
            image_data = message_images[0]["data"]
            if image_data.startswith("data:"):
                _, base64_data = image_data.split(",", 1)
                image_bytes = base64.b64decode(base64_data)

                image_stream = io.BytesIO(image_bytes)
                image_stream.name = "image.png"

                file = chatgpt.files.create(file=image_stream, purpose="vision")

                content.append(
                    {"type": "image_file", "image_file": {"file_id": file.id}}
                )
                print(f"Image added with file ID: {file.id}")
        except binascii.Error as e:
            print(f"Base64 decoding error: {str(e)}")
        except OSError as e:
            print(f"IO error processing image: {str(e)}")

    # Create thread and get response.
    result = create_thread(content, attachments, assistant, response_schema)
    return result



================================================
FILE: invoice_processing/process_gmails.py
================================================
"""Processes Gmail messages to identify and extract invoice details."""

import base64
import json
import time
import traceback

from autokitteh.google import gmail_client

import openAI_handling
import scan_gmails
import schemas


gmail = gmail_client("gmail_conn").users()


def is_message_invoice(message_body, message_attachments, message_images):
    """Determine if a message contains an invoice."""
    print("Checking if message is an invoice...")

    # Use specific instructions that clearly request a simple True/False response.
    instructions = """
    You are a helper that determines if attached files are an invoice or receipt.
    IMPORTANT: Analyze all files and respond with ONLY 'True' or 'False'.
    - If ANY file is an invoice or receipt, respond with 'True'
    - Otherwise, respond with 'False'
    Do not include any explanations, just True or False.
    """

    # Get the raw text response from AI.
    is_invoice_response = openAI_handling.send_ai_request(
        message_body,
        message_attachments,
        message_images,
        instructions,
        schemas.AI_BOOLEAN_SCHEMA,
    )

    # Handle response as text.
    if not is_invoice_response:
        print("No response received from AI")
        return False

    # Parse text response - accept variations of true/yes.
    cleaned_response = is_invoice_response.strip().lower()

    # Check for positive responses.
    true_indicators = ["true", "yes", "1", "correct", "invoice", "receipt"]

    # Return True if any indicator is found in the response.
    for indicator in true_indicators:
        if indicator in cleaned_response:
            print(f"Found '{indicator}' in response - considering this an invoice")
            return True

    return False


def try_parse_json(response):
    """Attempt to parse JSON response with required invoice fields."""
    try:
        parsed_json = json.loads(response)
    except json.JSONDecodeError:
        parsed_json = {}

    required_keys = ["companyName", "date", "amount", "invoiceId"]
    if not all(key in parsed_json for key in required_keys):
        parsed_json = {}

    return parsed_json


def parse_invoice_to_json(message_body, message_attachments, message_images):
    """Extract invoice details into structured JSON."""
    max_retries = 3

    instructions = """
    Please extract information from the uploaded invoice files (PDF or images).
    For each invoice, extract:
    1. Company name (who issued the invoice)
    2. Invoice date
    3. Total amount (with currency)
    4. Invoice ID or number
    Return ONLY a JSON object with these fields:
    {
      "companyName": "Example Corp",
      "date": "2023-01-15",
      "amount": "$123.45",
      "invoiceId": "INV-12345"
    }
    """

    for attempt in range(max_retries):
        json_invoice = openAI_handling.send_ai_request(
            message_body,
            message_attachments,
            message_images,
            instructions,
            schemas.AI_INVOICE_JSON_SCHEMA,
        )

        if json_invoice:
            parsed_json = try_parse_json(json_invoice)
            if parsed_json:
                return parsed_json

        if attempt < max_retries - 1:
            print(f"Retrying invoice parsing... ({attempt + 1}/{max_retries})")
            time.sleep(2)  # Brief pause before retry.

    return None


def handle_scan(ts):
    """Scan emails since timestamp ts and process for invoices."""
    invoices = []

    try:
        messages = scan_gmails.scan_gmail_messages(ts)

        for idx, msg in enumerate(messages):
            print(f"Processing message {idx + 1}/{len(messages)}")

            # Rate limiting.
            time.sleep(5)

            # Check if message is an invoice.
            is_email_invoice = is_message_invoice(
                msg["body"], msg["attachments"], msg["images"]
            )

            if is_email_invoice:
                # Parse invoice details.
                message_json_parsed = parse_invoice_to_json(
                    msg["body"], msg["attachments"], msg["images"]
                )

                if message_json_parsed:
                    invoices.append(message_json_parsed)
            else:
                print(f"Message {msg['id']} is not an invoice")

    except json.JSONDecodeError as e:
        print(f"Error in handle_scan: {e}")
        traceback.print_exc()

    return invoices


def send_invoices(invoices):
    """Send an email report with processed invoices."""
    try:
        profile = gmail.getProfile(userId="me").execute()

        if not invoices:
            mail_body = "No invoices found for this period."
        else:
            mail_body = json.dumps(invoices, indent=4)

        msg = f"""From: {profile["emailAddress"]}
To: {profile["emailAddress"]}
Subject: Invoice Processing Report

{mail_body}"""

        # Format message for Gmail API
        msg = msg.replace("\n", "\r\n")
        msg = base64.urlsafe_b64encode(msg.encode()).decode()

        gmail.messages().send(userId="me", body={"raw": msg}).execute()
        print("Invoice report sent successfully!")

    except json.JSONDecodeError as e:
        print(f"Unexpected error sending invoice report: {str(e)}")



================================================
FILE: invoice_processing/program.py
================================================
"""Invoice processing system module."""

from datetime import datetime, UTC
import os
import time

import autokitteh

import process_gmails


def main(event):
    """Main entry point for the invoice processing system"""
    invoices = []

    polling_interval = int(os.getenv("POLLING_INTERVAL_MINUTES", "60")) * 60

    start_date = os.getenv("START_DATE")
    if start_date is None:
        start_date = datetime.now(UTC).replace(day=1)
        start_date = start_date.strftime("%Y-%m-%d")

    last_check_time = int(time.mktime(time.strptime(start_date, "%Y-%m-%d")))

    # Subscribe to send_mail events.
    send_mail_webhook = autokitteh.subscribe("send_mail", "true")

    # Initial scan.
    new_invoices = process_gmails.handle_scan(last_check_time)
    invoices.extend(new_invoices)
    last_check_time = int(time.time())

    while True:
        # Wait for send_mail event or timeout.
        send_mail_req = autokitteh.next_event(
            send_mail_webhook, timeout=polling_interval
        )

        if send_mail_req:
            # Send invoice report on demand.
            print("Received send_mail event - sending invoice report")
            process_gmails.send_invoices(invoices)
        else:
            # Check for new invoices.
            new_invoices = process_gmails.handle_scan(last_check_time)

            if new_invoices:
                print(f"Found {len(new_invoices)} new invoices")
                invoices.extend(new_invoices)
            else:
                print("No new invoices found")

            last_check_time = int(time.time())



================================================
FILE: invoice_processing/scan_gmails.py
================================================
"""Scan Gmail messages and extract content.

Including subject, body, PDF attachments, and image attachments.
"""

import base64
from datetime import datetime, UTC

from autokitteh.google import gmail_client


IMAGE_MIME_TYPES = [
    "image/bmp",  # Not sure if works, need to check.
    "image/gif",  # Not sure if works, need to check.
    "image/jpeg",  # Not sure if works, need to check.
    "image/png",
    "image/tiff",  # Not sure if works, need to check.
    "image/webp",  # Not sure if works, need to check.
]

TEXT_MIME_TYPES = [
    "text/html",
    "text/plain",
]

gmail = gmail_client("gmail_conn").users()


def is_image(part):
    recognized_type = part.get("mimeType") in IMAGE_MIME_TYPES
    return recognized_type and "attachmentId" not in part.get("body", {})


def is_pdf(part):
    recognized_type = part.get("mimeType") == "application/pdf"
    return recognized_type and "attachmentId" in part.get("body", {})


def is_text(part):
    recognized_type = part.get("mimeType") in TEXT_MIME_TYPES
    return recognized_type and "data" in part.get("body", {})


def get_mail_content(message):
    subject = get_subject(message)
    body = get_body(message)
    pdf_files = get_pdf_attachments(message)
    images = get_image_attachments(message)
    return subject, body, pdf_files, images


def get_subject(message):
    """Extract subject from message headers."""
    headers = message.get("payload", {}).get("headers", [])
    return next(
        (header["value"] for header in headers if header["name"].lower() == "subject"),
        "No Subject",
    )


def get_body(message):
    payload = message.get("payload", {})

    for part in payload.get("parts", []):
        if part["mimeType"] == "multipart/alternative":
            for sub_part in part.get("parts", []):
                if is_text(sub_part):
                    return process_body_part(sub_part)
        elif is_text(part):
            return process_body_part(part)

    return "No body content"


def process_body_part(part):
    data = part["body"]["data"]
    return base64.urlsafe_b64decode(data).decode("utf-8")


def get_pdf_attachments(message):
    """Extract PDF attachments from message."""
    pdf_files = []

    payload = message.get("payload", {})
    for part in [part for part in payload.get("parts", []) if is_pdf(part)]:
        client = gmail.messages().attachments()
        attachment = client.get(
            userId="me", messageId=message["id"], id=part["body"]["attachmentId"]
        ).execute()

        if "data" not in attachment:
            continue

        pdf_files.append(
            {
                "filename": part.get("filename", "unnamed.pdf"),
                "data": base64url_to_base64(attachment),
            }
        )

    return pdf_files


def base64url_to_base64(attachment):
    data = base64.urlsafe_b64decode(attachment["data"])
    return base64.b64encode(data).decode("utf-8")


def get_image_attachments(message):
    """Extract images from message, including from nested multipart messages."""
    image_files = []
    payload = message.get("payload", {})

    def process_part(part):
        if part.get("mimeType") == "multipart/alternative":
            for sub_part in part.get("parts", []):
                process_part(sub_part)

        elif is_image(part):
            try:
                client = gmail.messages().attachments()
                attachment = client.get(
                    userId="me",
                    messageId=message["id"],
                    id=part["body"]["attachmentId"],
                ).execute()

                if attachment.get("data"):
                    mime_type = part.get("mimeType", "image/png")
                    encoded_data = base64url_to_base64(attachment)

                    # Create proper image URL format.
                    data_url = f"data:{mime_type};base64,{encoded_data}"

                    image_files.append({"data": data_url})

            except (KeyError, TypeError) as e:
                print(f"Error processing image attachment: {str(e)}")
                return  # Use return instead of continue.

    # Process all parts.
    if "parts" in payload:
        for part in payload["parts"]:
            process_part(part)
    elif is_image(payload):
        process_part(payload)

    return image_files


def scan_gmail_messages(ts):
    """Scans Gmail for messages based on a timestamp (ts)."""
    date_from = datetime.fromtimestamp(ts, tz=UTC).strftime("%Y/%m/%d")
    messages = gmail.messages().list(userId="me", q=f"after:{date_from}").execute()
    emails = []

    for msg in messages.get("messages", []):
        message = gmail.messages().get(userId="me", id=msg["id"]).execute()
        subject, body, pdf_files, images = get_mail_content(message)

        attachments = []
        for pdf in pdf_files:
            attachment = {"filename": pdf["filename"], "data": pdf["data"]}
            attachments.append(attachment)

        mail_data = {
            "id": message["id"],
            "subject": subject,
            "body": body,
            "images": images or [],
            "attachments": attachments,
        }
        emails.append(mail_data)

    return emails



================================================
FILE: invoice_processing/schemas.py
================================================
"""This module contains JSON schemas for invoice parsing and detection."""

# Schema for invoice parsing.
AI_INVOICE_JSON_SCHEMA = {
    "type": "json_schema",
    "json_schema": {
        "strict": True,
        "name": "parsed_invoice",
        "schema": {
            "type": "object",
            "properties": {
                "companyName": {"type": "string", "nullable": True},
                "date": {"type": "string", "nullable": True},
                "amount": {"type": "string", "nullable": True},
                "invoiceId": {"type": "string", "nullable": True},
            },
            "required": ["companyName", "date", "amount", "invoiceId"],
            "additionalProperties": False,
        },
    },
}

# Schema for invoice detection (boolean response).
AI_BOOLEAN_SCHEMA = {"type": "text"}



================================================
FILE: jenkins_release/README.md
================================================
title: GitHub and Jenkins workflow
description: This ensures that when a commit is pushed to main, a specific Jenkins build is completed.
integrations: ["github"]
categories: ["DevOps"]
tags: ["webhook_handling", "retry_mechanisms", "monitoring", "notifications"]



================================================
FILE: jenkins_release/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that monitors comments on GitHub issues.

version: v1

project:
  name: jenkins_release

  vars:
    - name: JENKINS_URL
      value:
    - name: JENKINS_USER
      value:
    - name: JENKINS_PASSWORD
      secret: true
      value:
    - name: JOB_NAME
      value:

  connections:
    - name: github_conn
      integration: github

  triggers:
    - name: on_github_push
      event_type: push
      connection: github_conn
      call: program.py:on_github_push



================================================
FILE: jenkins_release/program.py
================================================
"""Trigger and track Jenkins builds based on GitHub push events."""

from os import getenv

from jenkins import Jenkins
from jenkins import JenkinsException
from tenacity import retry
from tenacity import retry_if_exception
from tenacity import retry_if_result
from tenacity import wait_fixed


JOB_NAME = getenv("JOB_NAME")

jenkins = Jenkins(
    getenv("JENKINS_URL"),
    username=getenv("JENKINS_USER"),
    password=getenv("JENKINS_PASSWORD"),
)


def on_github_push(event):
    if not event.data.get("ref") == "refs/heads/main":
        print("not main")
        return

    _must_build(JOB_NAME, event.data.get("after"))


# Retry until build is successful.
@retry(
    retry=(
        retry_if_result(lambda r: r != "SUCCESS") | retry_if_exception(JenkinsException)
    )
)
def _must_build(job_name, sha):
    build_number = jenkins.get_job_info(job_name)["nextBuildNumber"]

    build_id = jenkins.build_job(job_name, {"sha": sha})

    print(f"job {job_name}(sha={sha}) started: build id {build_id}, #{build_number}")

    return _track(job_name, build_number)


# Retry until there is a result.
@retry(
    wait=wait_fixed(3),
    retry=(retry_if_result(lambda r: not r) | retry_if_exception(JenkinsException)),
)
def _track(job_name, build_number):
    bi = jenkins.get_build_info(job_name, build_number)
    if bi.get("building"):
        print(f"build {build_number} is building")
        return ""

    result = bi.get("result")

    print(f"build {build_number} finished with result {result}")

    return result



================================================
FILE: jira_google_calendar/assignee_from_schedule/README.md
================================================
title: Jira assignee from Google Calendar
description: Set assignee in Jira ticket to the person currently on-call
integrations: ["jira", "googlecalendar"]
categories: ["DevOps"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: jira_google_calendar/assignee_from_schedule/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that sets the assignee of new Atlassian Jira
# issues based on an on-call rotation in a shared Google Calendar.

version: v1

project:
  name: jira_assignee_from_google_calendar_schedule

  vars:
    - name: SHARED_CALENDAR_ID
      value: primary

  connections:
    - name: google_calendar_connection
      integration: googlecalendar
    - name: jira_connection
      integration: jira

  triggers:
    - name: jira_issue_created
      connection: jira_connection
      event_type: issue_created
      filter: data.issue.fields.project.key == "JIRA_PROJECT_KEY"
      call: program.py:on_jira_issue_created



================================================
FILE: jira_google_calendar/assignee_from_schedule/program.py
================================================
"""This program assigns Atlassian Jira issues based on a shared Google Calendar.

The shared Google Calendar defines a 27/4 on-call rotation.
How to create it: https://support.google.com/calendar/answer/37095

This program assumes that the calendar entries have these fields:
- Summary: the on-call person's human-readable name
- Description: their Atlassian account ID
"""

from datetime import datetime, timedelta, UTC
import os

import autokitteh
from autokitteh.atlassian import jira_client
from autokitteh.google import google_calendar_client


def on_jira_issue_created(event):
    """Workflow's entry-point."""
    name, account_id = _get_current_oncall()
    update = {"assignee": {"accountId": account_id}}

    jira = jira_client("jira_connection")
    jira.update_issue_field(event.data.issue.key, update, notify_users=True)

    print(f"Assigned {event.data.issue.key} to {name}")


@autokitteh.activity
def _get_current_oncall():
    """Return the name and Atlassian account ID of the current on-call."""
    gcal = google_calendar_client("google_calendar_connection").events()
    now = datetime.now(UTC)
    in_a_minute = now + timedelta(minutes=1)

    result = gcal.list(
        calendarId=os.getenv("SHARED_CALENDAR_ID"),
        timeMin=now.isoformat(),  # Request all currently-effective events.
        timeMax=in_a_minute.isoformat(),
        orderBy="updated",  # Use the most-recently updated one.
    ).execute()["items"][-1]

    # Google Calendar may add whitespaces - strip them.
    return result["summary"].strip(), result["description"].strip()



================================================
FILE: jira_google_calendar/deadline_to_event/README.md
================================================
title: Create calendar due date event for Jira ticket
description: When a new Jira issue is created, the workflow automatically generates a Google Calendar event with a deadline
integrations: ["googlecalendar", "jira"]
categories: ["DevOps"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: jira_google_calendar/deadline_to_event/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that creates events in Google Calendar
# when Atlassian Jira issues are created in a specific project.

version: v1

project:
  name: jira_deadline_to_google_calendar_event

  connections:
    - name: jira_connection
      integration: jira
    - name: google_calendar_connection
      integration: googlecalendar

  triggers:
    - name: jira_issue_created
      connection: jira_connection
      event_type: issue_created
      filter: data.issue.fields.project.key == "JIRA_PROJECT_KEY"
      call: program.py:on_jira_issue_created



================================================
FILE: jira_google_calendar/deadline_to_event/program.py
================================================
"""This program receives Jira events and creates Google Calendar events.

Scenario:
    Initiating a procedure that requires collaboration and coordination,
    e.g. scheduling a consult with another team, or planning a joint review.

Workflow:
    The user creates a new Jira ticket for the discussion. AutoKitteh
    automatically generates a Google Calendar event with a deadline for
    the completion, to ensure that the review happens as planned.
"""

import autokitteh
from autokitteh import atlassian
from autokitteh.google import google_calendar_client


def on_jira_issue_created(event):
    """Workflow's entry-point."""
    _create_calendar_event(event.data.issue.fields, event.data.issue.key)


@autokitteh.activity
def _create_calendar_event(issue, key):
    url = atlassian.get_base_url("jira_connection")
    link = f"Link to Jira issue: {url}/browse/{key}\n\n"

    event = {
        "summary": issue.summary,
        "description": link + issue.description,
        "start": {"date": issue.duedate},
        "end": {"date": issue.duedate},
        "reminders": {"useDefault": True},
        "attendees": [
            {"email": "auto@example.com"},
            {"email": "kitteh@example.com"},
        ],
    }

    gcal = google_calendar_client("google_calendar_connection").events()
    event = gcal.insert(calendarId="primary", body=event).execute()

    print("Google Cloud event created: " + event.get("htmlLink"))



================================================
FILE: leash/README.md
================================================
title: Leash - Incident Management & On-Call Escalation
description: Automated incident management system with on-call rotation, escalation workflows, and multi-channel notifications
integrations: ["googlesheets", "slack", "twilio", "gmail"]
categories: ["DevOps"]
tags:
  [
    "webhook_handling",
    "long_running",
    "next_event",
    "subscribe",
    "interactive_workflows",
    "notifications",
    "monitoring",
    "sync_responses",
    "durable",
  ]



================================================
FILE: leash/autokitteh.yaml
================================================
version: v2

project:
  name: leash

  vars:
    - name: GOOGLE_SPREADSHEET_ID
      value: "1o8MzkYzbl_YO6mvmZUFrOVz5phgXvF3W9kPhdsh8fGw"
      description: "The ID of the Google Spreadsheet managing this automation."
    - name: ESCALATION_DELAY_MINUTES
      value: "15"
      description: "The delay between escalation steps, in minutes."
    - name: TZ
      value: "America/Los_Angeles"
      description: "The timezone to use for schedules and time calculations."
    - name: FAIL_ON_NO_ASSIGNEE
      value: "false"
      description: "Whether to fail creating an incident if there is no assignee."
    - name: TS_FORMAT
      value: "%m-%d-%Y %H:%M"
      description: "The datetime format to use for parsing and formatting timestamps."
    - name: TWILIO_PHONE_NUMBER
      value: "+17756006369"
      description: "If using Twilio, the phone number to send SMS messages from."

  connections:
    - name: gsheets
      integration: googlesheets
    - # optional, init if you want to use Slack for notifications.
      name: slack
      integration: slack
    - # optional, init if you want to use Twilio for SMS notifications.
      name: twilio
      integration: twilio
    - # optional, init if you want to use Gmail for email notifications.
      name: gmail
      integration: gmail

  triggers:
    - # New incident webhook, creates a new incident from the webhook data.
      name: new_incident_webhook
      type: webhook
      call: handlers.py:on_new_incident_webhook
      # This is long running, so need to run as a durable session.
      is_durable: true
      # Will respond with the new incident id.
      is_sync: true
    - # Incident dashboard response webhook:
      # - POST: consumed by the escalation loop to handle ack/resolve/escalate actions.
      # - GET: returns the current incident status and actions.
      name: incident_dashboard_webhook
      type: webhook
      call: handlers.py:on_incident_dashboard_webhook
      # Responds with an HTML page showing the incident status and possible actions.
      is_sync: true



================================================
FILE: leash/config.py
================================================
"""Configuration management for the Leash incident management system.

This module loads and manages configuration settings from environment variables,
including escalation delays, timezone settings, notification preferences, and
integration endpoints.
"""

from datetime import timedelta
from os import getenv
from zoneinfo import ZoneInfo

from autokitteh import get_webhook_url


def _get(key: str, default):
    """Get a configuration value."""
    return type(default)(getenv(key, default))


ESCALATION_DELAY = timedelta(minutes=_get("ESCALATION_DELAY_MINUTES", 15))

REMIND_BEFORE_ONCALL_DURATION = timedelta(
    minutes=_get("REMIND_BEFORE_ONCALL_MINUTES", 10)
)

TZ = ZoneInfo(_get("TZ", "UTC"))

FAIL_ON_NO_ASSIGNEE = _get("FAIL_ON_NO_ASSIGNEE", "1").lower() in (
    "1",
    "true",
    "yes",
)

TS_FORMAT = _get("TS_FORMAT", "%m-%d-%Y %H:%M")

TWILIO_PHONE_NUMBER = _get("TWILIO_PHONE_NUMBER", "")

INCIDENT_DASHBOARD_WEBHOOK_URL = get_webhook_url("incident_dashboard_webhook")



================================================
FILE: leash/handlers.py
================================================
"""Triggers handlers for incident management.

This module contains the AutoKitteh event handlers for processing incoming
webhooks, including new incident creation and interactive incident dashboard
requests. Handlers coordinate between incoming HTTP events and the incident
management workflow.
"""

from dataclasses import replace

import incidents
from model import IncidentState
import store

from autokitteh import Event, http_outcome


def on_new_incident_webhook(event: Event):
    details = event.data.body.text.strip()

    print(f"new incident, details={details}")

    inc = incidents.create(details)

    http_outcome(status_code=201, json={"incident_id": inc.id})

    try:
        incidents.run(inc)
    except Exception as e:
        store.update_incident(
            replace(
                inc,
                state=incidents.IncidentState.ERROR,
                comment=str(e),
            )
        )
        raise


def on_incident_dashboard_webhook(event: Event):
    data = event.data
    user = data.get("user")

    unique_id = data.url.query.get("unique_id")
    if not unique_id:
        http_outcome(status_code=403, json={"error": "missing unique_id"})
        return

    inc = store.get_incident_by_unique_id(unique_id)
    if not inc:
        print(f"incident not found: {unique_id}")
        http_outcome(status_code=404, json={"error": "not found"})
        return

    match data.method:
        case "GET":
            # Handle GET below.
            pass

        case "POST":
            http_outcome(
                status_code=303,
                headers={"Location": f"{inc.dashboard_url + '&msg=notified'}"},
            )
            # continue normal handling below.

        case _:
            http_outcome(status_code=405, json={"error": "method not allowed"})
            return

    take = '<button name="action" value="take">Take</button>'
    ack = '<button name="action" value="ack">Ack</button>'
    esc = '<button name="action" value="escalate">Escalate</button>'
    resolve = '<button name="action" value="resolve">Resolve</button>'
    notify = '<button name="action" value="notify">Notify</button>'

    form = f"""
        <form method="POST" action="{inc.dashboard_url}">
            {ack if inc.state == IncidentState.ASSIGNED else ""}
            {resolve}
            {take if user else ""}
            {esc if inc.state in (IncidentState.IN_PROGRESS, IncidentState.ASSIGNED) else ""}
            {notify}
        </form>
    """  # noqa: E501

    user = data.get("user")
    msg = data.url.query.get("msg")

    http_outcome(
        status_code=200,
        body=f"""<html>
    <body>
        <h1>Incident {inc.id}</h1>

        {f"<p style='color: green;'>{msg}</p>" if msg else ""}

        <p>State: <b>{inc.state}</b></p>
        <p>Details: <pre>{inc.details}</pre></p>
        <p>Comment: <pre>{inc.comment or "none"}</pre></p>
        <p>Assignee: {inc.assignee or "none"}</p>
        <p>Assigned at: {inc.assigned_at}</p>

        {form if inc.state.is_active else "<p>Incident is no longer active.</p>"}

        <p>You are {user.email if user else "anonymous"}.</p>
    </body>
</html>""",
    )


def init(_):
    """Run this function manually once to initialize the system."""
    print("initialized.")



================================================
FILE: leash/incidents.py
================================================
"""Core incident management logic and workflow orchestration.

This module implements the incident lifecycle management including creation,
assignment, escalation, and resolution. It handles the automatic escalation
workflow, on-call schedule rotation, notification delivery, and processing
of user actions from the incident dashboard.
"""

from dataclasses import replace
from datetime import datetime, timedelta
import secrets
from typing import cast

from model import Incident
from model import IncidentState
from model import ScheduleRow
from notifications import notify
import store

from autokitteh import next_event, subscribe
import config


def _now() -> datetime:
    return datetime.now(tz=config.TZ)


def create(details: str) -> Incident:
    """Create a new incident and store it."""
    t = _now()

    inc = Incident(
        id=store.next_incident_id(),
        details=details,
        state=IncidentState.PENDING,
        started_at=t,
        unique_id=secrets.token_urlsafe(16),
    )

    store.add_incident(inc)

    return inc


def run(inc: Incident) -> None:
    """Run the incident management loop in a durable workflow."""
    # Subscribe to incident dashboard webhooks for this incident id.
    webhook_response_subscription = subscribe(
        "incident_dashboard_webhook",
        filter=(
            f"data.method == 'POST' && data.url.query.unique_id == '{inc.unique_id}'"
        ),
    )

    # Escalation loop.
    while inc.state.is_active:
        now = _now()

        if _is_new_assignee_required(now, inc):
            schedule = store.get_schedule_row(now)

            inc = _auto_assign(now, inc, schedule)

            store.update_incident(inc)

            if not inc.state.is_active:
                continue

        data = next_event(webhook_response_subscription, timeout=timedelta(minutes=1))
        if data:
            inc = _handle_webhook_response(data.body.form, data.get("user"), inc)
            store.update_incident(inc)

    print(f"incident {inc.id} no longer active.")


def _is_new_assignee_required(t: datetime, inc: Incident) -> bool:
    match inc.state:
        case IncidentState.PENDING:
            return True
        case IncidentState.ASSIGNED:
            return (
                (t - inc.assigned_at) > config.ESCALATION_DELAY
                if inc.assigned_at
                else False
            )
        case _:
            return False


def _notify(contact: store.Contact, inc: Incident) -> None:
    notify(
        contact,
        subject="[LEASH] New incident assigned",
        message=f"""Incident details:
{inc.details}
ID: {inc.id}
Respond: {inc.dashboard_url}""",
    )


def _assign(t: datetime, inc: Incident, assignee: str, comment: str) -> Incident:
    contact = store.get_contact_by_name(assignee)
    if contact is None:
        return replace(
            inc,
            state=IncidentState.ERROR,
            comment=f"assignee '{assignee}' not found in contacts",
        )

    _notify(contact, inc)

    return replace(
        inc,
        state=IncidentState.ASSIGNED,
        assigned_at=t,
        assignee=assignee,
        comment=comment,
    )


def _auto_assign(t: datetime, inc: Incident, schedule: ScheduleRow | None) -> Incident:
    fail_state = (
        IncidentState.ERROR if config.FAIL_ON_NO_ASSIGNEE else IncidentState.PENDING
    )

    if not schedule:
        return replace(inc, state=fail_state, comment="no schedule set")

    assignee = schedule.get_next_assignee(inc.assignee)
    if not assignee:
        return replace(inc, state=fail_state, comment="schedule has no assignees")

    return _assign(t, inc, assignee, "auto-assigned")


def _handle_webhook_response(
    form: dict[str, str],
    user: dict | None,
    inc: Incident,
) -> Incident:
    """Handle a webhook response event."""
    print(f"webhook response: {form}")

    action = form.get("action")

    by = ""
    if user:
        by = f" by {user.get('email')}"

    match action:
        case "ack" | "a":
            return replace(
                inc,
                state=IncidentState.IN_PROGRESS,
                comment=f"ack'd via webhook{by}",
            )

        case "resolve" | "r":
            return replace(
                inc,
                state=IncidentState.RESOLVED,
                comment=f"resolved via webhook{by}",
            )

        case "escalate" | "e":
            return replace(inc, state=IncidentState.PENDING, comment=f"escalated{by}")

        case "take" | "t":
            if not user:
                return replace(
                    inc, comment="take attempted but no user info in webhook"
                )

            return _assign(
                _now(),
                inc,
                cast(str, user.get("email")),
                f"taken via webhook{by}",
            )

        case "assign" | "g":
            assignee = form.get("assignee")
            if not assignee:
                return replace(inc, comment="assign: no assignee given")

            return _assign(_now(), inc, assignee, f"manually assigned via webhook{by}")

        case "notify" | "n":
            if not inc.assignee:
                return replace(inc, comment="notify: no assignee set")

            contact = store.get_contact_by_name(inc.assignee)
            if not contact:
                return replace(
                    inc,
                    comment=f"notify: assignee '{inc.assignee}' not found in contacts",
                )

            _notify(contact, inc)

            return replace(inc, comment=f"notified assignee via webhook{by}")

        case _:
            return replace(inc, comment=f"unknown action '{action}' received{by}")



================================================
FILE: leash/Makefile
================================================
# All of these packages are builtin into autokitteh SDK.
UVX=uvx --with autokitteh \
		--with gspread \
		--with google-api-python-client \
		--with google-generativeai \
		--with twilio \
		--with pytest \
		--with slack-sdk
		

.PHONY: all
all: lint typecheck test format

.PHONY: lint
lint:
	$(UVX) ruff check --config ../pyproject.toml

.PHONY: format
format:
	$(UVX) ruff format --check --config ../pyproject.toml

.PHONY: typecheck
typecheck:
	$(UVX) mypy --follow-untyped-imports  .

.PHONY: test
test:
	$(UVX) pytest

.PHONY: deploy
deploy:
	ak deploy --manifest autokitteh.yaml



================================================
FILE: leash/model.py
================================================
"""Data models for the Leash incident management system.

This module defines the core data structures used throughout the system including
Contact (person to notify), ScheduleRow (on-call rotation schedule), Incident
(event being tracked), and IncidentState (lifecycle state). Models include
serialization methods for Google Sheets storage.
"""

from dataclasses import dataclass
from datetime import datetime
from enum import auto
from enum import StrEnum
from typing import ClassVar

from utils import format_ts
from utils import parse_ts

import config


def _col(row: list, i: int, default=None):
    """Get a column from a row, returning a default if it doesn't exist."""
    try:
        return row[i]
    except IndexError:
        return default


@dataclass(frozen=True, kw_only=True)
class Contact:
    """A contact."""

    name: str
    """The name of the contact."""

    email: str | None = None
    """The email address of the contact, if any."""

    phone: str | None = None
    """The phone number of the contact, if any."""

    @staticmethod
    def from_row(row: list) -> "Contact":
        return Contact(
            name=row[0],
            email=_col(row, 1),
            phone=_col(row, 2),
        )


@dataclass(frozen=True, kw_only=True)
class ScheduleRow:
    """A schedule row."""

    start_time: datetime
    """When the schedule period begins."""

    end_time: datetime
    """When the schedule period ends."""

    assignees: list[str]
    """List of people assigned to this schedule in the order they should be assigned."""

    def get_next_assignee(self, curr: str | None) -> str | None:
        """Get the next assignee in the schedule after the current assignee."""
        if not self.assignees:
            return None

        if not curr:
            return self.assignees[0]

        i = self.assignees.index(curr)
        if i < 0:
            # Assignee does not exist, maybe removed. Reset rotation.
            return self.assignees[0]

        i = (i + 1) % len(self.assignees)

        return self.assignees[i]

    labels: ClassVar = ["start_time", "end_time", "assignees"]

    @property
    def row(self) -> list:
        """Return the schedule row as a list for storage."""
        return [
            format_ts(self.start_time),
            format_ts(self.end_time),
            *self.assignees,
        ]

    @staticmethod
    def from_row(row: list) -> "ScheduleRow":
        """Create a ScheduleRow from a row."""
        return ScheduleRow(
            start_time=parse_ts(row[0]),
            end_time=parse_ts(row[1]),
            assignees=[s for s in row[2:] if s],
        )

    def match(self, t: datetime) -> bool:
        """Return True if the given time is within the schedule period."""
        return self.start_time <= t <= self.end_time


class IncidentState(StrEnum):
    """An incident state."""

    PENDING = auto()
    """Incident has been reported but not yet assigned."""

    ASSIGNED = auto()
    """Incident has been assigned to someone but work hasn't started."""

    IN_PROGRESS = auto()
    """Someone is actively working on the incident."""

    RESOLVED = auto()
    """Incident has been resolved and closed."""

    ERROR = auto()
    """An error occurred while processing the incident."""

    @property
    def is_active(self) -> bool:
        """Return True if the incident is active (not resolved or error)."""
        return self in {
            IncidentState.PENDING,
            IncidentState.ASSIGNED,
            IncidentState.IN_PROGRESS,
        }


@dataclass(frozen=True, kw_only=True)
class Incident:
    """An incident."""

    id: str
    """Unique identifier for the incident."""

    started_at: datetime
    """When the incident was started."""

    details: str
    """Description of what happened, usually the payload of the notification."""

    state: IncidentState
    """Current state of the incident."""

    assignee: str | None = None
    """The person that was last assigned to the incident, if any."""

    assigned_at: datetime | None = None
    """When the incident was last assigned, if ever."""

    comment: str | None = None
    """Optional comment about the incident."""

    unique_id: str
    """A unique identifier for the incident, used to prevent scraping."""

    labels: ClassVar = [
        "id",
        "started_at",
        "state",
        "assignee",
        "assigned_at",
        "comment",
        "details",
        "action",
        "unique_id",
    ]

    @property
    def dashboard_url(self) -> str:
        """Return the URL of the incident dashboard, if configured."""
        if url := config.INCIDENT_DASHBOARD_WEBHOOK_URL:
            return f"{url}?unique_id={self.unique_id}"
        return ""

    @property
    def row(self) -> list:
        """Return the incident as a row for storage."""
        return [
            int(self.id),
            format_ts(self.started_at),
            self.state,
            self.assignee,
            format_ts(self.assigned_at) if self.assigned_at else "",
            self.comment or "",
            self.details,
            f'=HYPERLINK("{self.dashboard_url}", "ACT")' if self.dashboard_url else "",
            self.unique_id,
        ]

    @staticmethod
    def from_row(row: list) -> "Incident":
        """Create an Incident from a row."""
        return Incident(
            id=str(row[0]),
            started_at=parse_ts(row[1]),
            state=IncidentState(row[2]),
            assignee=row[3] or None,
            assigned_at=parse_ts(row[4]) if row[4] else None,
            comment=row[5] or None,
            details=row[6],
            unique_id=row[8],
        )



================================================
FILE: leash/notifications.py
================================================
"""Notification delivery system for incident alerts.

This module handles sending notifications to contacts through multiple channels
including email (Gmail), SMS (Twilio), and Slack messages. It initializes
connections to these services and provides a unified interface for notifying
contacts about incidents.
"""

import base64

from autokitteh.errors import ConnectionInitError
from autokitteh.google import gmail_client
from autokitteh.slack import slack_client
from autokitteh.twilio import twilio_client
from googleapiclient.errors import HttpError
from model import Contact
from slack_sdk.web.client import WebClient as SlackWebClient
from twilio.base.exceptions import TwilioRestException

import config
from slack_sdk.errors import SlackApiError
from twilio.rest import Client as TwilioClient


try:
    twilio: TwilioClient | None = twilio_client("twilio")
except ConnectionInitError:
    twilio = None
    print("WARN: twilio connection not initialized.")

try:
    slack: SlackWebClient | None = slack_client("slack")
except ConnectionInitError:
    slack = None
    print("WARN: slack connection not initialized.")

try:
    gmail = gmail_client("gmail")
except ConnectionInitError:
    gmail = None
    print("WARN: gmail connection not initialized.")


def notify(contact: Contact, subject: str, message: str) -> None:
    print(f"notifying {contact}: {subject}...")

    any_sent = False

    if contact.phone:
        any_sent |= _send_twilio_message(contact.phone, subject, message)

    if contact.email:
        any_sent |= _send_email(contact.email, subject, message)

    if contact.email:
        any_sent |= _send_slack_message(contact.email, subject, message)

    if not any_sent:
        print(f"WARN: no notification sent to {contact.name}.")


def _send_email(email: str, subject: str, message: str) -> bool:
    if not gmail:
        return False

    print(f"sending email to {email}...")

    users = gmail.users()
    profile = users.getProfile(userId="me").execute()

    msg = f"""From: {profile["emailAddress"]}
To: {email}
Subject: {subject}

{message}""".replace("\n", "\r\n")

    msg = base64.urlsafe_b64encode(msg.encode()).decode()

    try:
        msg = users.messages().send(userId="me", body={"raw": msg}).execute()
        print(f"sent message {msg['id']}.")
        return True
    except HttpError as e:
        print(f"ERROR: `{e.reason}`")
        return False


def _send_twilio_message(phone: str, subject: str, message: str) -> bool:
    if not twilio:
        return False

    print(f"sending text to {phone}...")

    try:
        msg = twilio.messages.create(
            from_=config.TWILIO_PHONE_NUMBER,
            to=phone,
            body=f"{subject}\n\n{message}",
        )

        print(f"sent message {msg.sid}.")

        return True
    except TwilioRestException as e:
        print(f"ERROR: `{e}`")
        return False


def _send_slack_message(email: str, subject: str, message: str) -> bool:
    if not slack:
        return False

    print(f"sending slack message to {email}...")

    try:
        user_id = slack.users_lookupByEmail(email=email)["user"]["id"]
    except SlackApiError as e:
        print(f"error: {e}")
        return False

    try:
        msg = slack.chat_postMessage(
            channel=user_id,
            text=f"*{subject}*\n\n{message}",
        )
        print(f"sent message {msg['ts']}.")
        return True
    except SlackApiError as e:
        print(f"ERROR: `{e.response['error']}`")
        return False



================================================
FILE: leash/store.py
================================================
"""Google Sheets storage backend for Leash data.

This module provides data persistence using Google Sheets as the storage layer.
It manages worksheets for incidents, schedules, contacts, and internal state,
providing CRUD operations for incidents and queries for schedules and contacts.
"""

from datetime import datetime
from os import getenv

from autokitteh.google import gspread_client
from gspread.exceptions import WorksheetNotFound
from gspread.utils import ValueInputOption
from gspread.worksheet import Worksheet
from model import Contact
from model import Incident
from model import ScheduleRow


_GOOGLE_SPREADSHEET_ID = getenv("GOOGLE_SPREADSHEET_ID")
if not _GOOGLE_SPREADSHEET_ID:
    raise RuntimeError("GOOGLE_SPREADSHEET_ID not set")

_client = gspread_client("gsheets").open_by_key(_GOOGLE_SPREADSHEET_ID)


#
# Utils
#


def get(name: str) -> Worksheet | None:
    """Get a worksheet by name."""
    try:
        return _client.worksheet(name)
    except WorksheetNotFound:
        return None


def _get_or_create(name: str, init=None) -> Worksheet:
    """Ensure a worksheet exists, creating it if needed.

    If `init` is given, it is used to initialize the sheet.
    """
    try:
        return _client.worksheet(name)
    except WorksheetNotFound:
        pass

    w = _client.add_worksheet(name, rows=100, cols=20)

    if init:
        w.update(init, raw=False)

    return w


#
# Sheets
#


_incidents = _get_or_create("incidents", [Incident.labels])
_schedule = _get_or_create("schedule", [ScheduleRow.labels])

_scratchpad = _get_or_create(
    "_scratchpad",
    [
        ["next_incident_id", "=MAX(incidents!A:A) + 1"],
    ],
)

_contacts = get("contacts")


#
# Operations
#


def next_incident_id() -> str:
    return str(_scratchpad.acell("B1").value or 1)


def add_incident(inc: Incident) -> None:
    _incidents.append_row(inc.row, value_input_option=ValueInputOption.user_entered)


def get_incident_by_unique_id(unique_id: str) -> Incident | None:
    cell = _incidents.find(unique_id, in_column=9)
    if not cell:
        return None

    return Incident.from_row(_incidents.row_values(cell.row))


def update_incident(inc: Incident) -> None:
    print(f"update: {inc}")

    cell = _incidents.find(str(inc.id), in_column=1)
    if not cell:
        raise ValueError(f"Incident with id {inc.id} not found")

    _incidents.update(
        [inc.row],
        f"A{cell.row}",
        value_input_option=ValueInputOption.user_entered,
    )


def get_schedule_row(t: datetime) -> ScheduleRow | None:
    """Get the schedule row for a specific time.

    If no schedule is found, returns None.
    If more than one schedule matches, returns the first one.
    """
    rows = _schedule.get_all_values()
    for i, row in enumerate(rows[1:]):
        try:
            sched = ScheduleRow.from_row(row)
        except ValueError as exc:
            print(f"ERROR: Invalid schedule row {i + 1}: {row} -> {exc}")
            continue

        if sched.match(t):
            return sched

    return None


def get_contact_by_name(name: str) -> Contact | None:
    """Get a contact by name."""
    if not _contacts:
        return None

    cell = _contacts.find(name, in_column=1)
    if not cell:
        return None

    return Contact.from_row(_contacts.row_values(cell.row))


def get_contact_by_email(email: str) -> Contact | None:
    """Get a contact by email."""
    if not _contacts:
        return None

    cell = _contacts.find(email, in_column=2)
    if not cell:
        return None

    return Contact.from_row(_contacts.row_values(cell.row))



================================================
FILE: leash/test_handlers.py
================================================
"""Tests for incident webhook handlers."""

import os
from unittest.mock import MagicMock
from unittest.mock import Mock
from unittest.mock import patch

import pytest


# Set required environment variables before importing any modules
os.environ["GOOGLE_SPREADSHEET_ID"] = "test_spreadsheet_id"

# Mock autokitteh and store dependencies before importing handlers
with (
    patch("autokitteh.get_webhook_url", return_value="http://test.webhook.url"),
    patch("autokitteh.google.gspread_client", return_value=MagicMock()),
    patch("autokitteh.http_outcome") as mock_http_outcome,
):
    import handlers
    from model import Incident
    from model import IncidentState


@pytest.fixture
def mock_event():
    """Create a mock event object."""
    event = Mock()
    event.data = Mock()
    return event


@pytest.fixture
def sample_incident():
    """Return a sample incident for testing."""
    from datetime import datetime
    from zoneinfo import ZoneInfo

    return Incident(
        id="42",
        details="Test incident",
        state=IncidentState.PENDING,
        started_at=datetime(2024, 1, 15, 10, 0, 0, tzinfo=ZoneInfo("UTC")),
        unique_id="test_unique_id",
    )


class TestOnNewIncidentWebhook:
    """Tests for the on_new_incident_webhook handler."""

    @patch("handlers.incidents.run")
    @patch("handlers.incidents.create")
    @patch("handlers.http_outcome")
    def test_successful_incident_creation(
        self, mock_http_outcome, mock_create, mock_run, mock_event, sample_incident
    ):
        """Test successful creation of a new incident."""
        mock_event.data.body.text = "Server is down"
        mock_create.return_value = sample_incident

        handlers.on_new_incident_webhook(mock_event)

        # Verify incident was created
        mock_create.assert_called_once_with("Server is down")

        # Verify HTTP response
        mock_http_outcome.assert_called_once_with(
            status_code=201, json={"incident_id": "42"}
        )

        # Verify incident was run
        mock_run.assert_called_once_with(sample_incident)

    @patch("handlers.incidents.run")
    @patch("handlers.incidents.create")
    @patch("handlers.http_outcome")
    def test_strips_whitespace_from_details(
        self, mock_http_outcome, mock_create, mock_run, mock_event, sample_incident
    ):
        """Test that whitespace is stripped from incident details."""
        mock_event.data.body.text = "  Database connection failed  \n"
        mock_create.return_value = sample_incident

        handlers.on_new_incident_webhook(mock_event)

        mock_create.assert_called_once_with("Database connection failed")

    @patch("handlers.store.update_incident")
    @patch("handlers.incidents.run")
    @patch("handlers.incidents.create")
    @patch("handlers.http_outcome")
    def test_handles_exception_during_run(
        self,
        mock_http_outcome,
        mock_create,
        mock_run,
        mock_update,
        mock_event,
        sample_incident,
    ):
        """Test that exceptions during run are handled properly."""
        mock_event.data.body.text = "Test incident"
        mock_create.return_value = sample_incident
        mock_run.side_effect = RuntimeError("Something went wrong")

        with pytest.raises(RuntimeError, match="Something went wrong"):
            handlers.on_new_incident_webhook(mock_event)

        # Verify HTTP response was sent before error
        mock_http_outcome.assert_called_once_with(
            status_code=201, json={"incident_id": "42"}
        )

        # Verify incident was updated with error state
        mock_update.assert_called_once()
        updated_incident = mock_update.call_args[0][0]
        assert updated_incident.state == IncidentState.ERROR
        assert updated_incident.comment == "Something went wrong"


class TestOnIncidentDashboardWebhook:
    """Tests for the on_incident_dashboard_webhook handler."""

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_missing_unique_id(self, mock_http_outcome, mock_get_incident, mock_event):
        """Test that missing unique_id returns 403."""
        mock_event.data.url.query.get.return_value = None

        handlers.on_incident_dashboard_webhook(mock_event)

        mock_http_outcome.assert_called_once_with(
            status_code=403, json={"error": "missing unique_id"}
        )
        mock_get_incident.assert_not_called()

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_incident_not_found(self, mock_http_outcome, mock_get_incident, mock_event):
        """Test that non-existent incident returns 404."""
        mock_event.data.url.query.get.return_value = "nonexistent_id"
        mock_event.data.get.return_value = None
        mock_get_incident.return_value = None

        handlers.on_incident_dashboard_webhook(mock_event)

        mock_http_outcome.assert_called_once_with(
            status_code=404, json={"error": "not found"}
        )

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_unsupported_method(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that unsupported HTTP methods return 405."""
        mock_event.data.url.query.get.return_value = "test_unique_id"
        mock_event.data.get.return_value = None
        mock_event.data.method = "DELETE"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        mock_http_outcome.assert_called_once_with(
            status_code=405, json={"error": "method not allowed"}
        )

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_renders_dashboard(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that GET request renders the incident dashboard."""
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        # Verify HTTP response contains dashboard HTML
        mock_http_outcome.assert_called_once()
        call_args = mock_http_outcome.call_args
        assert call_args[1]["status_code"] == 200
        assert "Incident 42" in call_args[1]["body"]
        assert "Test incident" in call_args[1]["body"]
        assert sample_incident.state in call_args[1]["body"]

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_with_user(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test GET request includes user email in dashboard."""
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_user = Mock()
        mock_user.email = "alice@example.com"
        mock_event.data.get.return_value = mock_user
        mock_event.data.method = "GET"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        assert "alice@example.com" in call_args[1]["body"]

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_with_message(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test GET request includes message from query params."""
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": "notified",
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        assert "notified" in call_args[1]["body"]
        assert "color: green" in call_args[1]["body"]

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_pending_state_shows_buttons(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that PENDING state shows appropriate buttons."""
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]
        # Should show resolve and notify buttons
        assert 'value="resolve"' in body
        assert 'value="notify"' in body
        # Should not show ack button (only for ASSIGNED state)
        assert 'value="ack"' not in body

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_assigned_state_shows_ack(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that ASSIGNED state shows ack button."""
        from dataclasses import replace

        assigned_incident = replace(sample_incident, state=IncidentState.ASSIGNED)
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = assigned_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]
        # Should show ack, resolve, escalate, and notify buttons
        assert 'value="ack"' in body
        assert 'value="resolve"' in body
        assert 'value="escalate"' in body
        assert 'value="notify"' in body

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_in_progress_shows_escalate(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that IN_PROGRESS state shows escalate button."""
        from dataclasses import replace

        in_progress_incident = replace(sample_incident, state=IncidentState.IN_PROGRESS)
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = in_progress_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]
        assert 'value="escalate"' in body
        assert 'value="resolve"' in body

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_resolved_state_no_form(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that RESOLVED state shows no action form."""
        from dataclasses import replace

        resolved_incident = replace(sample_incident, state=IncidentState.RESOLVED)
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = resolved_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]
        # Should not show action form, but show message
        assert "<form" not in body
        assert "no longer active" in body

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_with_authenticated_user_shows_take(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that authenticated users see the take button."""
        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_user = Mock()
        mock_user.email = "alice@example.com"
        mock_event.data.get.return_value = mock_user
        mock_event.data.method = "GET"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]
        # Should show take button for authenticated user
        assert 'value="take"' in body

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_post_request_redirects_with_notification(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that POST request redirects with notification message."""
        mock_event.data.url.query.get.return_value = "test_unique_id"
        mock_event.data.get.return_value = None
        mock_event.data.method = "POST"
        mock_get_incident.return_value = sample_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        # Should return two http_outcome calls: redirect (303) and then content (200)
        assert mock_http_outcome.call_count == 2

        # First call should be redirect
        first_call = mock_http_outcome.call_args_list[0]
        assert first_call[1]["status_code"] == 303
        assert "Location" in first_call[1]["headers"]
        assert "&msg=notified" in first_call[1]["headers"]["Location"]

    @patch("handlers.store.get_incident_by_unique_id")
    @patch("handlers.http_outcome")
    def test_get_request_shows_incident_fields(
        self, mock_http_outcome, mock_get_incident, mock_event, sample_incident
    ):
        """Test that dashboard shows all incident fields."""
        from dataclasses import replace
        from datetime import datetime
        from zoneinfo import ZoneInfo

        detailed_incident = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="bob@example.com",
            assigned_at=datetime(2024, 1, 15, 10, 30, 0, tzinfo=ZoneInfo("UTC")),
            comment="Working on it",
        )

        mock_event.data.url.query.get.side_effect = lambda key: {
            "unique_id": "test_unique_id",
            "msg": None,
        }.get(key)
        mock_event.data.get.return_value = None
        mock_event.data.method = "GET"
        mock_get_incident.return_value = detailed_incident

        handlers.on_incident_dashboard_webhook(mock_event)

        call_args = mock_http_outcome.call_args
        body = call_args[1]["body"]

        # Verify all fields are displayed
        assert "Incident 42" in body
        assert "assigned" in body
        assert "Test incident" in body
        assert "Working on it" in body
        assert "bob@example.com" in body


class TestInit:
    """Tests for the init handler."""

    @patch("builtins.print")
    def test_init_prints_message(self, mock_print):
        """Test that init function prints initialization message."""
        handlers.init(None)

        mock_print.assert_called_once_with("initialized.")



================================================
FILE: leash/test_incidents.py
================================================
"""Tests for incident management logic and workflow orchestration."""

from dataclasses import replace
from datetime import datetime, timedelta
import os
from unittest.mock import MagicMock
from unittest.mock import Mock
from unittest.mock import patch
from zoneinfo import ZoneInfo

import pytest


# Set required environment variables before importing any modules
os.environ["GOOGLE_SPREADSHEET_ID"] = "test_spreadsheet_id"

# Mock autokitteh and store dependencies before importing incidents
with (
    patch("autokitteh.get_webhook_url", return_value="http://test.webhook.url"),
    patch("autokitteh.google.gspread_client", return_value=MagicMock()),
):
    import incidents
from model import Contact
from model import Incident
from model import IncidentState
from model import ScheduleRow


@pytest.fixture
def fixed_time():
    """Return a fixed datetime for testing."""
    return datetime(2024, 1, 15, 10, 0, 0, tzinfo=ZoneInfo("UTC"))


@pytest.fixture
def sample_incident(fixed_time):
    """Return a sample incident for testing."""
    return Incident(
        id="1",
        details="Test incident",
        state=IncidentState.PENDING,
        started_at=fixed_time,
        unique_id="test_unique_id_123",
    )


@pytest.fixture
def sample_contact():
    """Return a sample contact for testing."""
    return Contact(
        name="alice@example.com",
        email="alice@example.com",
        phone="+1234567890",
    )


@pytest.fixture
def sample_schedule(fixed_time):
    """Return a sample schedule for testing."""
    return ScheduleRow(
        start_time=fixed_time - timedelta(hours=1),
        end_time=fixed_time + timedelta(hours=23),
        assignees=["alice@example.com", "bob@example.com", "charlie@example.com"],
    )


class TestCreate:
    """Tests for the create function."""

    @patch("incidents.store.next_incident_id")
    @patch("incidents.store.add_incident")
    @patch("incidents._now")
    @patch("incidents.secrets.token_urlsafe")
    def test_create_new_incident(
        self, mock_token, mock_now, mock_add, mock_next_id, fixed_time
    ):
        """Test creating a new incident."""
        mock_next_id.return_value = "42"
        mock_now.return_value = fixed_time
        mock_token.return_value = "unique_token_abc"

        inc = incidents.create("Server is down")

        assert inc.id == "42"
        assert inc.details == "Server is down"
        assert inc.state == IncidentState.PENDING
        assert inc.started_at == fixed_time
        assert inc.unique_id == "unique_token_abc"
        assert inc.assignee is None
        assert inc.assigned_at is None

        mock_add.assert_called_once_with(inc)


class TestIsNewAssigneeRequired:
    """Tests for the _is_new_assignee_required function."""

    def test_pending_state_requires_assignee(self, sample_incident, fixed_time):
        """Test that PENDING state always requires a new assignee."""
        assert incidents._is_new_assignee_required(fixed_time, sample_incident)

    @patch("incidents.config.ESCALATION_DELAY", timedelta(minutes=15))
    def test_assigned_state_requires_escalation_after_delay(
        self, sample_incident, fixed_time
    ):
        """Test that ASSIGNED state requires escalation after delay."""
        inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assigned_at=fixed_time - timedelta(minutes=20),
        )
        assert incidents._is_new_assignee_required(fixed_time, inc)

    @patch("incidents.config.ESCALATION_DELAY", timedelta(minutes=15))
    def test_assigned_state_no_escalation_before_delay(
        self, sample_incident, fixed_time
    ):
        """Test that ASSIGNED state does not require escalation before delay."""
        inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assigned_at=fixed_time - timedelta(minutes=10),
        )
        assert not incidents._is_new_assignee_required(fixed_time, inc)

    def test_assigned_state_no_assigned_at(self, sample_incident, fixed_time):
        """Test ASSIGNED state with no assigned_at timestamp."""
        inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assigned_at=None,
        )
        assert not incidents._is_new_assignee_required(fixed_time, inc)

    def test_in_progress_state_no_escalation(self, sample_incident, fixed_time):
        """Test that IN_PROGRESS state does not require escalation."""
        inc = replace(sample_incident, state=IncidentState.IN_PROGRESS)
        assert not incidents._is_new_assignee_required(fixed_time, inc)

    def test_resolved_state_no_escalation(self, sample_incident, fixed_time):
        """Test that RESOLVED state does not require escalation."""
        inc = replace(sample_incident, state=IncidentState.RESOLVED)
        assert not incidents._is_new_assignee_required(fixed_time, inc)

    def test_error_state_no_escalation(self, sample_incident, fixed_time):
        """Test that ERROR state does not require escalation."""
        inc = replace(sample_incident, state=IncidentState.ERROR)
        assert not incidents._is_new_assignee_required(fixed_time, inc)


class TestAssign:
    """Tests for the _assign function."""

    @patch("incidents._notify")
    @patch("incidents.store.get_contact_by_name")
    def test_assign_success(
        self, mock_get_contact, mock_notify, sample_incident, sample_contact, fixed_time
    ):
        """Test successful assignment."""
        mock_get_contact.return_value = sample_contact

        inc = incidents._assign(
            fixed_time, sample_incident, "alice@example.com", "manual assignment"
        )

        assert inc.state == IncidentState.ASSIGNED
        assert inc.assignee == "alice@example.com"
        assert inc.assigned_at == fixed_time
        assert inc.comment == "manual assignment"

        mock_get_contact.assert_called_once_with("alice@example.com")
        mock_notify.assert_called_once_with(sample_contact, sample_incident)

    @patch("incidents.store.get_contact_by_name")
    def test_assign_contact_not_found(
        self, mock_get_contact, sample_incident, fixed_time
    ):
        """Test assignment when contact is not found."""
        mock_get_contact.return_value = None

        inc = incidents._assign(
            fixed_time, sample_incident, "unknown@example.com", "auto-assigned"
        )

        assert inc.state == IncidentState.ERROR
        assert "unknown@example.com" in inc.comment
        assert "not found" in inc.comment


class TestAutoAssign:
    """Tests for the _auto_assign function."""

    @patch("incidents._assign")
    @patch("incidents.config.FAIL_ON_NO_ASSIGNEE", True)
    def test_auto_assign_no_schedule(self, mock_assign, sample_incident, fixed_time):
        """Test auto-assignment when no schedule is available."""
        inc = incidents._auto_assign(fixed_time, sample_incident, None)

        assert inc.state == IncidentState.ERROR
        assert inc.comment == "no schedule set"
        mock_assign.assert_not_called()

    @patch("incidents.config.FAIL_ON_NO_ASSIGNEE", False)
    def test_auto_assign_no_schedule_no_fail(self, sample_incident, fixed_time):
        """Test auto-assignment when FAIL_ON_NO_ASSIGNEE is False."""
        inc = incidents._auto_assign(fixed_time, sample_incident, None)

        assert inc.state == IncidentState.PENDING
        assert inc.comment == "no schedule set"

    @patch("incidents._assign")
    @patch("incidents.config.FAIL_ON_NO_ASSIGNEE", True)
    def test_auto_assign_empty_schedule(
        self, mock_assign, sample_incident, sample_schedule, fixed_time
    ):
        """Test auto-assignment when schedule has no assignees."""
        empty_schedule = replace(sample_schedule, assignees=[])
        inc = incidents._auto_assign(fixed_time, sample_incident, empty_schedule)

        assert inc.state == IncidentState.ERROR
        assert inc.comment == "schedule has no assignees"
        mock_assign.assert_not_called()

    @patch("incidents._assign")
    def test_auto_assign_success(
        self, mock_assign, sample_incident, sample_schedule, fixed_time
    ):
        """Test successful auto-assignment."""
        expected_inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="alice@example.com",
        )
        mock_assign.return_value = expected_inc

        inc = incidents._auto_assign(fixed_time, sample_incident, sample_schedule)

        mock_assign.assert_called_once_with(
            fixed_time, sample_incident, "alice@example.com", "auto-assigned"
        )
        assert inc == expected_inc

    @patch("incidents._assign")
    def test_auto_assign_next_in_rotation(
        self, mock_assign, sample_incident, sample_schedule, fixed_time
    ):
        """Test auto-assignment gets next person in rotation."""
        inc_with_assignee = replace(sample_incident, assignee="alice@example.com")
        expected_inc = replace(
            inc_with_assignee,
            state=IncidentState.ASSIGNED,
            assignee="bob@example.com",
        )
        mock_assign.return_value = expected_inc

        incidents._auto_assign(fixed_time, inc_with_assignee, sample_schedule)

        mock_assign.assert_called_once_with(
            fixed_time, inc_with_assignee, "bob@example.com", "auto-assigned"
        )


class TestHandleWebhookResponse:
    """Tests for the _handle_webhook_response function."""

    def test_ack_action(self, sample_incident):
        """Test acknowledgement action."""
        form = {"action": "ack"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.IN_PROGRESS
        assert "ack'd via webhook" in inc.comment

    def test_ack_action_short_form(self, sample_incident):
        """Test acknowledgement action using short form."""
        form = {"action": "a"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.IN_PROGRESS

    def test_ack_with_user(self, sample_incident):
        """Test acknowledgement with user information."""
        form = {"action": "ack"}
        user = {"email": "alice@example.com"}
        inc = incidents._handle_webhook_response(form, user, sample_incident)

        assert inc.state == IncidentState.IN_PROGRESS
        assert "alice@example.com" in inc.comment

    def test_resolve_action(self, sample_incident):
        """Test resolve action."""
        form = {"action": "resolve"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.RESOLVED
        assert "resolved via webhook" in inc.comment

    def test_resolve_action_short_form(self, sample_incident):
        """Test resolve action using short form."""
        form = {"action": "r"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.RESOLVED

    def test_escalate_action(self, sample_incident):
        """Test escalate action."""
        form = {"action": "escalate"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.PENDING
        assert "escalated" in inc.comment

    def test_escalate_action_short_form(self, sample_incident):
        """Test escalate action using short form."""
        form = {"action": "e"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert inc.state == IncidentState.PENDING

    @patch("incidents._assign")
    @patch("incidents._now")
    def test_take_action(self, mock_now, mock_assign, sample_incident, fixed_time):
        """Test take action with user."""
        mock_now.return_value = fixed_time
        expected_inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="alice@example.com",
        )
        mock_assign.return_value = expected_inc

        form = {"action": "take"}
        user = {"email": "alice@example.com"}
        inc = incidents._handle_webhook_response(form, user, sample_incident)

        mock_assign.assert_called_once()
        assert inc == expected_inc

    def test_take_action_no_user(self, sample_incident):
        """Test take action without user information."""
        form = {"action": "take"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert "take attempted but no user info" in inc.comment

    @patch("incidents._assign")
    @patch("incidents._now")
    def test_assign_action(self, mock_now, mock_assign, sample_incident, fixed_time):
        """Test manual assignment action."""
        mock_now.return_value = fixed_time
        expected_inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="bob@example.com",
        )
        mock_assign.return_value = expected_inc

        form = {"action": "assign", "assignee": "bob@example.com"}
        incidents._handle_webhook_response(form, None, sample_incident)

        mock_assign.assert_called_once_with(
            fixed_time,
            sample_incident,
            "bob@example.com",
            "manually assigned via webhook",
        )

    def test_assign_action_no_assignee(self, sample_incident):
        """Test manual assignment without assignee."""
        form = {"action": "assign"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert "assign: no assignee given" in inc.comment

    @patch("incidents._notify")
    @patch("incidents.store.get_contact_by_name")
    def test_notify_action(
        self, mock_get_contact, mock_notify, sample_incident, sample_contact
    ):
        """Test notify action."""
        inc_with_assignee = replace(sample_incident, assignee="alice@example.com")
        mock_get_contact.return_value = sample_contact

        form = {"action": "notify"}
        inc = incidents._handle_webhook_response(form, None, inc_with_assignee)

        mock_get_contact.assert_called_once_with("alice@example.com")
        mock_notify.assert_called_once_with(sample_contact, inc_with_assignee)
        assert "notified assignee via webhook" in inc.comment

    def test_notify_action_no_assignee(self, sample_incident):
        """Test notify action without assignee."""
        form = {"action": "notify"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert "notify: no assignee set" in inc.comment

    @patch("incidents.store.get_contact_by_name")
    def test_notify_action_contact_not_found(self, mock_get_contact, sample_incident):
        """Test notify action when contact is not found."""
        inc_with_assignee = replace(sample_incident, assignee="unknown@example.com")
        mock_get_contact.return_value = None

        form = {"action": "notify"}
        inc = incidents._handle_webhook_response(form, None, inc_with_assignee)

        assert "not found in contacts" in inc.comment

    def test_unknown_action(self, sample_incident):
        """Test unknown action."""
        form = {"action": "unknown_action"}
        inc = incidents._handle_webhook_response(form, None, sample_incident)

        assert "unknown action 'unknown_action'" in inc.comment


class TestRun:
    """Tests for the run function."""

    @patch("incidents.subscribe")
    @patch("incidents.next_event")
    @patch("incidents.store.update_incident")
    @patch("incidents.store.get_schedule_row")
    @patch("incidents._auto_assign")
    @patch("incidents._is_new_assignee_required")
    @patch("incidents._now")
    def test_run_auto_assign_then_resolve(
        self,
        mock_now,
        mock_is_new_assignee,
        mock_auto_assign,
        mock_get_schedule,
        mock_update,
        mock_next_event,
        mock_subscribe,
        sample_incident,
        sample_schedule,
        fixed_time,
    ):
        """Test run function with auto-assignment followed by resolution."""
        # Setup
        mock_now.return_value = fixed_time
        mock_subscription = Mock()
        mock_subscribe.return_value = mock_subscription

        # First iteration: auto-assign
        assigned_inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="alice@example.com",
            assigned_at=fixed_time,
        )

        # Second iteration: resolve via webhook
        resolved_inc = replace(assigned_inc, state=IncidentState.RESOLVED)

        mock_is_new_assignee.side_effect = [True, False]
        mock_get_schedule.return_value = sample_schedule
        mock_auto_assign.return_value = assigned_inc

        webhook_data = Mock()
        webhook_data.body.form = {"action": "resolve"}
        webhook_data.get.return_value = {"email": "alice@example.com"}

        mock_next_event.side_effect = [None, webhook_data]

        # Patch _handle_webhook_response to return resolved incident
        with patch("incidents._handle_webhook_response", return_value=resolved_inc):
            incidents.run(sample_incident)

        # Verify subscription
        mock_subscribe.assert_called_once()
        assert "incident_dashboard_webhook" in mock_subscribe.call_args[0]
        assert sample_incident.unique_id in mock_subscribe.call_args[1]["filter"]

        # Verify store updates
        assert mock_update.call_count == 2
        mock_update.assert_any_call(assigned_inc)
        mock_update.assert_any_call(resolved_inc)

    @patch("incidents.subscribe")
    @patch("incidents.next_event")
    @patch("incidents.store.update_incident")
    @patch("incidents.store.get_schedule_row")
    @patch("incidents._auto_assign")
    @patch("incidents._is_new_assignee_required")
    @patch("incidents._now")
    def test_run_escalation_timeout(
        self,
        mock_now,
        mock_is_new_assignee,
        mock_auto_assign,
        mock_get_schedule,
        mock_update,
        mock_next_event,
        mock_subscribe,
        sample_incident,
        sample_schedule,
        fixed_time,
    ):
        """Test run function with escalation after timeout."""
        mock_now.return_value = fixed_time
        mock_subscription = Mock()
        mock_subscribe.return_value = mock_subscription

        # First iteration: assign to alice
        assigned_alice = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="alice@example.com",
            assigned_at=fixed_time,
        )

        # Second iteration: escalate to bob
        assigned_bob = replace(
            assigned_alice,
            assignee="bob@example.com",
        )

        # Third iteration: resolve
        resolved_inc = replace(assigned_bob, state=IncidentState.RESOLVED)

        mock_is_new_assignee.side_effect = [True, True, False]
        mock_get_schedule.return_value = sample_schedule
        mock_auto_assign.side_effect = [assigned_alice, assigned_bob]

        webhook_data = Mock()
        webhook_data.body.form = {"action": "resolve"}
        webhook_data.get.return_value = None

        mock_next_event.side_effect = [None, None, webhook_data]

        with patch("incidents._handle_webhook_response", return_value=resolved_inc):
            incidents.run(sample_incident)

        # Verify both escalations occurred
        assert mock_auto_assign.call_count == 2
        assert mock_update.call_count == 3

    @patch("incidents.subscribe")
    @patch("incidents.next_event")
    @patch("incidents.store.update_incident")
    @patch("incidents.store.get_schedule_row")
    @patch("incidents._auto_assign")
    @patch("incidents._is_new_assignee_required")
    @patch("incidents._now")
    def test_run_immediate_error(
        self,
        mock_now,
        mock_is_new_assignee,
        mock_auto_assign,
        mock_get_schedule,
        mock_update,
        mock_next_event,
        mock_subscribe,
        sample_incident,
        fixed_time,
    ):
        """Test run function when auto-assignment fails immediately."""
        mock_now.return_value = fixed_time
        mock_subscription = Mock()
        mock_subscribe.return_value = mock_subscription

        error_inc = replace(
            sample_incident,
            state=IncidentState.ERROR,
            comment="no schedule set",
        )

        mock_is_new_assignee.return_value = True
        mock_get_schedule.return_value = None
        mock_auto_assign.return_value = error_inc

        incidents.run(sample_incident)

        # Should update once with error state and then exit
        mock_update.assert_called_once_with(error_inc)
        # next_event should not be called since state is not active
        mock_next_event.assert_not_called()

    @patch("incidents.subscribe")
    @patch("incidents.next_event")
    @patch("incidents.store.update_incident")
    @patch("incidents._is_new_assignee_required")
    @patch("incidents._now")
    def test_run_webhook_only_no_assignment(
        self,
        mock_now,
        mock_is_new_assignee,
        mock_update,
        mock_next_event,
        mock_subscribe,
        sample_incident,
        fixed_time,
    ):
        """Test run function with webhook response without auto-assignment."""
        mock_now.return_value = fixed_time
        mock_subscription = Mock()
        mock_subscribe.return_value = mock_subscription

        # Incident is already assigned, no new assignee needed
        assigned_inc = replace(
            sample_incident,
            state=IncidentState.ASSIGNED,
            assignee="alice@example.com",
        )

        resolved_inc = replace(assigned_inc, state=IncidentState.RESOLVED)

        mock_is_new_assignee.return_value = False

        webhook_data = Mock()
        webhook_data.body.form = {"action": "resolve"}
        webhook_data.get.return_value = None

        mock_next_event.return_value = webhook_data

        with patch("incidents._handle_webhook_response", return_value=resolved_inc):
            incidents.run(assigned_inc)

        # Should only update once with resolved state
        mock_update.assert_called_once_with(resolved_inc)



================================================
FILE: leash/test_model.py
================================================
"""Tests for model.py data structures and methods."""

from datetime import UTC  # noqa: I001
from datetime import datetime

import pytest

from model import Contact
from model import Incident
from model import IncidentState
from model import ScheduleRow


class TestContact:
    """Tests for Contact class."""

    def test_from_row_with_all_fields(self):
        """Test creating a Contact from a complete row."""
        row = ["John Doe", "john@example.com", "+1234567890"]
        contact = Contact.from_row(row)

        assert contact.name == "John Doe"
        assert contact.email == "john@example.com"
        assert contact.phone == "+1234567890"

    def test_from_row_with_name_only(self):
        """Test creating a Contact from a row with only name."""
        row = ["Jane Smith"]
        contact = Contact.from_row(row)

        assert contact.name == "Jane Smith"
        assert contact.email is None
        assert contact.phone is None

    def test_from_row_with_name_and_email(self):
        """Test creating a Contact from a row with name and email only."""
        row = ["Bob Wilson", "bob@example.com"]
        contact = Contact.from_row(row)

        assert contact.name == "Bob Wilson"
        assert contact.email == "bob@example.com"
        assert contact.phone is None

    def test_from_row_with_empty_email(self):
        """Test creating a Contact with empty string for email."""
        row = ["Alice Brown", "", "+9876543210"]
        contact = Contact.from_row(row)

        assert contact.name == "Alice Brown"
        assert contact.email == ""
        assert contact.phone == "+9876543210"


class TestScheduleRow:
    """Tests for ScheduleRow class."""

    def test_from_row(self):
        """Test creating a ScheduleRow from a row."""
        row = ["01-01-2025 00:00", "01-07-2025 23:59", "Alice", "Bob", "Charlie"]
        schedule = ScheduleRow.from_row(row)

        assert schedule.start_time == datetime(2025, 1, 1, 0, 0, 0, tzinfo=UTC)
        assert schedule.end_time == datetime(2025, 1, 7, 23, 59, 0, tzinfo=UTC)
        assert schedule.assignees == ["Alice", "Bob", "Charlie"]

    def test_from_row_filters_empty_assignees(self):
        """Test that from_row filters out empty strings from assignees."""
        row = ["01-01-2025 00:00", "01-07-2025 23:59", "Alice", "", "Bob", ""]
        schedule = ScheduleRow.from_row(row)

        assert schedule.assignees == ["Alice", "Bob"]

    def test_row_property(self):
        """Test that row property returns correct format."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob"],
        )
        row = schedule.row

        assert row[0] == "01-01-2025 00:00"
        assert row[1] == "01-07-2025 23:59"
        assert row[2:] == ["Alice", "Bob"]

    def test_match_within_range(self):
        """Test match returns True for time within schedule period."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice"],
        )

        assert schedule.match(datetime(2025, 1, 3, 12, 0, 0)) is True  # noqa: DTZ001

    def test_match_at_start_boundary(self):
        """Test match returns True for time at start boundary."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice"],
        )

        assert schedule.match(datetime(2025, 1, 1, 0, 0, 0)) is True  # noqa: DTZ001

    def test_match_at_end_boundary(self):
        """Test match returns True for time at end boundary."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice"],
        )

        assert schedule.match(datetime(2025, 1, 7, 23, 59, 59)) is True  # noqa: DTZ001

    def test_match_before_range(self):
        """Test match returns False for time before schedule period."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice"],
        )

        assert schedule.match(datetime(2024, 12, 31, 23, 59, 59)) is False  # noqa: DTZ001

    def test_match_after_range(self):
        """Test match returns False for time after schedule period."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice"],
        )

        assert schedule.match(datetime(2025, 1, 8, 0, 0, 0)) is False  # noqa: DTZ001

    def test_get_next_assignee_first_with_no_current(self):
        """Test get_next_assignee returns first assignee when current is None."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob", "Charlie"],
        )

        assert schedule.get_next_assignee(None) == "Alice"

    def test_get_next_assignee_first_with_empty_current(self):  # noqa: E501
        """Test get_next_assignee returns first assignee when current is empty string."""  # noqa: E501
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob", "Charlie"],
        )

        assert schedule.get_next_assignee("") == "Alice"

    def test_get_next_assignee_rotates(self):
        """Test get_next_assignee rotates through assignees."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob", "Charlie"],
        )

        assert schedule.get_next_assignee("Alice") == "Bob"
        assert schedule.get_next_assignee("Bob") == "Charlie"

    def test_get_next_assignee_wraps_around(self):
        """Test get_next_assignee wraps around to first assignee."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob", "Charlie"],
        )

        assert schedule.get_next_assignee("Charlie") == "Alice"

    def test_get_next_assignee_empty_list(self):
        """Test get_next_assignee returns None when no assignees."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=[],
        )

        assert schedule.get_next_assignee(None) is None
        assert schedule.get_next_assignee("Alice") is None

    def test_get_next_assignee_not_found_resets(self):
        """Test get_next_assignee resets to first when current not in list."""
        schedule = ScheduleRow(
            start_time=datetime(2025, 1, 1, 0, 0, 0),  # noqa: DTZ001
            end_time=datetime(2025, 1, 7, 23, 59, 59),  # noqa: DTZ001
            assignees=["Alice", "Bob"],
        )

        # When current assignee isn't in the list, it should raise ValueError
        # based on line 71: i = self.assignees.index(curr) will raise ValueError
        with pytest.raises(ValueError):  # noqa: PT011
            schedule.get_next_assignee("Charlie")


class TestIncidentState:
    """Tests for IncidentState enum."""

    def test_is_active_pending(self):
        """Test is_active returns True for PENDING state."""
        assert IncidentState.PENDING.is_active is True

    def test_is_active_assigned(self):
        """Test is_active returns True for ASSIGNED state."""
        assert IncidentState.ASSIGNED.is_active is True

    def test_is_active_in_progress(self):
        """Test is_active returns True for IN_PROGRESS state."""
        assert IncidentState.IN_PROGRESS.is_active is True

    def test_is_active_resolved(self):
        """Test is_active returns False for RESOLVED state."""
        assert IncidentState.RESOLVED.is_active is False

    def test_is_active_error(self):
        """Test is_active returns False for ERROR state."""
        assert IncidentState.ERROR.is_active is False

    def test_state_values(self):
        """Test that state enum values are correct."""
        assert IncidentState.PENDING.value == "pending"
        assert IncidentState.ASSIGNED.value == "assigned"
        assert IncidentState.IN_PROGRESS.value == "in_progress"
        assert IncidentState.RESOLVED.value == "resolved"
        assert IncidentState.ERROR.value == "error"


class TestIncident:
    """Tests for Incident class."""

    def test_from_row_complete(self):
        """Test creating an Incident from a complete row."""
        row = [
            "123",
            "01-15-2025 10:30",
            "assigned",
            "Alice",
            "01-15-2025 10:35",
            "Working on it",
            "Server down",
            "=HYPERLINK(...)",
            "unique-123",
        ]
        incident = Incident.from_row(row)

        assert incident.id == "123"
        assert incident.started_at == datetime(2025, 1, 15, 10, 30, 0, tzinfo=UTC)
        assert incident.state == IncidentState.ASSIGNED
        assert incident.assignee == "Alice"
        assert incident.assigned_at == datetime(2025, 1, 15, 10, 35, 0, tzinfo=UTC)
        assert incident.comment == "Working on it"
        assert incident.details == "Server down"
        assert incident.unique_id == "unique-123"

    def test_from_row_minimal(self):
        """Test creating an Incident from a minimal row with no optional fields."""
        row = [
            "456",
            "01-15-2025 10:30",
            "pending",
            "",
            "",
            "",
            "Database error",
            "",
            "unique-456",
        ]
        incident = Incident.from_row(row)

        assert incident.id == "456"
        assert incident.started_at == datetime(2025, 1, 15, 10, 30, 0, tzinfo=UTC)
        assert incident.state == IncidentState.PENDING
        assert incident.assignee is None
        assert incident.assigned_at is None
        assert incident.comment is None
        assert incident.details == "Database error"
        assert incident.unique_id == "unique-456"

    def test_row_property_complete(self):
        """Test row property returns correct format for complete incident."""
        incident = Incident(
            id="789",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.IN_PROGRESS,
            assignee="Bob",
            assigned_at=datetime(2025, 1, 15, 10, 35, 0),  # noqa: DTZ001
            comment="In progress",
            details="Network issue",
            unique_id="unique-789",
        )
        row = incident.row

        assert row[0] == 789
        assert row[1] == "01-15-2025 10:30"
        assert row[2] == "in_progress"
        assert row[3] == "Bob"
        assert row[4] == "01-15-2025 10:35"
        assert row[5] == "In progress"
        assert row[6] == "Network issue"
        assert row[8] == "unique-789"

    def test_row_property_minimal(self):
        """Test row property returns correct format for minimal incident."""
        incident = Incident(
            id="101",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="CPU spike",
            unique_id="unique-101",
        )
        row = incident.row

        assert row[0] == 101
        assert row[1] == "01-15-2025 10:30"
        assert row[2] == "pending"
        assert row[3] is None
        assert row[4] == ""
        assert row[5] == ""
        assert row[6] == "CPU spike"
        assert row[8] == "unique-101"

    def test_dashboard_url_with_config(self, monkeypatch):
        """Test dashboard_url property when webhook URL is configured."""
        monkeypatch.setattr(
            "config.INCIDENT_DASHBOARD_WEBHOOK_URL", "https://example.com/dashboard"
        )

        incident = Incident(
            id="202",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="Test incident",
            unique_id="unique-202",
        )

        assert (
            incident.dashboard_url
            == "https://example.com/dashboard?unique_id=unique-202"
        )

    def test_dashboard_url_without_config(self, monkeypatch):
        """Test dashboard_url property when webhook URL is not configured."""
        monkeypatch.setattr("config.INCIDENT_DASHBOARD_WEBHOOK_URL", None)

        incident = Incident(
            id="303",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="Test incident",
            unique_id="unique-303",
        )

        assert incident.dashboard_url == ""

    def test_dashboard_url_with_empty_config(self, monkeypatch):
        """Test dashboard_url property when webhook URL is empty string."""
        monkeypatch.setattr("config.INCIDENT_DASHBOARD_WEBHOOK_URL", "")

        incident = Incident(
            id="404",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="Test incident",
            unique_id="unique-404",
        )

        assert incident.dashboard_url == ""

    def test_row_property_includes_hyperlink_with_url(self, monkeypatch):  # noqa: E501
        """Test row property includes hyperlink formula when dashboard URL is configured."""  # noqa: E501
        monkeypatch.setattr(
            "config.INCIDENT_DASHBOARD_WEBHOOK_URL", "https://example.com/dashboard"
        )

        incident = Incident(
            id="505",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="Test incident",
            unique_id="unique-505",
        )
        row = incident.row

        assert (
            row[7]
            == '=HYPERLINK("https://example.com/dashboard?unique_id=unique-505", "ACT")'
        )

    def test_row_property_no_hyperlink_without_url(self, monkeypatch):
        """Test row property has empty string for hyperlink when no dashboard URL."""
        monkeypatch.setattr("config.INCIDENT_DASHBOARD_WEBHOOK_URL", None)

        incident = Incident(
            id="606",
            started_at=datetime(2025, 1, 15, 10, 30, 0),  # noqa: DTZ001
            state=IncidentState.PENDING,
            details="Test incident",
            unique_id="unique-606",
        )
        row = incident.row

        assert row[7] == ""



================================================
FILE: leash/test_store.py
================================================
"""Tests for Google Sheets storage backend functionality."""

from datetime import datetime, timedelta
import os
from unittest.mock import MagicMock
from unittest.mock import Mock
from unittest.mock import patch
from zoneinfo import ZoneInfo

from gspread.exceptions import WorksheetNotFound

import pytest


# Set required environment variables before importing store
os.environ["GOOGLE_SPREADSHEET_ID"] = "test_spreadsheet_id"

# Mock autokitteh dependencies before importing store
with (
    patch("autokitteh.get_webhook_url", return_value="http://test.webhook.url"),
    patch("autokitteh.google.gspread_client") as mock_gspread,
):
    mock_client = MagicMock()
    mock_gspread.return_value = mock_client
    import store

from model import Contact
from model import Incident
from model import IncidentState
from model import ScheduleRow


@pytest.fixture
def fixed_time():
    """Return a fixed datetime for testing."""
    return datetime(2024, 1, 15, 10, 0, 0, tzinfo=ZoneInfo("UTC"))


@pytest.fixture
def sample_incident(fixed_time):
    """Return a sample incident for testing."""
    return Incident(
        id="42",
        details="Test incident details",
        state=IncidentState.PENDING,
        started_at=fixed_time,
        unique_id="test_unique_id_xyz",
    )


@pytest.fixture
def sample_contact():
    """Return a sample contact for testing."""
    return Contact(
        name="alice@example.com",
        email="alice@example.com",
        phone="+1234567890",
    )


@pytest.fixture
def sample_schedule(fixed_time):
    """Return a sample schedule for testing."""
    return ScheduleRow(
        start_time=fixed_time - timedelta(hours=1),
        end_time=fixed_time + timedelta(hours=23),
        assignees=["alice@example.com", "bob@example.com"],
    )


class TestGet:
    """Tests for the get function."""

    def test_get_existing_worksheet(self):
        """Test getting an existing worksheet."""
        mock_worksheet = Mock()
        store._client.worksheet = Mock(return_value=mock_worksheet)

        result = store.get("test_sheet")

        assert result == mock_worksheet
        store._client.worksheet.assert_called_once_with("test_sheet")

    def test_get_nonexistent_worksheet(self):
        """Test getting a worksheet that doesn't exist."""
        store._client.worksheet = Mock(side_effect=WorksheetNotFound("Not found"))

        result = store.get("nonexistent_sheet")

        assert result is None
        store._client.worksheet.assert_called_once_with("nonexistent_sheet")


class TestNextIncidentId:
    """Tests for the next_incident_id function."""

    def test_next_incident_id_with_value(self):
        """Test getting next incident ID when value exists."""
        mock_cell = Mock()
        mock_cell.value = "42"
        store._scratchpad.acell = Mock(return_value=mock_cell)

        result = store.next_incident_id()

        assert result == "42"
        store._scratchpad.acell.assert_called_once_with("B1")

    def test_next_incident_id_default(self):
        """Test getting next incident ID when no value exists."""
        mock_cell = Mock()
        mock_cell.value = None
        store._scratchpad.acell = Mock(return_value=mock_cell)

        result = store.next_incident_id()

        assert result == "1"


class TestAddIncident:
    """Tests for the add_incident function."""

    def test_add_incident(self, sample_incident):
        """Test adding an incident to the sheet."""
        store._incidents.append_row = Mock()

        store.add_incident(sample_incident)

        store._incidents.append_row.assert_called_once()
        call_args = store._incidents.append_row.call_args
        assert call_args[0][0] == sample_incident.row
        assert "value_input_option" in call_args[1]


class TestGetIncidentByUniqueId:
    """Tests for the get_incident_by_unique_id function."""

    def test_get_incident_found(self, sample_incident):
        """Test getting an incident that exists."""
        mock_cell = Mock()
        mock_cell.row = 2
        store._incidents.find = Mock(return_value=mock_cell)
        store._incidents.row_values = Mock(return_value=sample_incident.row)

        result = store.get_incident_by_unique_id("test_unique_id_xyz")

        assert result is not None
        assert result.id == sample_incident.id
        assert result.unique_id == sample_incident.unique_id
        store._incidents.find.assert_called_once_with("test_unique_id_xyz", in_column=9)

    def test_get_incident_not_found(self):
        """Test getting an incident that doesn't exist."""
        store._incidents.find = Mock(return_value=None)

        result = store.get_incident_by_unique_id("nonexistent_id")

        assert result is None
        store._incidents.find.assert_called_once_with("nonexistent_id", in_column=9)


class TestUpdateIncident:
    """Tests for the update_incident function."""

    def test_update_incident_success(self, sample_incident):
        """Test updating an existing incident."""
        mock_cell = Mock()
        mock_cell.row = 3
        store._incidents.find = Mock(return_value=mock_cell)
        store._incidents.update = Mock()

        store.update_incident(sample_incident)

        store._incidents.find.assert_called_once_with(
            str(sample_incident.id), in_column=1
        )
        store._incidents.update.assert_called_once()
        call_args = store._incidents.update.call_args
        assert call_args[0][0] == [sample_incident.row]
        assert call_args[0][1] == "A3"

    def test_update_incident_not_found(self, sample_incident):
        """Test updating an incident that doesn't exist."""
        store._incidents.find = Mock(return_value=None)

        with pytest.raises(ValueError, match="Incident with id 42 not found"):
            store.update_incident(sample_incident)


class TestGetScheduleRow:
    """Tests for the get_schedule_row function."""

    def test_get_schedule_row_match(self, fixed_time, sample_schedule):
        """Test getting a schedule row that matches the time."""
        store._schedule.get_all_values = Mock(
            return_value=[
                ScheduleRow.labels,
                sample_schedule.row,
            ]
        )

        result = store.get_schedule_row(fixed_time)

        assert result is not None
        assert result.start_time == sample_schedule.start_time
        assert result.end_time == sample_schedule.end_time
        assert result.assignees == sample_schedule.assignees

    def test_get_schedule_row_no_match(self, fixed_time, sample_schedule):
        """Test getting a schedule row when time doesn't match."""
        # Create schedule that doesn't match the fixed_time
        past_schedule = ScheduleRow(
            start_time=fixed_time - timedelta(days=2),
            end_time=fixed_time - timedelta(days=1),
            assignees=["alice@example.com"],
        )

        store._schedule.get_all_values = Mock(
            return_value=[
                ScheduleRow.labels,
                past_schedule.row,
            ]
        )

        result = store.get_schedule_row(fixed_time)

        assert result is None

    def test_get_schedule_row_multiple_matches_returns_first(self, fixed_time):
        """Test that when multiple schedules match, the first one is returned."""
        schedule1 = ScheduleRow(
            start_time=fixed_time - timedelta(hours=1),
            end_time=fixed_time + timedelta(hours=1),
            assignees=["alice@example.com"],
        )
        schedule2 = ScheduleRow(
            start_time=fixed_time - timedelta(hours=2),
            end_time=fixed_time + timedelta(hours=2),
            assignees=["bob@example.com"],
        )

        store._schedule.get_all_values = Mock(
            return_value=[
                ScheduleRow.labels,
                schedule1.row,
                schedule2.row,
            ]
        )

        result = store.get_schedule_row(fixed_time)

        assert result is not None
        assert result.assignees == ["alice@example.com"]

    def test_get_schedule_row_invalid_row(self, fixed_time, sample_schedule):
        """Test getting a schedule row with an invalid row in the data."""
        store._schedule.get_all_values = Mock(
            return_value=[
                ScheduleRow.labels,
                ["invalid", "data"],  # Invalid row
                sample_schedule.row,  # Valid row
            ]
        )

        result = store.get_schedule_row(fixed_time)

        # Should skip invalid row and return the valid one
        assert result is not None
        assert result.assignees == sample_schedule.assignees

    def test_get_schedule_row_empty(self, fixed_time):
        """Test getting a schedule row when no schedules exist."""
        store._schedule.get_all_values = Mock(return_value=[ScheduleRow.labels])

        result = store.get_schedule_row(fixed_time)

        assert result is None


class TestGetContactByName:
    """Tests for the get_contact_by_name function."""

    def test_get_contact_by_name_found(self, sample_contact):
        """Test getting a contact that exists."""
        mock_cell = Mock()
        mock_cell.row = 2
        store._contacts = Mock()
        store._contacts.find = Mock(return_value=mock_cell)
        store._contacts.row_values = Mock(
            return_value=[
                sample_contact.name,
                sample_contact.email,
                sample_contact.phone,
            ]
        )

        result = store.get_contact_by_name("alice@example.com")

        assert result is not None
        assert result.name == sample_contact.name
        assert result.email == sample_contact.email
        assert result.phone == sample_contact.phone
        store._contacts.find.assert_called_once_with("alice@example.com", in_column=1)

    def test_get_contact_by_name_not_found(self):
        """Test getting a contact that doesn't exist."""
        store._contacts = Mock()
        store._contacts.find = Mock(return_value=None)

        result = store.get_contact_by_name("unknown@example.com")

        assert result is None

    def test_get_contact_by_name_no_contacts_sheet(self):
        """Test getting a contact when contacts sheet doesn't exist."""
        store._contacts = None

        result = store.get_contact_by_name("alice@example.com")

        assert result is None


class TestGetContactByEmail:
    """Tests for the get_contact_by_email function."""

    def test_get_contact_by_email_found(self, sample_contact):
        """Test getting a contact by email that exists."""
        mock_cell = Mock()
        mock_cell.row = 2
        store._contacts = Mock()
        store._contacts.find = Mock(return_value=mock_cell)
        store._contacts.row_values = Mock(
            return_value=[
                sample_contact.name,
                sample_contact.email,
                sample_contact.phone,
            ]
        )

        result = store.get_contact_by_email("alice@example.com")

        assert result is not None
        assert result.name == sample_contact.name
        assert result.email == sample_contact.email
        assert result.phone == sample_contact.phone
        store._contacts.find.assert_called_once_with("alice@example.com", in_column=2)

    def test_get_contact_by_email_not_found(self):
        """Test getting a contact by email that doesn't exist."""
        store._contacts = Mock()
        store._contacts.find = Mock(return_value=None)

        result = store.get_contact_by_email("unknown@example.com")

        assert result is None

    def test_get_contact_by_email_no_contacts_sheet(self):
        """Test getting a contact by email when contacts sheet doesn't exist."""
        store._contacts = None

        result = store.get_contact_by_email("alice@example.com")

        assert result is None



================================================
FILE: leash/utils.py
================================================
"""Utility functions for date and time formatting.

This module provides helper functions for working with datetime objects,
including formatting and parsing timestamps according to the configured
timezone and format settings.
"""

from datetime import datetime

import config


def format_ts(t: datetime) -> str:
    """Return a nice ISO format string for a datetime."""
    return t.strftime(config.TS_FORMAT)


def parse_ts(s: str) -> datetime:
    """Parse a datetime from a string in the configured timezone."""
    dt = datetime.strptime(s.replace("/", "-"), config.TS_FORMAT)  # noqa: DTZ007
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=config.TZ)
    return dt



================================================
FILE: project_template/autokitteh.yaml
================================================
# Simple AutoKitteh project configuration (manifest file).
# This is the basic setup needed for any AutoKitteh project.
# If you're using the cloud platform, you can export the project to get this file.

# Version is always required - use v1.
version: v1

# Project configuration
project:
  # Project name - must be unique and not use spaces.
  name: simple_slack_bot

  # Single trigger that responds to Slack messages.
  triggers:
    # This trigger activates when someone sends a message in Slack.
    - name: slack_message

      # Must match the connection name below.
      connection: slack_conn
      # Listen for any message in Slack.
      event_type: message
      # Function to call when a message is received.
      call: program.py:on_slack_message

  # Single connection to Slack
  connections:
    # Slack connection for receiving and sending messages.
    - name: slack_conn
      # Integration type - must be exact name.
      integration: slack



================================================
FILE: project_template/program.py
================================================
"""Simple Slack bot using AutoKitteh.

This bot listens to Slack messages and responds to basic commands.
"""

# AutoKitteh SDK - provides easy access to integrations.
# Import the specific client you need from autokitteh.{service}.
from autokitteh.slack import slack_client


# Initialize the Slack client using your connection name from autokitteh.yaml.
# The connection name "slack_conn" must match what's defined in your YAML.
slack = slack_client("slack_conn")


def on_slack_message(event):
    """Handle incoming Slack messages.

    This function runs every time someone sends a message in Slack.
    The 'event' parameter contains all the message details from Slack.
    """
    print("=== New Slack Message Received ===")

    try:
        # Get the important parts of the message.
        message_text = event.data.get("text", "")
        user_id = event.data.get("user", "")
        channel_id = event.data.get("channel", "")

        print(f"Message: {message_text}")
        print(f"From: {user_id}")
        print(f"Channel: {channel_id}")

        # Respond to simple commands
        if "hello" in message_text.lower():
            print("User said hello! Responding with greeting.")
            # To actually send a response:
            # slack.chat_postMessage(
            #     channel=channel_id,
            #     text="Hello! üëã Nice to meet you!"
            # )

        elif "help" in message_text.lower():
            print("User needs help! Sending help message.")
            # To send help:
            # slack.chat_postMessage(
            #     channel=channel_id,
            #     text="I can respond to 'hello' and 'help' commands!"
            # )

        else:
            print("Regular message - just logging it.")

        return {"status": "success"}
    # Handle exceptions gracefully
    except AttributeError as e:
        print(f"Error processing message: {e}")
        return {"status": "error", "message": str(e)}
    except KeyError as e:
        print(f"Missing expected key: {e}")
        return {"status": "error", "message": f"Missing key: {e}"}



================================================
FILE: project_template/readme_template.md
================================================
<!--
Template Instructions:
- Remove these comment blocks after using
- Replace all {PLACEHOLDERS} with your content
- Delete any optional sections you don't need
- Keep the formatting (---, #, ##, etc.)
- Suggested formats and examples are provided for guidance.
-->

---

title: {PROJECT_NAME} <!-- Provide a short, descriptive name for your project -->
description: {ONE_LINE_DESCRIPTION} <!-- One-line summary of what the workflow does, avoid filler words -->
integrations: {LIST_OF_INTEGRATIONS} <!-- e.g., ["jira", "calendar"] -->
categories: {LIST_OF_CATEGORIES} <!-- e.g., ["DevOps"] -->
tags: {LIST_OF_TAGS} <!-- e.g., ["webhook_handling", "data_processing"] -->

---

# {PROJECT_NAME} <!-- Same as the title above, but capitalized -->

<!-- Replace with 2-3 sentences describing what your workflow does -->

This project automates {PRIMARY_AUTOMATION_TASK} by integrating {LIST_OF_INTEGRATIONS_PROSE} <!-- Write a sentence or two about the integrations used (e.g., "integrating Jira and Google Calendar for seamless task management"). -->

<!-- Optional section - Include only if API documentation is relevant -->

API documentation:

- {API_DOCUMENTATION} <!-- e.g., "Atlassian Jira: https://docs.autokitteh.com/integrations/atlassian/jira" -->

## How It Works

<!-- List 2-5 main steps of your workflow -->
<!-- Use action verbs to clearly describe each step -->

1. {STEP_1} <!-- e.g., "Detect new Jira issues" -->
2. {STEP_2} <!-- e.g., "Create corresponding Google Calendar events" -->
3. {STEP_3} <!-- Add more steps as needed -->

## Cloud Usage

1. Initialize your connections ({LIST_OF_INTEGRATIONS_PROSE})
2. {CONFIGURATION_STEP} <!-- e.g., "Edit the trigger settings" -->
<!-- If using a webhook trigger, add this as an additional step:
3. Copy the webhook URL from the "Triggers" tab (see the [instructions here](https://docs.autokitteh.com/get_started/deployment#webhook-urls))
   -->
4. {CONFIGURATION_STEP} <!-- Add more steps as needed -->
5. <!-- If the trigger is simple and differs from the Self-Hosted Deployment section, it can be included here. -->
6. Deploy project

<!-- Use ### if the trigger workflow differs from the Self-Hosted Deployment section or if the trigger instructions are complex -->

## Trigger Workflow

> [!IMPORTANT]
> Ensure all connections ({LIST_OF_INTEGRATIONS_PROSE}) are initialized; otherwise, the workflow will raise a `ConnectionInitError`.

<!-- Option 1: List of steps -->

1. {TRIGGER_STEP_1} <!-- e.g., "Navigate to your Jira project settings" -->
2. {TRIGGER_STEP_2} <!-- e.g., "Set up a webhook with the following URL: ..." -->
3. {TRIGGER_STEP_3} <!-- e.g., "Configure the webhook to trigger on issue updates" -->

<!-- OR Option 2: Simple description -->

{TRIGGER_DESCRIPTION} <!-- e.g., "Triggered via a webhook from Jira when an issue is updated." -->

## Self-Hosted Deployment

Follow [these detailed instructions](https://docs.autokitteh.com/get_started/deployment) to deploy the project on a self-hosted server.

<!-- Optional section - include only if self-hosted triggering differs from the section under Cloud Usage -->

### Trigger Workflow

<!-- Optional section -->

## Known Limitations

- {LIMITATION_1} <!-- e.g., "Does not support Socket Mode." -->
- {LIMITATION_2} <!-- e.g., "The polling mechanism is basic." -->

<!-- Optional section -->

## Visual Example

![Example Image](./images/{IMAGE_NAME})
{IMAGE_DESCRIPTION} <!-- Briefly describe the image, e.g., "A flowchart showing the integration process." -->



================================================
FILE: quickstart/README.md
================================================
title: Quickstart
description: Sample for quickstart
integrations: []
categories: ["Samples"]
tags: ["essential"]



================================================
FILE: quickstart/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes
# the minimal setup of an AutoKitteh project.

version: v1

project:
  name: quickstart

  triggers:
    - name: quickstart_webhook
      type: webhook
      event_type: get
      call: program.py:quickstart



================================================
FILE: quickstart/program.py
================================================
"""Handler for manual runs with a simple loop."""

import time


SLEEP_SECONDS = 1
ITERATIONS = 5


def quickstart(_):
    for i in range(ITERATIONS):
        print(f"Loop iteration: {i + 1} of {ITERATIONS}")
        time.sleep(SLEEP_SECONDS)



================================================
FILE: reliability/aws_health_monitor/README.md
================================================
title: AWS Health monitor
description: Announce AWS Health events in Slack channels, based on resource ownership data in a Google Sheet
integrations: ["aws", "slack", "googlesheets"]
categories: ["Reliability"]
tags: ["activity", "scheduled_tasks", "monitoring", "notifications", "data_processing", "essential"]



================================================
FILE: reliability/aws_health_monitor/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that announces AWS Health events in Slack
# channels, based on resource ownership data in a Google Sheet.

version: v1

project:
  name: aws_health_monitor

  vars:
    - name: GOOGLE_SHEET_URL
      value: https://docs.google.com/spreadsheets/d/1PalmLwSZOPW9k668_jU-wFI5xCj88a4mDfNUtJAupMQ/
    - name: TRIGGER_INTERVAL
      value: 1m

  connections:
    - name: aws_conn
      integration: aws
    - name: sheets_conn
      integration: googlesheets
    - name: slack_conn
      integration: slack

  triggers:
    - name: every_minute
      schedule: "@every 1m"
      call: program.py:on_schedule



================================================
FILE: reliability/aws_health_monitor/program.py
================================================
"""Announce AWS Health events in Slack, based on resource ownership in a Google Sheet.

API documentation:
- https://docs.aws.amazon.com/health/
- https://aws.amazon.com/blogs/mt/tag/aws-health-api/

See the configuration and deployment instructions in the README.md file.
"""

from datetime import datetime, timedelta, UTC
import json
import os

import autokitteh
from autokitteh.aws import boto3_client
from autokitteh.google import google_id, google_sheets_client
from autokitteh.slack import slack_client
from hubspot.crm.contacts.exceptions import ApiException


OWNERSHIP_DATA = os.getenv("GOOGLE_SHEET_URL", "")

slack = slack_client("slack_conn")


def on_schedule(_):
    """Workflow's entry-point, triggered at the beginning of every minute."""
    slack_channels = _read_google_sheet()
    events = _aws_health_events()

    if not events:
        print("No AWS Health events found.")
        return

    events_by_arn = {event["arn"]: event for event in events}
    for entity in _affected_aws_entities(events):
        project = entity.get("tags", {}).get("project")
        if not project:
            print(f"Error: AWS entity without project tag: {entity}")
            continue

        channel = slack_channels.get(project)
        affecting_events = [events_by_arn[arn] for arn in entity["eventArns"]]
        _post_slack_message(project, channel, entity, affecting_events)


@autokitteh.activity
def _read_google_sheet() -> dict[str, str]:
    """Read mapping of project tags to Slack channels from Google Sheet."""
    sheets = google_sheets_client("google_sheets_conn").spreadsheets().values()
    rows = sheets.get(spreadsheetId=google_id(OWNERSHIP_DATA), range="A:B").execute()
    return {row[0].strip(): row[1].strip() for row in rows.get("values", [])}


@autokitteh.activity
def _aws_health_events() -> list[dict]:
    """List all recent AWS Health events.

    This function currently fetches events for a single AWS account:
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/health/client/describe_events.html

    With a bit more code, you can also fetch events for multiple ones:
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/health/client/describe_events_for_organization.html
    """
    # Remove the unit suffix ("m") and parse as an integer.
    interval = int((os.getenv("TRIGGER_INTERVAL", "1m"))[:-1])
    try:
        end_time = datetime.now(UTC).replace(second=0, microsecond=0)
        start_time = end_time - timedelta(minutes=interval)
        filter = {"lastUpdatedTimes": [{"from": start_time, "to": end_time}]}

        aws = boto3_client("aws_conn", "health")
        resp = aws.describe_events(filter=filter)
        events = resp.get("events", [])

        next_token = resp.get("nextToken")
        while next_token:
            resp = aws.describe_events(filter=filter, nextToken=next_token)
            events += resp.get("events", [])
            next_token = resp.get("nextToken")

        return events

    except ApiException as e:
        print(f"Boto3 error: {e}")
        return []


@autokitteh.activity
def _affected_aws_entities(events: list[dict]) -> list[dict]:
    """List all AWS entities affected by the given AWS Health events.

    API reference:
    https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/health/client/describe_affected_entities.html
    """
    try:
        aws = boto3_client("aws_conn", "health")
        arns = [event["arn"] for event in events]

        filter = {"eventArns": arns}
        # Possible alternative: describe_affected_entities_for_organization.
        resp = aws.describe_affected_entities(filter=filter)
        entities = resp.get("entities", [])

        next_token = resp.get("nextToken")
        while next_token:
            resp = aws.describe_affected_entities(filter=filter, nextToken=next_token)
            entities += resp.get("entities", [])
            next_token = resp.get("nextToken")

        return entities
    except ApiException as e:
        print(f"Boto3 error: {e}")
        return []


def _post_slack_message(
    channel: str, project: str, entity: dict, affecting_events: list[dict]
):
    if not channel:
        print(f"Error: project tag {project!r} not found in {OWNERSHIP_DATA}")

    text = f"This AWS resource:\n```\n{json.dumps(entity, indent=4)}\n```"
    text += "\nis affected by these AWS Health events:"
    for i, event in enumerate(affecting_events, 1):
        text += f"\n{i}.\n```\n{json.dumps(event, indent=4)}\n```"

    print(f"Posting in Slack channel: {channel}")
    slack.chat_postMessage(channel=channel, text=text)



================================================
FILE: reliability/incidenter/README.md
================================================
title: Incident management automation
description: Connect separate systems to have seamless incident management
integrations: ["slack", "zoom", "height"]
categories: ["Reliability"]
tags: ["next_event", "subscribe", "interactive_workflows", "user_interactions", "event_loops", "notifications", "workflow_patterns"]



================================================
FILE: reliability/incidenter/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that automates incident management.

version: v1

project:
  name: incidenter

  vars:
    - name: SLACK_CHANNEL_PREFIX
      value: test_incident_
    - name: HEIGHT_LIST_ID
      value:

  connections:
    - name: height_conn
      integration: height
    - name: slack_conn
      integration: slack
    - name: zoom_conn
      integration: zoom

  triggers:
    - name: slack_app_mention
      event_type: app_mention
      connection: slack
      call: program.py:on_slack_app_mention



================================================
FILE: reliability/incidenter/height.py
================================================
"""Create Height tasks and add messages to them."""

import os
from urllib.parse import urljoin

from autokitteh.height import height_client


_ROOT_URL = "https://api.height.app/"

_HEIGHT_LIST_ID = os.getenv("HEIGHT_LIST_ID")

if not _HEIGHT_LIST_ID:
    raise ValueError("HEIGHT_LIST_ID project variable must be set")

height = height_client("height_conn")


def _post(path: str, data: dict) -> dict:
    resp = height.post(urljoin(_ROOT_URL, path), json=data)
    resp.raise_for_status()
    return resp.json()


def create_task(name: str, desc: str, status: str) -> dict:
    return _post(
        "tasks",
        {
            "type": "task",
            "name": name,
            "description": desc,
            "status": status,
            "listIds": [_HEIGHT_LIST_ID],
        },
    )


def add_task_message(task_id: str, msg: str) -> dict:
    return _post(
        "activities",
        {
            "type": "comment",
            "taskId": task_id,
            "message": msg,
        },
    )



================================================
FILE: reliability/incidenter/program.py
================================================
"""Tracks Slack-reported incidents, integrating with Height and Zoom."""

import os
import re

from autokitteh import next_event, subscribe
from autokitteh.slack import normalize_channel_name
from autokitteh.slack import slack_client

import height
import zoom


_CHANNEL_PREFIX = os.getenv("SLACK_CHANNEL_PREFIX", "")

slack_client = slack_client("slack_conn")


def on_slack_app_mention(event):
    # Another option is to put this straight in the trigger definition as "filter".
    m = re.compile(r"^<.+?>\s*incident\s*(.*)").match(event.data.text)
    if not m:
        print("irrelevant")
        return

    incident = _start(event.data.user, event.data.channel, event.data.ts, m.group(1))

    _track(incident)


def _start(
    slack_user: str, trigger_channel_id: str, trigger_ts: str, title: str
) -> dict:
    task = height.create_task(title, "New incident created from slack", "inProgress")

    zoom_url = zoom.create_meeting(f"Incident: {title}")

    name = f"{_CHANNEL_PREFIX}{task['index']}_{normalize_channel_name(title)}"
    resp = slack_client.conversations_create(name=name, is_private=False)
    channel = resp.get("channel")

    slack_client.conversations_setTopic(
        channel=channel["id"],
        topic=f"‚ö† Incident: {title}",
    )

    slack_client.conversations_setPurpose(
        channel=channel["id"],
        purpose=f"Task: {task['url']} | Zoom: {zoom_url}",
    )

    slack_client.conversations_invite(
        channel=channel["id"],
        users=slack_user,
    )

    slack_client.chat_postMessage(
        channel=trigger_channel_id,
        thread_ts=trigger_ts,
        text=f"""‚ö†‚ö†‚ö† Started incident: {title}
Task created: {task["url"]}
Channel created: <#{channel["id"]}>
Zoom: {zoom_url}
""",
    )

    return {
        "title": title,
        "slack_user": slack_user,
        "trigger": {
            "channel_id": trigger_channel_id,
            "ts": trigger_ts,
        },
        "zoom_url": zoom_url,
        "channel": channel,
        "task": task,
    }


def _track(incident: dict):
    s = subscribe("slack", f"data.channel == '{incident['channel']['id']}'")

    while True:
        evt = next_event(s)
        text, user = evt.text.strip(), evt["user"]

        if not text.startswith("!"):
            continue

        parts = text[1:].strip().split(" ", 1)
        cmd = parts[0]
        rest = parts[1] if len(parts) > 1 else ""

        match cmd:
            case "abandon":
                slack_client.chat_postMessage(
                    channel=evt["channel"],
                    ts=evt["ts"],
                    text="abandoned.",
                )
                return
            case "resolve":
                _resolve(incident, user, rest)
                return
            case "note":
                _note(incident, user, rest)

                slack_client.reactions_add(
                    channel=evt["channel"],
                    timestamp=evt["ts"],
                    name="memo",
                )
            case _:
                slack_client.chat_postMessage(
                    channel=evt["channel"],
                    ts=evt["ts"],
                    text="unknown incident command.",
                )


def _resolve(incident: dict, slack_user: str, msg: str):
    text = "üéâ Incident resolved!"

    if msg:
        text += f"\nwith note from <@{slack_user}>: {msg}"

    slack_client.chat_postMessage(
        channel=incident["channel"]["id"],
        text=text,
    )

    slack_client.chat_postMessage(
        channel=incident["trigger"]["channel_id"],
        thread_ts=incident["trigger"]["ts"],
        text=text,
    )

    _note(incident, slack_user, msg)

    slack_client.reactions_add(
        channel=incident["trigger"]["channel_id"],
        timestamp=incident["trigger"]["ts"],
        name="white_check_mark",
    )


def _note(incident: dict, slack_user: str, msg: str):
    resp = slack_client.users_info(user=slack_user)

    height.add_task_message(
        incident["task"]["id"],
        f'{resp["user"]["name"]} via slack: "{msg}"',
    )



================================================
FILE: reliability/incidenter/zoom.py
================================================
"""Create Zoom meetings."""

from autokitteh.zoom import zoom_client


zoom = zoom_client("zoom_conn")


def create_meeting(topic):
    resp = zoom.post(
        "https://api.zoom.us/v2/users/me/meetings",
        json={"topic": topic},
    )
    resp.raise_for_status()
    return resp.json().get("join_url")



================================================
FILE: reliability/missing_jira_events_monitor/README.md
================================================
title: Missing Jira events monitor
description: Send Slack alerts when AutoKitteh doesn't receive certain Jira events in time
integrations: ["jira", "slack"]
categories: ["Reliability"]
tags: ["monitoring", "notifications", "scheduled_tasks", "event_filtering"]



================================================
FILE: reliability/missing_jira_events_monitor/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that sends Slack alerts when AutoKitteh
# doesn't receive certain Jira events in time.

version: v1

project:
  name: missing_jira_events_monitor

  vars:
    # This should be identical to the connection
    # name of the monitored service below!
    - name: CONN_NAME
      value: monitored_service_conn
    # Must be identical/equivalent to the "event_type"
    # and/or "filter" fields of the trigger below!
    - name: EVENT_FILTER
      value:
    - name: EVENT_DESCRIPTION
      value:
    - name: TIMEOUT_HOURS
      value: 24
    - name: PING_HOURS
      value: 1
    - name: SLACK_CHANNEL_NAME_OR_ID
      value: autokitteh-alerts

  connections:
    - name: monitored_service_conn
      integration: jira
    - name: slack_conn
      integration: slack

  triggers:
    - name: monitor_trigger
      connection: monitored_service_conn
      # Set this CEL expression to match the events you want to monitor.
      # Also set the "EVENT_FILTER" project variable above accordingly!
      filter: event_type == "TODO" && data.TODO["TODO"] == "TODO"
      call: program.py:on_monitor_trigger



================================================
FILE: reliability/missing_jira_events_monitor/program.py
================================================
"""Send Slack alerts when AutoKitteh doesn't receive certain Jira events in time.

See the configuration and deployment instructions in the README.md file.
"""

from datetime import datetime, timedelta, UTC
import os

import autokitteh
from autokitteh.slack import slack_client


CONN_NAME = os.getenv("CONN_NAME", "")
EVENT_FILTER = os.getenv("EVENT_FILTER", "")
EVENT_DESCRIPTION = os.getenv("EVENT_DESCRIPTION", "")

TIMEOUT_HOURS = int(os.getenv("TIMEOUT_HOURS", "24"))
PING_HOURS = int(os.getenv("PING_HOURS", "1"))

SLACK_CHANNEL = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")


def on_monitor_trigger(_):
    """Handle an incoming event from a monitored service."""
    start_time = datetime.now(UTC)
    slack = slack_client(CONN_NAME)

    # Wait for the next conformant event from the monitored service.
    sub = autokitteh.subscribe(CONN_NAME, filter=EVENT_FILTER)
    data = autokitteh.next_event(sub, timeout=timedelta(hours=TIMEOUT_HOURS))
    incident_detected = data is None

    # The monitored service hasn't sent us a conformant event for TIMEOUT_HOURS.
    # Send a Slack alert once every PING_HOURS, until the incident is resolved.
    while data is None:
        description = EVENT_DESCRIPTION or f"`{EVENT_FILTER}` in `{CONN_NAME}`"
        msg = f"Events not received since {start_time} (UTC): {description}"
        slack.chat_postMessage(channel=SLACK_CHANNEL, text=msg)

        data = autokitteh.next_event(sub, timeout=timedelta(hours=PING_HOURS))

    # All clear, the monitored service is sending us events still/again.
    # Note that another "on_monitor_trigger" workflow is starting to run now,
    # in a separate AutoKitteh session, waiting for the next event/incident.
    autokitteh.unsubscribe(sub)
    if incident_detected:
        msg = f":relieved: Event received again now: {description}"
        slack.chat_postMessage(channel=SLACK_CHANNEL, text=msg)



================================================
FILE: reliability/session_errors_monitor/README.md
================================================
title: AutoKitteh session errors monitor
description: Send Slack alerts when AutoKitteh sessions end due to errors
integrations: ["slack"]
categories: ["Reliability"]
tags: ["monitoring", "notifications", "scheduled_tasks", "error_handling"]



================================================
FILE: reliability/session_errors_monitor/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of an
# AutoKitteh project that sends Slack alerts when sessions end due to errors.

version: v1

project:
  name: session_errors_monitor

  vars:
    - name: AUTOKITTEH_API_BASE_URL
      value: https://api.autokitteh.cloud
    - name: AUTOKITTEH_UI_BASE_URL
      value: https://app.autokitteh.cloud
    - name: AUTOKITTEH_AUTH_TOKEN
      secret: true
      value:
    - name: SLACK_CHANNEL_NAME_OR_ID
      value: autokitteh-alerts
    - name: TRIGGER_INTERVAL
      value: 1m

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: monitor_schedule
      schedule: "@every 1m"
      call: program.py:on_monitor_schedule



================================================
FILE: reliability/session_errors_monitor/program.py
================================================
"""Send Slack alerts when AutoKitteh sessions end due to errors.

See the configuration and deployment instructions in the README.md file.
"""

from datetime import datetime, timedelta, UTC
import json
import os
from urllib.parse import urljoin

from autokitteh.slack import slack_client
import requests
from requests import exceptions


API_BASE_URL = os.getenv("AUTOKITTEH_API_BASE_URL", "")
UI_BASE_URL = os.getenv("AUTOKITTEH_UI_BASE_URL", "")
JWT = os.getenv("AUTOKITTEH_AUTH_TOKEN", "")
SLACK_CHANNEL = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")

slack = slack_client("slack_conn")


def on_monitor_schedule(_):
    """Triggered at the beginning of every minute, so it covers the previous one."""
    end_time = datetime.now(UTC).replace(second=0, microsecond=0)
    # Remove the unit suffix ("m") and parse as an integer.
    interval = int((os.getenv("TRIGGER_INTERVAL", "1m"))[:-1])
    start_time = end_time - timedelta(minutes=interval)

    count = 0
    for session in reversed(_list_sessions_with_errors()):
        session_updated = datetime.fromisoformat(session["updatedAt"])
        if start_time <= session_updated < end_time:
            count += 1
            _log_error(session)

    print(f"Found {count} sessions with new errors")


def _list_sessions_with_errors():
    url = urljoin(API_BASE_URL, "autokitteh.sessions.v1.SessionsService/List")
    headers = {"Content-Type": "application/json"}
    if JWT:  # Servers in dev mode don't require auth.
        headers["Authorization"] = "Bearer " + JWT

    resp = requests.post(url, headers=headers, json={"stateType": 3}, timeout=10)
    print(f"API call's Round Trip Time: {resp.elapsed}")
    resp.raise_for_status()

    try:
        return resp.json().get("sessions", [])
    except exceptions.JSONDecodeError:
        print(f"Response headers: {resp.headers}")
        print(f"Response text: {resp.text}")
        raise


def _log_error(session):
    data = json.dumps(session, indent=4)
    print(data)

    pid, did = session["projectId"], session["deploymentId"]
    path = f"/projects/{pid}/deployments/{did}/sessions/{session['sessionId']}"
    msg = f"Error in AutoKitteh session: {urljoin(UI_BASE_URL, path)}\n```{data}```"
    slack.chat_postMessage(channel=SLACK_CHANNEL, text=msg)



================================================
FILE: room_reservation/README.md
================================================
title: Ad-hoc room reservation via Slack
description: Ad-hoc room reservation via Slack slash commands
integrations: ["slack", "googlecalendar"]
categories: ["Productivity"]
tags: ["user_interactions", "webhook_handling", "data_processing", "error_handling"]



================================================
FILE: room_reservation/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that manages via Slack ad-hoc room
# reservations in Google Calendar.

version: v1

project:
  name: room_reservation

  vars:
    - name: GOOGLE_SHEET_ID
      value:

  connections:
    - name: calendar_conn
      integration: googlecalendar
    - name: sheets_conn
      integration: googlesheets
    - name: slack_conn
      integration: slack

  triggers:
    - name: slack_slash_command_available_rooms
      connection: slack_conn
      event_type: slash_command
      filter: data.text == "availablerooms"
      call: available_rooms.py:on_slack_slash_command
    - name: slack_slash_command_room_status
      connection: slack_conn
      event_type: slash_command
      filter: data.text.startsWith("roomstatus ")
      call: room_status.py:on_slack_slash_command
    - name: slack_slash_command_reserve_room
      connection: slack_conn
      event_type: slash_command
      filter: data.text.startsWith("reserveroom ")
      call: reserve_room.py:on_slack_slash_command



================================================
FILE: room_reservation/available_rooms.py
================================================
"""List all the available rooms for the next half hour."""

from datetime import datetime, timedelta, UTC

from autokitteh.google import google_calendar_client
from autokitteh.slack import slack_client
from googleapiclient.errors import HttpError

import util


def on_slack_slash_command(event):
    """Entry point for the "/<app-name> availablerooms" Slack slash command."""
    slack = slack_client("slack_conn")
    channel_id = event.data.user_id  # event.data.channel_id

    now = datetime.now(UTC)
    in_30_minutes = now + timedelta(minutes=30)
    gcal = google_calendar_client("calendar_conn").events()

    # Iterate over the list of rooms, notify the user about
    # each room which is available in the next half hour.
    available = False
    for room in sorted(util.get_room_list()):
        print(f"Checking upcoming events in: {room}")
        try:
            events = gcal.list(
                calendarId=room,
                timeMin=now.isoformat(),
                timeMax=in_30_minutes.isoformat(),
                singleEvents=True,
                orderBy="startTime",
            ).execute()

            events = events.get("items", [])
            # Ignore non-blocking events where the room is marked as "free".
            events = [e for e in events if e.get("transparency", "") != "transparent"]

            if not events:
                msg = f"The room `{room}` is available for the next half hour"
                slack.chat_postMessage(channel=channel_id, text=msg)
                available = True

        except HttpError as e:
            err = f"Error for the room `{room}`: '{e.reason}'"
            slack.chat_postMessage(channel=channel_id, text=err)
            print(f"Error when listing events for room `{room}`: {e}")

    if not available:
        msg = "No available rooms found for the next half hour"
        slack.chat_postMessage(channel=channel_id, text=msg)



================================================
FILE: room_reservation/reserve_room.py
================================================
"""Reserve a specific room for the next half hour."""

from datetime import datetime, timedelta, UTC

import autokitteh
from autokitteh.google import google_calendar_client
from autokitteh.slack import slack_client
from googleapiclient.errors import HttpError

import util


def on_slack_slash_command(event):
    """Entry point for the "reserveroom <room> <title>" Slack slash command."""
    data = event.data

    slack = slack_client("slack_conn")
    channel_id = data.user_id  # DM the user who sent the command.

    cmd_text = data.text.split(maxsplit=2)

    if len(cmd_text) < 3:
        err = f"Error: use this format: `{data.command} reserveroom <room> <title>`"
        slack.chat_postMessage(channel=channel_id, text=err)
        return
    _, room, title = cmd_text

    room = util.get_email_from_slack_command(room)

    if room not in util.get_room_list():
        err = f"Error: `{room}` not found in the list of rooms"
        slack.chat_postMessage(channel=channel_id, text=err)
        return

    user = slack.users_profile_get(user=data.user_id).get("profile", {})

    now = datetime.now(UTC)
    in_5_minutes = now + timedelta(minutes=5)
    in_30_minutes = now + timedelta(minutes=30)

    event = {
        "summary": title,
        "description": f"Reserved via Slack by {user['real_name']}",
        "start": {"dateTime": in_5_minutes.isoformat()},
        "end": {"dateTime": in_30_minutes.isoformat()},
        "reminders": {"useDefault": False},
        "attendees": [
            {"email": user["email"]},
        ],
    }

    result = _create_calendar_event(room, event)
    slack.chat_postMessage(channel=channel_id, text=result)


# It's better to mark this as a single activity, to minimize the creation of
# multiple overly-granular activities during this Google Calendar API call.
@autokitteh.activity
def _create_calendar_event(room, event):
    try:
        gcal = google_calendar_client("calendar_conn").events()
        gcal.insert(calendarId=room, body=event).execute()
        return f"Scheduled a meeting now in the room `{room}`"
    except HttpError as e:
        return f"Error: failed to schedule a meeting ('{e.reason}')"



================================================
FILE: room_reservation/room_status.py
================================================
"""Check the status of a specific room for the next hour."""

from datetime import datetime, timedelta, UTC

import autokitteh
from autokitteh.google import google_calendar_client
from autokitteh.slack import slack_client
from googleapiclient.errors import HttpError

import util


def on_slack_slash_command(event):
    """Entry point for the "/<app-name> roomstatus <room>" Slack slash command."""
    slack = slack_client("slack_conn")
    channel_id = event.data.user_id  # event.data.channel_id

    # Extract the email address from the Slack command text, which is formatted like:
    # "<@USER_ID> <mailto:test@example.com|test@example.com>".
    room = util.get_email_from_slack_command(event.data.text)

    if room not in util.get_room_list():
        err = f"Error: `{room}` not found in the list of rooms"
        slack.chat_postMessage(channel=channel_id, text=err)

    gcal = google_calendar_client("calendar_conn").events()
    now = datetime.now(UTC)
    in_1_hour = now + timedelta(hours=1)

    msg = f"Events in the room `{room}`:"
    try:
        events = gcal.list(
            calendarId=room,
            timeMin=now.isoformat(),
            timeMax=in_1_hour.isoformat(),
            singleEvents=True,
            orderBy="startTime",
        ).execute()

        events = events.get("items", [])
        # Ignore non-blocking events where the room is marked as "free".
        events = [e for e in events if e.get("transparency", "") != "transparent"]

        if not events:
            msg += " none found for the next half hour"

        for event in events:
            event = autokitteh.AttrDict(event)
            start = event.start.get("dateTime") or event.start.get("date")
            msg += f"\n{start} - {event.summary}"

    except HttpError as e:
        msg += f" error '{e.reason}'"
        print(f"Error when listing events for room `{room}`: {e}")

    slack.chat_postMessage(channel=channel_id, text=msg)



================================================
FILE: room_reservation/util.py
================================================
"""Utility functions for the room reservation app."""

import os

from autokitteh.google import google_sheets_client


def get_room_list():
    sheet = google_sheets_client("sheets_conn").spreadsheets().values()
    rows = sheet.get(spreadsheetId=os.getenv("GOOGLE_SHEET_ID"), range="A:A").execute()
    return [cell[0] for cell in rows.get("values", []) if cell]


def get_email_from_slack_command(text):
    """Extract the email address from the Slack command text, which is formatted like:

    "<@USER_ID> <mailto:test@example.com|test@example.com>".
    """
    return text.split("|")[-1].strip(">")



================================================
FILE: samples/anthropic/README.md
================================================
title: Anthropic Claude sample
description: Sample using Anthropic Claude API
integrations: ["anthropic"]
categories: ["AI", "Samples"]



================================================
FILE: samples/anthropic/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with
# Anthropic Claude.

version: v2

project:
  name: anthropic_sample

  connections:
    - name: anthropic_conn
      integration: anthropic

  triggers:
    - name: on_http_post_with_prompt
      type: webhook
      event_type: post
      call: program.py:on_http_post_with_prompt
      is_sync: true

    - name: on_http_get_demo
      type: webhook
      event_type: get
      call: program.py:on_http_get_demo



================================================
FILE: samples/anthropic/program.py
================================================
"""This program demonstrates AutoKitteh's Anthropic Claude integration.

The program implements two entry-point functions:
- one that requires a custom prompt in the HTTP request body
- one that uses a default prompt for quick demos

Both functions are configured in the "autokitteh.yaml" manifest file.
They send requests to the Claude API and print the responses
in the AutoKitteh session log, along with Claude's usage statistics.

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

from autokitteh import http_outcome
from autokitteh.anthropic import anthropic_client


MODEL = "claude-3-5-haiku-20241022"

claude = anthropic_client("anthropic_conn")


def on_http_post_with_prompt(event):
    """Entry-point function for handling HTTP POST requests with a custom prompt.

    This function requires a text prompt in the request body.

    Example usage:
    - URL: "http://localhost:9980/webhooks/<webhook_slug>"
    - Curl command:
      curl -X POST "<URL>" -H "Content-Type: text/plain" -d "Why do cats purr?"

    Args:
        event: The HTTP event containing request data.
    """
    body = event.data.body.bytes.decode("utf-8")

    # Send the user's prompt to Claude with system instructions.
    message = claude.messages.create(
        model=MODEL,
        max_tokens=1024,
        system=(
            "You are a helpful coding assistant who explains complex "
            "programming concepts clearly and concisely."
        ),
        messages=[
            {
                "role": "user",
                "content": body,
            }
        ],
    )

    # Print Claude's response in the AutoKitteh session's log.
    print(f"User prompt: {body}")
    print(f"\nClaude's response: {message.content[0].text}")
    print(f"\nUsage statistics: {message.usage}")

    http_outcome(status_code=200, body=message.content[0].text)


def on_http_get_demo(event):
    """Entry-point function for HTTP GET requests with a default prompt.

    This function doesn't require any input and demonstrates Claude
    with a preset prompt.

    Example usage:
    - URL: "http://localhost:9980/webhooks/<webhook_slug>"
    - Curl command:
      curl -X GET "<URL>"

    Args:
        event: The HTTP event containing request data.
    """
    # Simple interaction with Claude using a default prompt.
    message = claude.messages.create(
        model=MODEL,
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": "Give me 3 interesting facts about cats.",
            }
        ],
    )

    # Print Claude's response in the AutoKitteh session's log.
    print(f"Claude's response: {message.content[0].text}")
    print(f"\nUsage statistics: {message.usage}")
    print(f"Model: {message.model}")



================================================
FILE: samples/asana/README.md
================================================
title: Asana sample
description: Simple usage of the Asana API
integrations: ["asana"]
categories: ["Samples"]



================================================
FILE: samples/asana/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Asana.

version: v1

project:
  name: asana_sample

  vars:
    - name: WORKSPACE_GID
      value:

  connections:
    - name: asana_conn
      integration: asana

  triggers:
    - name: create_task_webhook
      type: webhook
      event_type: get
      call: program.py:create_task
    - name: update_task_webhook
      type: webhook
      event_type: post
      call: program.py:update_task



================================================
FILE: samples/asana/program.py
================================================
"""Demonstrates AutoKitteh‚Äôs Asana integration for managing tasks via the Asana API."""

import os

import asana
from autokitteh.asana import asana_client


api_client = asana_client("asana_conn")
client = asana.TasksApi(api_client)

WORKSPACE_GID = os.getenv("WORKSPACE_GID", "")


def create_task(event):
    task_name = event.data.url.query.get("name") or "autokitteh task"
    body = {
        "data": {
            "workspace": WORKSPACE_GID,
            "name": task_name,
            "assignee": "me",
        }
    }

    task = client.create_task(body, {})
    print(f"Task '{task['name']}' has been successfully created!")


def update_task(event):
    """Updates an Asana task's name and due date."""
    form = event.data.body.form
    task_gid = form.get("task_gid")
    new_due_date = form.get("new_due_date", "2025-01-20")
    new_name_suffix = form.get("name_suffix", " - Updated by AutoKitteh")

    task = client.get_task(task_gid, {"opt_fields": "name,assignee,due_on,tags"})
    print(f"Current Task: {task}")

    body = {
        "data": {
            "name": task["name"] + new_name_suffix,
            "due_on": new_due_date,
        }
    }

    updated_task = client.update_task(body, task_gid, {})

    print(f"Task '{updated_task['name']}' has been successfully updated!")



================================================
FILE: samples/atlassian/README.md
================================================



================================================
FILE: samples/atlassian/jira/README.md
================================================
title: Jira sample
description: Samples using Jira APIs
integrations: ["jira"]
categories: ["Samples"]



================================================
FILE: samples/atlassian/jira/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Atlassian Jira (https://www.atlassian.com/software/jira).

version: v1

project:
  name: jira_sample

  connections:
    - name: jira_conn
      integration: jira

  triggers:
    - name: jira_comment_created
      connection: jira_conn
      event_type: comment_created
      call: program.py:on_jira_comment_created
    - name: jira_issue_created
      connection: jira_conn
      event_type: issue_created
      call: program.py:on_jira_issue_created



================================================
FILE: samples/atlassian/jira/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Atlassian Jira integration.

Atlassian Jira API documentation:
- https://docs.autokitteh.com/integrations/atlassian/jira/python
- https://docs.autokitteh.com/integrations/atlassian/jira/events
"""

from autokitteh.atlassian import jira_client


def on_jira_issue_created(event):
    issue_key = event.data.issue.key
    user_name = event.data.user.displayName

    jira = jira_client("jira_conn")
    jira.issue_add_comment(issue_key, "This issue was created by " + user_name)


def on_jira_comment_created(event):
    issue_key = event.data.issue.key
    comment = event.data.comment

    jira = jira_client("jira_conn")
    suffix = "\n\nThis comment was added by " + comment.author.displayName
    jira.issue_edit_comment(issue_key, comment.id, comment.body + suffix)



================================================
FILE: samples/auth0/README.md
================================================
title: Auth0 sample
description: Simple usage of the Auth0 API
integrations: ["auth0"]
categories: ["Samples"]



================================================
FILE: samples/auth0/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Auth0.

version: v1

project:
  name: auth0_sample

  vars:
    - name: ROLE_ID
      value:
    - name: TIME_INTERVAL
      value: 7d

  connections:
    - name: auth_conn
      integration: auth0

  triggers:
    - name: weekly
      schedule: 0 0 * * 1
      call: program.py:weekly_user_growth
    - name: assign_role_webhook
      type: webhook
      event_type: post
      call: program.py:assign_role



================================================
FILE: samples/auth0/program.py
================================================
"""Demonstrates AutoKitteh‚Äôs Auth0 integration for managing tasks via the Auth0 API."""

from datetime import datetime, timedelta, UTC
import os

from autokitteh.auth0 import auth0_client


ROLE_ID = os.getenv("ROLE_ID", "")

auth0 = auth0_client("auth_conn")


def assign_role(event):
    """Entry-point function for a webhook-based workflow assigning a role to a user."""
    user = event.data.body.form.get("user_id", "")
    auth0.roles.add_users(ROLE_ID, [user])
    print(f"Assigned role {ROLE_ID!r} to user {user!r}")


def weekly_user_growth(_):
    """Fetch and display the number of users created in the past week."""
    # Remove the unit suffix ("d") and parse as an integer.
    interval_days = int((os.getenv("TIME_INTERVAL", "7d"))[:-1])
    end_time = datetime.now(UTC).replace(second=0, microsecond=0)
    start_time = end_time - timedelta(minutes=interval_days)

    start_time_iso = start_time.isoformat()
    end_time_iso = end_time.isoformat()

    query = f"created_at:[{start_time_iso} TO {end_time_iso}]"

    response = auth0.users.list(q=query, search_engine="v3")
    new_users = response.get("users", [])

    print(f"New users in the past week: {len(new_users)}")
    for user in new_users:
        print(f"- {user['email']} (created at: {user['created_at']})")



================================================
FILE: samples/discord/README.md
================================================



================================================
FILE: samples/discord/discord_client/README.md
================================================



================================================
FILE: samples/discord/discord_client/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Discord (https://discord.com/).

version: v1

project:
  name: discord_client_sample

  vars:
    - name: CHANNEL_ID
      value:

  connections:
    - name: discord_conn
      integration: discord
  triggers:
    - name: start_event_loop
      type: webhook
      event_type: get
      call: program.py:start_event_loop



================================================
FILE: samples/discord/discord_client/program.py
================================================
"""Discprd bot that performs basic operations."""

import os

import autokitteh
import autokitteh.discord as ak_discord
import discord


intents = discord.Intents.default()
intents.message_content = True

client = ak_discord.discord_client("discord_conn", intents)


@autokitteh.activity
def start_event_loop(event):
    """Starts the bot and connects it to the Discord gateway."""
    client.run(ak_discord.bot_token("discord_conn"))


@client.event
async def on_ready():
    """Asynchronous function triggered when the bot successfully connects to Discord."""
    print(f"We have logged in as {client.user}")
    channel_id = int(os.getenv("CHANNEL_ID"))
    channel = client.get_channel(channel_id)

    if channel is None:
        print(f"Channel with ID {channel_id} not found")
        print("Available channels:")
        for guild in client.guilds:
            for channel in guild.channels:
                print(f"{channel.name} (ID: {channel.id})")
        return

    try:
        await channel.send("Meow!")
    except discord.Forbidden:
        print("The bot does not have permission to send messages in this channel.")
    except discord.HTTPException as e:
        print(f"Failed to send message: {e}")
    finally:
        # Closing the client to prevent duplicate messages
        # or unexpected behavior in future workflows.
        await client.close()



================================================
FILE: samples/discord/events/README.md
================================================



================================================
FILE: samples/discord/events/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Discord (https://discord.com/).

version: v1

project:
  name: discord_events_sample

  connections:
    - name: discord_conn
      integration: discord

  triggers:
    - name: discord_message_create
      connection: discord_conn
      event_type: message_create
      call: program.py:on_discord_message_create
    - name: discord_message_update
      connection: discord_conn
      event_type: message_update
      call: program.py:on_discord_message_update
    - name: discord_message_delete
      connection: discord_conn
      event_type: message_delete
      call: program.py:on_discord_message_delete



================================================
FILE: samples/discord/events/program.py
================================================
"""Handle message-related events in Discord.

Also log the corresponding information using the `autokitteh.discord` client.
"""


def on_discord_message_create(event):
    print(f"User {event.data['author']['username']} sent: {event.data['content']}")


def on_discord_message_update(event):
    print(f"Message updated to: {event.data['content']}")


def on_discord_message_delete(event):
    print(f"Message with ID {event.data['id']} was deleted")



================================================
FILE: samples/github/README.md
================================================



================================================
FILE: samples/google/README.md
================================================



================================================
FILE: samples/google/calendar/README.md
================================================
title: Google Calendar sample
description: Samples using Google Calendar APIs
integrations: ["googlecalendar"]
categories: ["Samples"]



================================================
FILE: samples/google/calendar/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Google Calendar (https://workspace.google.com/products/calendar/).

version: v1

project:
  name: google_calendar_sample

  connections:
    - name: calendar_conn
      integration: googlecalendar

  triggers:
    - name: list_events
      type: webhook
      event_type: get
      call: program.py:list_events
    - name: google_calendar_event_created
      connection: calendar_conn
      event_type: event_created
      call: program.py:on_calendar_event_created
    - name: google_calendar_event_updated
      connection: calendar_conn
      event_type: event_updated
      call: program.py:on_calendar_event_updated
    - name: google_calendar_event_deleted
      connection: calendar_conn
      event_type: event_deleted
      call: program.py:on_calendar_event_deleted



================================================
FILE: samples/google/calendar/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Google Calendar integration.

API documentation:
- https://docs.autokitteh.com/integrations/google/calendar/python
- https://docs.autokitteh.com/integrations/google/calendar/events
"""

from datetime import datetime, UTC

from autokitteh.google import google_calendar_client
from googleapiclient.errors import HttpError


def list_events(event):
    """Get the next 10 events from the primary calendar.

    This is the same as Google's quickstart code sample, but simpler:
    https://github.com/googleworkspace/python-samples/tree/main/calendar
    """
    gcal = google_calendar_client("calendar_conn").events()
    print("Getting the next 10 events")

    try:
        result = gcal.list(
            calendarId="primary",
            timeMin=datetime.now(UTC).isoformat(),
            maxResults=10,
            singleEvents=True,
            orderBy="startTime",
        ).execute()
    except HttpError as e:
        print(f"An error occurred: {e.reason}")
        return

    events = result.get("items")
    if not events:
        print("No upcoming events found")
        return

    for e in events:
        start = e["start"].get("dateTime") or e["start"].get("date")
        start = datetime.fromisoformat(start)
        print(f"{start} - {e['summary']}")


def on_calendar_event_created(event):
    print("Event created:", event.data)


def on_calendar_event_updated(event):
    print("Event updated:", event.data)


def on_calendar_event_deleted(event):
    print("Event deleted:", event.data)



================================================
FILE: samples/google/drive/README.md
================================================
title: Google Drive sample
description: Samples using Google Drive APIs
integrations: ["googledrive"]
categories: ["Samples"]



================================================
FILE: samples/google/drive/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Google Drive (https://workspace.google.com/products/drive/).

version: v1

project:
  name: google_drive_sample

  connections:
    - name: google_drive_conn
      integration: googledrive

  vars:
    - name: USER_EMAIL
      value:

  triggers:
    - name: create_new_document
      type: webhook
      call: program.py:create_new_document
    - name: on_file_change
      connection: google_drive_conn
      event_type: file_change
      call: program.py:on_file_change
    - name: on_file_remove
      connection: google_drive_conn
      event_type: file_remove
      call: program.py:on_file_remove



================================================
FILE: samples/google/drive/program.py
================================================
"""Autokitteh's Google Drive integration to monitor changes to files."""

import os

from autokitteh.google import google_drive_client


USER_EMAIL = os.getenv("USER_EMAIL", "")


def on_file_change(event):
    print(f"File with ID {event.data.file_id} has changed!")


def on_file_remove(event):
    print(f"File with ID {event.data.file_id} has been removed!")


def create_new_document(_):
    """Creates a new Google Document and optionally shares it with a specified user.

    If the Google Drive permission scope is limited to https://www.googleapis.com/auth/drive.file,
    the app must create a new file to enable change monitoring. Note that creating a
    file is not the only way to grant permissions; there are other options detailed
    here: https://developers.google.com/drive/api/guides/manage-sharing. For example,
    when using a service account, you can share a specific file with the service
    account's email address.
    """
    client = google_drive_client("google_drive_conn")

    file_metadata = {
        "name": "New Document",
        "mimeType": "application/vnd.google-apps.document",
    }

    file = client.files().create(body=file_metadata).execute()

    # When using a service account, granting access to a specific user
    # can simplify file interactions. This step is optional.
    if USER_EMAIL:
        client.permissions().create(
            fileId=file.get("id"),
            body={"type": "user", "role": "writer", "emailAddress": USER_EMAIL},
        ).execute()

    print(f"Created file with ID: {file.get('id')}")



================================================
FILE: samples/google/forms/README.md
================================================
title: Google Forms sample
description: Samples using Google Forms APIs
integrations: ["googleforms"]
categories: ["Samples"]



================================================
FILE: samples/google/forms/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Google Forms (https://www.google.com/forms/about/).

version: v1

project:
  name: google_forms_sample
  connections:
    - name: forms_conn
      integration: googleforms

  triggers:
    - name: add_question
      type: webhook
      event_type: get
      call: program.py:add_question
    - name: google_forms_schema_change
      connection: forms_conn
      event_type: schema
      call: program.py:on_form_change
    - name: google_forms_response
      connection: forms_conn
      event_type: responses
      call: program.py:on_form_response



================================================
FILE: samples/google/forms/new_question.json
================================================
{
    "requests": [
        {
            "createItem": {
                "item": {
                    "title": "In what year did the United States land a mission on the moon?",
                    "questionItem": {
                        "question": {
                            "required": true,
                            "choiceQuestion": {
                                "type": "RADIO",
                                "options": [
                                    {"value": "1965"},
                                    {"value": "1967"},
                                    {"value": "1969"},
                                    {"value": "1971"}
                                ],
                                "shuffle": true
                            }
                        }
                    }
                },
                "location": {"index": 0}
            }
        }
    ]
}



================================================
FILE: samples/google/forms/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Google Forms integration.

API documentation:
- https://docs.autokitteh.com/integrations/google/forms/python
- https://docs.autokitteh.com/integrations/google/forms/events
"""

import json
import os
from pathlib import Path

from autokitteh.google import google_forms_client


def add_question(event):
    """Add a new question to the form that our connection watches.

    This is the same as Google's quickstart code sample, but simpler:
    https://github.com/googleworkspace/python-samples/tree/main/forms
    """
    # Get the form that our connection watches.
    forms = google_forms_client("forms_conn").forms()
    form_id = os.environ.get("forms_conn__FormID")
    form = forms.get(formId=form_id).execute()
    new_index = len(form["items"])

    # Add a new question to the form.
    body = Path("new_question.json").read_text().replace("0", str(new_index))
    result = forms.batchUpdate(formId=form_id, body=json.loads(body)).execute()
    print(result)


def on_form_change(event):
    title = event.data.form.info.title
    form_id = event.data.form_id
    revision = event.data.form.revision_id
    items = len(event.data.form.get("items", []))
    print(f"Form change: {title} ({form_id}), revision {revision}, {items} items")


def on_form_response(event):
    print("New form response submitted:", event.data)



================================================
FILE: samples/google/gemini/README.md
================================================
title: Gemini sample
description: Simple usage of the Gemini API
integrations: ["googlegemini"]
categories: ["AI", "Samples"]



================================================
FILE: samples/google/gemini/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Gemini.

version: v1

project:
  name: gemini_sample

  connections:
    - name: gemini_conn
      integration: googlegemini

  triggers:
    - name: trivial_interaction
      type: webhook
      event_type: get
      call: program.py:trivial_interaction
    - name: interactive_chat
      type: webhook
      event_type: get
      call: program.py:interactive_chat



================================================
FILE: samples/google/gemini/program.py
================================================
"""Demonstration of AutoKitteh's Gemini integration.

Two entry-point functions are implemented that send requests to the
Gemini API and print the responses in the AutoKitteh session log.
"""

from autokitteh.google import gemini_client


MODEL = "gemini-2.5-flash-lite"

gemini = gemini_client("gemini_conn", model_name=MODEL)


def trivial_interaction(_):
    prompt = "say meow in different languages"
    response = gemini.generate_content(prompt)
    print(response.text)


def interactive_chat(_):
    chat = gemini.start_chat(
        history=[
            {"role": "user", "parts": "Hello"},
            {
                "role": "model",
                "parts": "Great to meet you. What would you like to know?",
            },
        ]
    )
    response = chat.send_message("I have 2 cats in my house.")
    print(response.text)
    response = chat.send_message("How many paws are in my house?")
    print(response.text)



================================================
FILE: samples/google/gmail/README.md
================================================
title: Gmail sample
description: Samples using Gmail APIs
integrations: ["gmail"]
categories: ["Samples"]
tags: ["webhook_handling", "store", "state_management", "data_processing", "essential"]



================================================
FILE: samples/google/gmail/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Gmail (https://www.google.com/gmail/about/).

version: v1

project:
  name: gmail_sample

  connections:
    - name: gmail_conn
      integration: gmail

  triggers:
    - name: on_http_get
      type: webhook
      event_type: get
      call: program.py:on_http_get
    - name: gmail_mailbox_change
      connection: gmail_conn
      event_type: mailbox_change
      call: program.py:on_gmail_mailbox_change



================================================
FILE: samples/google/gmail/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Gmail integration.

API documentation:
- https://docs.autokitteh.com/integrations/google/gmail/python
- https://docs.autokitteh.com/integrations/google/gmail/events
"""

import base64
import json

import autokitteh
from autokitteh.google import gmail_client
from googleapiclient.errors import HttpError


gmail = gmail_client("gmail_conn").users()


def on_http_get(event):
    """Handle Gmail interaction via HTTP trigger using query params.

    Example URL: "http://localhost:9980/webhooks/<webhook_slug>?cmd=list_drafts"

    Commands:
    - cmd=get_profile
    - cmd=list_drafts&query=optional_query
    - cmd=get_draft&draft_id=<draft_ID>
    - cmd=list_messages&query=optional_query
    - cmd=get_message&message_id=<message_ID>
    - cmd=send_message&text=<message_text>

    Args:
        event: HTTP request event data (contains query parameters).
    """
    params = event.data.url.query
    cmd = params.get("cmd")

    match cmd:
        case "get_profile":
            _get_profile()
        case "list_drafts":
            _drafts_list(params.get("query", ""))
        case "get_draft":
            _drafts_get(params.get("draft_id"))
        case "list_messages":
            _messages_list(params.get("query", ""))
        case "get_message":
            _messages_get(params.get("message_id"))
        case "send_message":
            _messages_send(params.get("text"))
        case _:
            return "Unknown command"


def _get_profile():
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.html#getProfile"""
    resp = gmail.getProfile(userId="me").execute()
    print(resp["emailAddress"])
    print("Total no. of messages:", resp["messagesTotal"])
    print("Total no. of threads:", resp["threadsTotal"])
    print("Current History record ID:", resp["historyId"])


def _drafts_get(id):
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.drafts.html#get

    Args:
        id: Required ID of the draft to retrieve.
    """
    try:
        resp = gmail.drafts().get(userId="me", id=id).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print(f"```\n{json.dumps(resp, indent=4)}\n```")


def _drafts_list(query):
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.drafts.html#list

    Args:
        query: Optional query, e.g. "is:unread".
    """
    try:
        resp = gmail.drafts().list(userId="me", q=query, maxResults=10).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print(f"Result size estimate: `{resp['resultSizeEstimate']}`")

    for i, d in enumerate(resp.get("drafts", []), start=1):
        print(f"{i}\n```\n{json.dumps(d, indent=4)}\n```")

    next_page_token = resp.get("nextPageToken")
    if next_page_token:
        print(f"Next page token: `{next_page_token}`")


def _messages_get(id):
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.messages.html#get

    Args:
        id: Required ID of the message to retrieve.
    """
    try:
        resp = gmail.messages().get(userId="me", id=id).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print(f"```\n{json.dumps(resp, indent=4)}\n```")


def _messages_list(query):
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.messages.html#list

    See also:
    https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.messages.html#list_next

    Args:
        query: Optional query, e.g. "is:unread".
    """
    try:
        resp = gmail.messages().list(userId="me", q=query, maxResults=10).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print(f"Result size estimate: `{resp['resultSizeEstimate']}`")

    for i, m in enumerate(resp.get("messages", []), start=1):
        print(f"{i}\n```\n{json.dumps(m, indent=4)}\n```")

    next_page_token = resp.get("nextPageToken")
    if next_page_token:
        print(f"Next page token: `{next_page_token}`")


def _messages_send(text):
    """https://developers.google.com/resources/api-libraries/documentation/gmail/v1/python/latest/gmail_v1.users.messages.html#send

    See also: https://developers.google.com/gmail/api/guides/sending

    This is the same as Google's send-message snippet, but simpler:
    https://github.com/googleworkspace/python-samples/blob/main/gmail/snippet/send%20mail/send_message.py

    Args:
        text: Short message to send to yourself.
    """
    profile = gmail.getProfile(userId="me").execute()

    # Raw text compliant with https://datatracker.ietf.org/doc/html/rfc5322.
    msg = f"""From: {profile["emailAddress"]}
    To: {profile["emailAddress"]}
    Subject: Test from AutoKitteh

    {text}"""

    msg = msg.replace("\n", "\r\n").replace("    ", "")
    msg = base64.urlsafe_b64encode(msg.encode()).decode()
    try:
        gmail.messages().send(userId="me", body={"raw": msg}).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print("Message sent successfully!")


def on_gmail_mailbox_change(event):
    """Gmail Mailbox Change Event Handler.

    This function acts as a custom event handler for Gmail mailbox changes
    (triggered via Pub/Sub webhook events). Due to limitations
    in Gmail's native history ID event handling, this
    function detects and handles incoming emails events.
    """
    try:
        history_id = event.data.get("history_id")
        if not history_id:
            return

        current_history_id = int(history_id)
        last_processed_id = int(
            autokitteh.get_value("last_processed_id") or (current_history_id - 100)
        )

        history = (
            gmail.history()
            .list(userId="me", startHistoryId=str(last_processed_id))
            .execute()
        )

        if "history" in history:
            for history_record in history["history"]:
                record_id = int(history_record["id"])

                # Skip already processed records.
                if record_id <= last_processed_id:
                    continue

                if "messagesAdded" in history_record:
                    for message_entry in history_record["messagesAdded"]:
                        message_id = message_entry["message"]["id"]
                        message = (
                            gmail.messages()
                            .get(
                                userId="me",
                                id=message_id,
                                format="metadata",
                                metadataHeaders=["From", "To", "Subject"],
                            )
                            .execute()
                        )

                        # Only process INBOX messages (incoming).
                        labels = message.get("labelIds", [])
                        if "INBOX" in labels and "SENT" not in labels:
                            on_new_message(message)

        # Only update if we processed something new.
        if current_history_id > last_processed_id:
            autokitteh.set_value("last_processed_id", str(current_history_id))

    except HttpError as e:
        print(f"Error: {e.reason}")


def on_new_message(message):
    headers = {
        h["name"]: h["value"] for h in message.get("payload", {}).get("headers", [])
    }
    print("New Mail Received:")
    print(f"From: {headers.get('From')}")
    print(f"To: {headers.get('To')}")
    print(f"Subject: {headers.get('Subject')}")



================================================
FILE: samples/google/sheets/README.md
================================================
title: Google Sheets sample
description: Samples using Google Sheets APIs
integrations: ["googlesheets"]
categories: ["Samples"]



================================================
FILE: samples/google/sheets/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Google Sheets (https://workspace.google.com/products/sheets/).

version: v1

project:
  name: google_sheets_sample

  connections:
    - name: sheets_conn
      integration: googlesheets

  triggers:
    - name: http_get
      type: webhook
      event_type: get
      call: program.py:on_http_get



================================================
FILE: samples/google/sheets/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Google Sheets integration.

API documentation:
https://docs.autokitteh.com/integrations/google/sheets/python
"""

import autokitteh
from autokitteh.google import google_sheets_client


sheet = google_sheets_client("sheets_conn").spreadsheets().values()


def on_http_get(event):
    """Entry point for the workflow.

    This function expects the URL parameter 'id' to be a valid Google Sheets ID
    (see https://developers.google.com/sheets/api/guides/concepts).

    Example URL: "http://localhost:9980/webhooks/<webhook-slug>?id=<Google-Sheets-ID>"

    Args:
        event: HTTP event data, including URL query parameters.
    """
    sheet_id = event.data.url.query.get("id")
    if not sheet_id:
        print("Error: Missing required 'id' URL parameter for Google Sheets.")
        return

    _write_values(sheet_id)
    _read_values(sheet_id)
    _read_formula(sheet_id)


@autokitteh.activity
def _write_values(id):
    """Write multiple cell values, with different data types."""
    resp = sheet.update(
        spreadsheetId=id,
        # Explanation of the A1 notation for cell ranges:
        # https://developers.google.com/sheets/api/guides/concepts#expandable-1
        range="Sheet1!A1:B7",
        # Value input options:
        # https://developers.google.com/sheets/api/reference/rest/v4/ValueInputOption
        valueInputOption="USER_ENTERED",
        body={
            "values": [
                ["String", "Hello, world!"],
                ["Number", -123.45],
                ["Also number", "-123.45"],
                ["Percent", "10.12%"],
                ["Boolean", True],
                ["Date", "2022-12-31"],
                ["Formula", "=B2*B3"],
            ]
        },
    ).execute()

    print(f"Updated range: {resp['updatedRange']!r}")
    print(f"Rows: {resp['updatedRows']}")
    print(f"Columns: {resp['updatedColumns']}")
    print(f"Cells: {resp['updatedCells']}")


@autokitteh.activity
def _read_values(id):
    """Read multiple cell values from a Google Sheet, and send them to Slack.

    Value render options:
    https://developers.google.com/sheets/api/reference/rest/v4/ValueRenderOption
    """
    # Default value render option: "FORMATTED_VALUE".
    resp = sheet.get(spreadsheetId=id, range="A1:B6").execute()
    col_a, formatted_col_b = list(zip(*resp.get("values", []), strict=True))

    ufv = "UNFORMATTED_VALUE"
    resp = sheet.get(spreadsheetId=id, range="A1:B6", valueRenderOption=ufv).execute()
    unformatted_col_b = [v for _, v in resp.get("values", [])]

    for i, row in enumerate(
        zip(col_a, formatted_col_b, unformatted_col_b, strict=True)
    ):
        data_type, formatted, unformatted = row
        text = f"Row {i + 1}: {data_type} = formatted "
        text += f"`{formatted!r}`, unformatted `{unformatted!r}`"
        print(text)


@autokitteh.activity
def _read_formula(id):
    """Read a single cell value with a formula, and its evaluated result.

    Value render options:
    https://developers.google.com/sheets/api/reference/rest/v4/ValueRenderOption
    """
    f = "FORMULA"
    resp = sheet.get(spreadsheetId=id, range="B7", valueRenderOption=f).execute()
    value = resp.get("values", [["Not found"]])[0][0]
    print(f"Formula: `{value!r}`")

    # Default value render option: "FORMATTED_VALUE".
    resp = sheet.get(spreadsheetId=id, range="B7").execute()
    value = resp.get("values", [["Not found"]])[0][0]
    print(f"Formula: `{value!r}`")

    ufv = "UNFORMATTED_VALUE"
    resp = sheet.get(spreadsheetId=id, range="B7", valueRenderOption=ufv).execute()
    value = resp.get("values", [["Not found"]])[0][0]
    print(f"Formula: `{value!r}`")



================================================
FILE: samples/http/README.md
================================================
title: HTTP sample
description: Samples using HTTP requests and webhooks
integrations: []
categories: ["Samples"]



================================================
FILE: samples/http/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way usage of HTTP.

version: v1

project:
  name: http_sample
  vars:
    - name: HTTPBIN_BASE_URL
      value: https://httpbin.org/

  triggers:
    - name: receive_http_get_or_head
      type: webhook
      filter: data.method in ["GET", "HEAD"]
      call: webhooks.py:on_http_get_or_head

    - name: receive_http_post_form
      type: webhook
      event_type: post
      filter: data.headers["Content-Type"] == "application/x-www-form-urlencoded"
      call: webhooks.py:on_http_post_form
    - name: receive_http_post_json
      type: webhook
      event_type: post
      filter: data.headers["Content-Type"].startsWith("application/json")
      call: webhooks.py:on_http_post_json

    - name: send_requests
      type: webhook
      call: webhooks.py:send_requests



================================================
FILE: samples/http/basic_auth.py
================================================
"""This module demonstrates the "requests" library with basic authentication."""

import base64
from urllib.parse import urljoin

import requests


def send_requests(base_url):
    """Send HTTP requests with basic authentication (username + password).

    See: https://datatracker.ietf.org/doc/html/rfc7617
    """
    print("\n>>> Sending HTTP requests with basic authentication")

    expected_creds = ("user", "pass")
    url = urljoin(base_url, f"basic-auth/{expected_creds[0]}/{expected_creds[1]}")

    print("\n--- Use the expected credentials (authentication success)")
    resp = requests.get(url, auth=expected_creds, timeout=10)
    _print_response_details(resp)

    print("\n--- Use unexpected credentials (authentication failure)")
    # Also, set them directly in the HTTP request headers, instead of
    # using the "auth" parameter, just for the sake of demonstration.
    unexpected_creds = "someone_else:wrong_password"
    headers = {
        "Authorization": "Basic " + base64.b64encode(unexpected_creds.encode()).decode()
    }
    resp = requests.get(url, headers=headers, timeout=10)
    _print_response_details(resp)


def _print_response_details(resp):
    print("Response URL:", resp.url)
    print("Response status code:", resp.status_code)
    print("Response text:", resp.text)
    print("Response headers:")
    for key in sorted(resp.headers):
        print(f"  {key} = {resp.headers[key]}")



================================================
FILE: samples/http/bearer_token.py
================================================
"""This module demonstrates the "requests" library with an OAuth bearer token."""

from urllib.parse import urljoin

import requests


def send_requests(base_url):
    """Send HTTP requests with an OAuth bearer token.

    See: https://datatracker.ietf.org/doc/html/rfc6750
    """
    print("\n>>> Sending HTTP requests with an OAuth bearer token")

    url = urljoin(base_url, "bearer")
    token = "my_bearer_token"  # noqa: S105
    headers = {"Authorization": "Bearer " + token}
    resp = requests.get(url, headers=headers, timeout=10)
    _print_response_details(resp)


def _print_response_details(resp):
    print("Response URL:", resp.url)
    print("Response status code:", resp.status_code)
    print("Response text:", resp.text)
    print("Response headers:")
    for key in sorted(resp.headers):
        print(f"  {key} = {resp.headers[key]}")



================================================
FILE: samples/http/no_auth.py
================================================
"""This module demonstrates the "requests" library without authentication."""

from urllib.parse import urljoin

import requests


def send_requests(base_url):
    print(">>> Sending requests without authentication")

    _get_echo_params(base_url)
    _get_html(base_url)
    _get_json(base_url)
    _get_error(base_url)

    url = urljoin(base_url, "post")
    _post_echo_form(url)
    _post_echo_json(url)


def _get_echo_params(base_url):
    """https://httpbin.org/#/HTTP_Methods/get_get"""
    url = urljoin(base_url, "get")
    print(f"\n--- GET {url}")
    resp = requests.get(url, params={"key1": "value1", "key2": "value2"}, timeout=10)
    # Expected: "Content-Type" header is "application/json".
    _print_response_status_and_headers(resp)

    # httpbin echoes back query params (as "args"), headers, and other things
    # in the response's JSON body. In this specific case, the "headers",
    # "args", "url" keys should be present in the response body.

    # Expected JSON: {"args": {"key1": "value1", ... }, ...}
    print(f"Response body (JSON):\n{resp.json()}")
    # Expected text: same as JSON, but formatted as multiline text.
    print(f"Response body (text):\n{resp.text}")


def _get_html(base_url):
    """https://httpbin.org/#/Response_formats/get_html"""
    url = urljoin(base_url, "html")
    print(f"\n--- GET {url}")
    resp = requests.get(url, timeout=10)
    _print_response_status_and_headers(resp)

    # Expected text: "\u003c!DOCTYPE html\u003e\\n..."
    print(f"Response body (text):\n{resp.text}")
    # Don't call resp.json(), since HTML is not valid JSON.


def _get_json(base_url):
    """https://httpbin.org/#/Response_formats/get_json"""
    url = urljoin(base_url, "json")
    print(f"\n--- GET {url}")
    resp = requests.get(url, timeout=10)
    _print_response_status_and_headers(resp)

    # Expected text: same as JSON, but formatted as multiline byte text.
    print(f"response body (bytes):\n{resp.content}")
    # Expected JSON: {"slideshow": {"author": "Yours Truly", ... }}
    print(f"response body (json):\n{resp.json()}")
    # Expected value inside JSON: "Yours Truly".
    slideshow_author = resp.json().get("slideshow", {}).get("author")
    print("response_json['slideshow']['author']:", slideshow_author)


def _get_error(base_url):
    url = urljoin(base_url, "status/404")
    print(f"\n--- GET {url}")
    resp = requests.get(url, timeout=10)
    _print_response_status_and_headers(resp)  # Expected status code: 404.


def _post_echo_form(url):
    """https://httpbin.org/#/HTTP_Methods/post_post"""
    print(f"\n--- POST {url} (form)")
    resp = requests.post(url, data={"foo": "bar"}, timeout=10)
    # Expected: "Content-Type" header is "application/json".
    _print_response_status_and_headers(resp)

    # The form we submitted will be echoed back by httpbin under the "form" key.

    # Expected JSON: {..., "form": {"foo": "bar"}, ...}
    print(f"Response body (JSON):\n{resp.json()}")
    # Expected text: same as JSON, but formatted as multiline text.
    print(f"Response body (text):\n{resp.text}")


def _post_echo_json(url):
    """https://httpbin.org/#/HTTP_Methods/post_post"""
    print(f"\n--- POST {url} (JSON)")

    # Option 1: use the "json" param, without specifying content type.
    resp = requests.post(url, json={"foo": "bar"}, timeout=10)

    # Option 2: use the "data" param, and specify its content type.
    # headers={"Content-Type": "application/json", ...}
    # resp = requests.post(url, data={"foo": "bar"}, headers=headers)

    _print_response_status_and_headers(resp)

    # The JSON we sent will be echoed back by httpbin under the "data" key
    # (as a string), and the "json" key.

    # Expected JSON: {..., "data": "{...}", "json": {"foo": "bar"}, ...}
    print(f"Response body (JSON):\n{resp.json()}")
    # Expected text: same as JSON, but formatted as text.
    print(f"Response body (text):\n{resp.text}")


def _print_response_status_and_headers(resp):
    print("Response status code:", resp.status_code)
    print("Response headers:")
    for key in sorted(resp.headers):
        print(f"  {key} = {resp.headers[key]}")



================================================
FILE: samples/http/webhooks.py
================================================
"""This module demonstrates the usage of AutoKitteh webhooks."""

import os

import basic_auth
import bearer_token
import no_auth


BASE_URL = os.getenv("HTTPBIN_BASE_URL")  # Set in "autokitteh.yaml".


def on_http_get_or_head(event):
    """Handle incoming HTTP GET and HEAD requests.

    - https://www.rfc-editor.org/rfc/rfc9110#name-get
    - https://www.rfc-editor.org/rfc/rfc9110#name-head

    Args:
        event: Incoming HTTP request details.
    """
    _print_request_details(event.data)

    print("Query parameters:")
    if not event.data.url.query:
        print("  none")
    for key in sorted(event.data.url.query):
        print(f"  {key} = {event.data.url.query[key]}")


def on_http_post_form(event):
    """Handle URL-encoded form submissions in HTTP POST requests.

    - https://www.rfc-editor.org/rfc/rfc9110#name-post
    - https://html.spec.whatwg.org/multipage/forms.html

    Args:
        event: Incoming HTTP request details.
    """
    _print_request_details(event.data)
    print(f"Body: {event.data.body.bytes}")

    print("Form parameters:")
    if not event.data.body.form:
        print("  none")
    for key in sorted(event.data.body.form):
        print(f"  {key} = {event.data.body.form[key]}")


def on_http_post_json(event):
    """Handle incoming HTTP POST requests with a JSON body.

    https://www.rfc-editor.org/rfc/rfc9110#name-post

    Args:
        event: Incoming HTTP request details.
    """
    _print_request_details(event.data)
    print(f"Body: {event.data.body.bytes}")
    print(f"JSON: {event.data.body.json}")


def _print_request_details(data):
    print(f"Triggered by an HTTP {data.method} request")
    print("Full URL:", data.raw_url)
    print("URL path:", data.url.path)

    print("Headers:")
    for key in sorted(data.headers):
        print(f"  {key} = {data.headers[key]}")


def send_requests(event):
    """Send various HTTP requests with various authentication schemes."""
    no_auth.send_requests(BASE_URL)
    basic_auth.send_requests(BASE_URL)
    bearer_token.send_requests(BASE_URL)



================================================
FILE: samples/hubspot/README.md
================================================
title: HubSpot sample
description: Simple usage of the HubSpot API
integrations: ["hubspot"]
categories: ["CRM", "Samples"]



================================================
FILE: samples/hubspot/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that demonstrates integration with HubSpot.

version: v1

project:
  name: hubspot

  connections:
    - name: hubspot_conn
      integration: hubspot

  triggers:
    - name: create_contact_webhook
      type: webhook
      event_type: post
      call: program.py:create_contact
    - name: list_deals_webhook
      type: webhook
      event_type: get
      call: program.py:list_deals



================================================
FILE: samples/hubspot/program.py
================================================
"""Demonstration of AutoKitteh's HubSpot integration.

This script showcases two basic operations with the HubSpot API:
creating a new contact and listing all deals.
"""

from autokitteh.hubspot import hubspot_client
from hubspot.crm import contacts


hubspot = hubspot_client("hubspot_conn")


def create_contact(event):
    contact_properties = {
        "email": event.data.body.form.get("email", "meow@autokitteh.com"),
        "firstname": event.data.body.form.get("firstname", "Kitty"),
        "lastname": event.data.body.form.get("lastname", "Meowington"),
    }
    contact_input = contacts.SimplePublicObjectInputForCreate(
        properties=contact_properties
    )

    response = hubspot.crm.contacts.basic_api.create(
        simple_public_object_input_for_create=contact_input
    )

    print(f"Contact created with ID: {response.id}")


def list_deals(event):
    for deal in hubspot.crm.deals.get_all():
        print(f"Deal ID: {deal.id}, deal name: {deal.properties.get('dealname')}")



================================================
FILE: samples/linear/README.md
================================================
title: Linear sample
description: Simple usage of the Linear API
integrations: ["linear"]
categories: ["Samples"]



================================================
FILE: samples/linear/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Linear.

version: v2

project:
  name: linear_sample

  vars:
    - name: TEAM_ID
      value:

  connections:
    - name: linear_conn
      integration: linear

  triggers:
    - name: create_issue_webhook
      type: webhook
      event_type: post
      call: program.py:create_issue

    - name: get_issue_webhook
      type: webhook
      event_type: get
      call: program.py:get_issue

    - name: update_issue_webhook
      type: webhook
      event_type: post
      call: program.py:update_issue



================================================
FILE: samples/linear/program.py
================================================
"""Demonstrates AutoKitteh's Linear integration for managing issues.

This sample shows how to create issues in Linear and retrieve issue information.

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

import os

from autokitteh.linear import linear_client
import queries


linear = linear_client("linear_conn")

TEAM_ID = os.getenv("TEAM_ID", "")  # Must be UUID type.


def create_issue(event):
    """Create a new issue in Linear.

    This function creates an issue with a title and optional description from form data.

    Args:
        event: The HTTP event containing request data.
    """
    if not TEAM_ID:
        print("Error: TEAM_ID environment variable is not set")
        return

    form = event.data.body.form
    issue_title = form.get("title", "AutoKitteh Issue")
    description = form.get("description", "Created by AutoKitteh")

    variables = {"teamId": TEAM_ID, "title": issue_title, "description": description}

    response = linear.post(
        "https://api.linear.app/graphql/",
        json={"query": queries.CREATE_ISSUE_QUERY, "variables": variables},
    )
    response.raise_for_status()

    result = response.json()
    print(result)

    if "data" in result and result["data"] is not None:
        issue = result["data"]["issueCreate"]["issue"]
        issue_id = issue["id"]
        issue_url = issue["url"]

        print(f"Issue '{issue_title}' created successfully!")
        print(f"Issue ID: {issue_id}")
        print(f"Issue URL: {issue_url}")
    else:
        print("Failed to create issue.")
        print("Error:", result.get("errors"))


def get_issue(event):
    """Retrieve information about a Linear issue.

    This function retrieves issue details using an issue ID from query parameters.

    Args:
        event: The HTTP event containing request data.
    """
    issue_id = event.data.url.query.get("issue_id")
    if not issue_id:
        print("Error: issue_id parameter is required")
        return

    variables = {"id": issue_id}
    response = linear.post(
        "https://api.linear.app/graphql/",
        json={"query": queries.GET_ISSUE_QUERY, "variables": variables},
    )
    response.raise_for_status()

    result = response.json()
    print(result)

    if "data" in result and result["data"] is not None:
        issue = result["data"]["issue"]
        print(f"""Issue ID: {issue["id"]}
Title: {issue["title"]}
Description: {issue["description"]}
State: {issue["state"]["name"]}
Priority: {issue["priority"]}
Created: {issue["createdAt"]}
Updated: {issue["updatedAt"]}
URL: {issue["url"]}""")

        if issue["assignee"]:
            print(f"Assignee: {issue['assignee']['name']}")
    else:
        print("Failed to retrieve issue.")
        print("Error:", result.get("errors"))


def update_issue(event):
    """Update an existing Linear issue.

    This function updates an issue's title and/or state.

    Args:
        event: The HTTP event containing request data.
    """
    form = event.data.body.form
    issue_id = form.get("issue_id")
    new_title = form.get("title")
    state_id = form.get("state_id")

    if not issue_id:
        print("Error: issue_id parameter is required")
        return

    # Build update payload.
    update_data = {}
    if new_title:
        update_data["title"] = new_title
    if state_id:
        update_data["stateId"] = state_id

    variables = {"id": issue_id, "input": update_data}
    response = linear.post(
        "https://api.linear.app/graphql/",
        json={"query": queries.UPDATE_ISSUE_QUERY, "variables": variables},
    )
    response.raise_for_status()

    result = response.json()
    print(result)

    if "data" in result and result["data"] is not None:
        issue = result["data"]["issueUpdate"]["issue"]
        print(f"Issue {issue_id} updated successfully!")
        print(f"New title: {issue['title']}")
    else:
        print("Failed to update issue.")
        print("Error:", result.get("errors"))



================================================
FILE: samples/linear/queries.py
================================================
"""GraphQL queries for interacting with Linear issues.

This module contains query strings for creating and managing issues via the Linear API.
"""

CREATE_ISSUE_QUERY = """
mutation CreateIssue($teamId: String!, $title: String!, $description: String) {
    issueCreate(
        input: {
            teamId: $teamId
            title: $title
            description: $description
        }
    ) {
        success
        issue {
            id
            url
        }
    }
}
"""


GET_ISSUE_QUERY = """
query GetIssue($id: String!) {
    issue(id: $id) {
        id
        title
        description
        state {
            name
        }
        priority
        createdAt
        updatedAt
        url
        assignee {
            name
        }
    }
}
"""

UPDATE_ISSUE_QUERY = """
mutation UpdateIssue($id: String!, $input: IssueUpdateInput!) {
    issueUpdate(
        id: $id
        input: $input
    ) {
        success
        issue {
            id
            title
        }
    }
}
"""



================================================
FILE: samples/notion/README.md
================================================
title: Notion sample
description: Simple usage of the Notion API
integrations: ["notion"]
categories: ["Samples"]



================================================
FILE: samples/notion/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Notion.

version: v2

project:
  name: notion_sample

  vars:
    - name: DATABASE_ID
      value:

  connections:
    - name: notion_conn
      integration: notion

  triggers:
    - name: create_page_webhook
      type: webhook
      event_type: post
      call: program.py:create_page

    - name: get_page_webhook
      type: webhook
      event_type: get
      call: program.py:get_page



================================================
FILE: samples/notion/program.py
================================================
"""Demonstrates AutoKitteh's Notion integration for managing pages.

This sample shows how to create pages in a Notion database
and retrieve page information.

API details:
- Notion API: https://developers.notion.com/
- Python client library: https://github.com/ramnes/notion-sdk-py

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

import os

from autokitteh.notion import notion_client
from notion_client.errors import APIResponseError


notion = notion_client("notion_conn")

DATABASE_ID = os.getenv("DATABASE_ID", "")


def create_page(event):
    """Create a new page in a Notion database.

    This function creates a page with a title from the form data.

    Example usage:
    - URL: "http://localhost:9980/webhooks/<webhook_slug>"
    - Curl command:
      curl -X POST "<URL>" -d "title=My New Page"

    Args:
        event: The HTTP event containing request data.
    """
    form = event.data.body.form
    page_title = form.get("title", "AutoKitteh Page")

    try:
        new_page = notion.pages.create(
            parent={"database_id": DATABASE_ID},
            properties={
                "Name": {"title": [{"text": {"content": page_title}}]},
            },
        )
        page_id = new_page["id"]
        page_url = new_page["url"]
        print(f"Page '{page_title}' created successfully!")
        print(f"Page ID: {page_id}")
        print(f"Page URL: {page_url}")
    except APIResponseError as e:
        print(f"Error: {e}")


def get_page(event):
    """Retrieve information about a Notion page.

    This function retrieves page details using a page ID from query parameters.

    Example usage:
    - URL: "http://localhost:9980/webhooks/<webhook_slug>"
    - Curl command:
      curl "<URL>?page_id=<PAGE_ID>"

    Args:
        event: The HTTP event containing request data.
    """
    page_id = event.data.url.query.get("page_id")

    if not page_id:
        print("Error: page_id parameter is required")
        return

    try:
        # Retrieve the page
        page = notion.pages.retrieve(page_id)

        # Extract and display page information
        print(f"Page ID: {page['id']}")
        print(f"Created time: {page['created_time']}")
        print(f"Last edited: {page['last_edited_time']}")
        print(f"Page URL: {page['url']}")

        # Display properties if available
        if "properties" in page:
            print(f"\nPage properties: {page['properties']}")
    except APIResponseError as e:
        print(f"Error: {e}")



================================================
FILE: samples/openai_chatgpt/README.md
================================================
title: OpenAI ChatGPT sample
description: Samples using chatGPT APIs
integrations: ["chatgpt"]
categories: ["AI", "Samples"]



================================================
FILE: samples/openai_chatgpt/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with
# OpenAI ChatGPT (https://chat.openai.com).

version: v1

project:
  name: chatgpt_sample

  connections:
    - name: chatgpt_conn
      integration: chatgpt

  triggers:
    - name: on_http_get
      type: webhook
      event_type: post
      filter: data.headers["Content-Type"] == "text/plain"
      call: program.py:on_http_post



================================================
FILE: samples/openai_chatgpt/program.py
================================================
"""This program demonstrates AutoKitteh's OpenAI ChatGPT integration.

The program implements a single entry-point function, which is
configured in the "autokitteh.yaml" manifest file to receive HTTP GET requests.

It sends a couple of requests to the ChatGPT API, and prints the responses
in the AutoKitteh session log, along with ChatGPT token usage stats.

API details:
- OpenAI developer platform: https://platform.openai.com/
- Python client library: https://github.com/openai/openai-python

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

from autokitteh.openai import openai_client


MODEL = "gpt-4o-mini"

chatgpt_client = openai_client("chatgpt_conn")


def on_http_post(event):
    """Entry-point function for handling HTTP GET requests in this workflow.

    Example usage:
    - URL: "http://localhost:9980/webhooks/<webhook_slug>"
    - Curl command:
      curl -X POST "<URL>" -H "Content-Type: text/plain" -d "Why do cats purr?"

    Args:
        event: The HTTP event containing request data.
    """
    body = ""
    if event:
        body = event.data.body.bytes.decode("utf-8")

    # Example 1: trivial interaction with ChatGPT.
    msg = {"role": "user", "content": body or "Meow"}
    resp = chatgpt_client.chat.completions.create(model=MODEL, messages=[msg])

    # For educational and debugging purposes, print ChatGPT's response
    # in the AutoKitteh session's log.
    print(resp)

    # Example 2: more verbose interaction with ChatGPT,
    # including the user's text as part of the conversation.
    msgs = [
        {
            "role": "system",
            "content": (
                "You are a poetic assistant, skilled in "
                "explaining complex engineering concepts."
            ),
        },
        {
            "role": "user",
            "content": body
            or (
                "Compose a Shakespearean sonnet about the importance of reliability, "
                "scalability, and durability, in distributed workflows."
            ),
        },
    ]

    resp = chatgpt_client.chat.completions.create(model=MODEL, messages=msgs)

    for choice in resp.choices:
        print(choice.message.content)
    print(f"Usage: `{resp.usage}`")



================================================
FILE: samples/pipedrive/README.md
================================================
title: Pipedrive sample
description: Simple usage of the Pipedrive API
integrations: ["pipedrive"]
categories: ["Samples"]



================================================
FILE: samples/pipedrive/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Pipedrive.

version: v2

project:
  name: pipedrive_sample

  connections:
    - name: pipedrive_conn
      integration: pipedrive

  triggers:
    - name: create_deal_webhook
      type: webhook
      event_type: post
      call: program.py:create_deal

    - name: fetch_all_deals_webhook
      type: webhook
      event_type: get
      call: program.py:fetch_all_deals



================================================
FILE: samples/pipedrive/program.py
================================================
"""Demonstrates AutoKitteh's Pipedrive integration for managing deals.

This sample shows how to create deals in Pipedrive
and retrieve deal information.

API details:
- Pipedrive API: https://developers.pipedrive.com/
- Python client library: https://github.com/pipedrive/client-python

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

from autokitteh.pipedrive import pipedrive_client


pipedrive = pipedrive_client("pipedrive_conn")


def create_deal(event):
    """Create a new deal in Pipedrive."""
    form = event.data.body.form
    deal_title = form.get("title", "AutoKitteh Deal")
    deal_value = form.get("value", "1000")

    # Create a new deal
    response = pipedrive.deals.create_deal(
        {
            "title": deal_title,
            "value": deal_value,
        }
    )

    if "success" in response and response["success"]:
        deal = response["data"]
        deal_id = deal["id"]
        deal_title = deal["title"]
        print(f"Deal '{deal_title}' created successfully!")
        print(f"Deal ID: {deal_id}")
        print(f"Value: {deal.get('value')} {deal.get('currency')}")
    else:
        print(f"Error creating deal: {response}")


def fetch_all_deals(_):
    """Retrieve information about all Pipedrive deals."""
    response = pipedrive.deals.get_all_deals()
    deals = response["data"]
    for deal in deals:
        print(deal["title"], "(worth", deal["value"], deal["currency"] + ")")



================================================
FILE: samples/reddit/README.md
================================================
title: Reddit sample
description: Simple usage of the Reddit API
integrations: ["reddit"]
categories: ["Samples"]



================================================
FILE: samples/reddit/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with Reddit.

version: v2

project:
  name: reddit_sample

  vars:
    - name: SUBREDDIT
      value:

  connections:
    - name: reddit_conn
      integration: reddit

  triggers:
    - name: create_post_webhook
      type: webhook
      event_type: post
      call: program.py:create_post

    - name: add_comment_webhook
      type: webhook
      event_type: post
      call: program.py:add_comment



================================================
FILE: samples/reddit/program.py
================================================
"""Demonstrates AutoKitteh's Reddit integration for managing posts and comments.

This sample shows how to create posts on Reddit, add comments, and retrieve post info.

This program isn't meant to cover all available functions and events.
It merely showcases various illustrative, annotated, reusable examples.
"""

import os

from autokitteh.reddit import reddit_client
from praw.exceptions import RedditAPIException


reddit = reddit_client("reddit_conn")

SUBREDDIT = os.getenv("SUBREDDIT", "")


def create_post(event):
    """Create a new post in a subreddit."""
    if not SUBREDDIT:
        print("Error: SUBREDDIT environment variable is not set")
        return

    form = event.data.body.form
    post_title = form.get("title", "AutoKitteh Post")
    post_content = form.get("content", "Created by AutoKitteh")
    post_flair = form.get("flair", "default")

    try:
        subreddit = reddit.subreddit(SUBREDDIT)
        submission = subreddit.submit(
            post_title, selftext=post_content, flair_id=post_flair
        )
        print(f"Post '{post_title}' created successfully!")
        print(f"Post ID: {submission.id}")
        print(f"Post URL: {submission.url}")
        print(f"Permalink: https://reddit.com{submission.permalink}")
    except RedditAPIException as e:
        print("Failed to create post.")
        print("Error:", str(e))


def add_comment(event):
    """Add a comment to an existing post.

    This function adds a comment to a post using the post ID from form data.

    Args:
        event: The HTTP event containing request data.
    """
    form = event.data.body.form
    post_id = form.get("post_id")
    comment_text = form.get("comment", "Comment from AutoKitteh")

    if not post_id:
        print("Error: post_id parameter is required")
        return

    try:
        submission = reddit.submission(id=post_id)
        comment = submission.reply(comment_text)

        print(f"Comment added successfully to post {post_id}")
        print(f"Comment ID: {comment.id}")
        print(f"Comment URL: https://reddit.com{comment.permalink}")
    except RedditAPIException as e:
        print("Failed to add comment.")
        print("Error:", str(e))



================================================
FILE: samples/runtime_events/README.md
================================================
title: Runtime Events sample
description: Samples using events in AutoKitteh - subscribe(), next_event(), unsubscribe()
integrations: []
categories: ["Samples"]
tags:
  [
    "subscribe",
    "next_event",
    "unsubscribe",
    "event_filtering",
    "timeout_handling",
    "essential",
  ]



================================================
FILE: samples/runtime_events/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates runtime event handling.

version: v1

project:
  name: runtime_events_sample

  triggers:
    - name: meow_webhook
      type: webhook
      event_type: get
      filter: data.url.path.endsWith("/meow")
      call: program.py:on_http_get_meow



================================================
FILE: samples/runtime_events/program.py
================================================
"""This program demonstrates AutoKitteh's runtime event handling."""

from datetime import timedelta

import autokitteh


def on_http_get_meow(event):
    """This workflow is triggered by a predefined HTTP GET request event."""
    print("Got a meow, waiting for a woof")

    # Wait (up to 1 minute) for a subsequent webhook
    # event where the URL path ends with "woof".
    filter = "data.url.path.endsWith('/woof')"
    sub = autokitteh.subscribe("meow_webhook", filter)
    delta = timedelta(minutes=1)
    next = autokitteh.next_event(sub, timeout=delta)

    if next:
        print("Got a woof:", next)
    else:
        print("Timeout!")



================================================
FILE: samples/scheduler/README.md
================================================
title: Scheduler sample
description: Samples using cron scheduler for workflows
integrations: []
categories: ["Samples"]
tags: ["scheduler"]



================================================
FILE: samples/scheduler/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates integration with a
# cron-like scheduler.

version: v1

project:
  name: scheduler_sample

  vars:
    - name: GITHUB_OWNER
      value:
    - name: GITHUB_REPO
      value:
    - name: OPENED_CUTOFF
      value: 4 # days
    - name: UPDATE_CUTOFF
      value: 1 # days

  connections:
    - name: github_conn
      integration: github

  triggers:
    - name: daily
      schedule: "@daily" # Same as "@midnight", "@every 1d", or "0 0 * * *".
      call: program.py:on_cron_trigger



================================================
FILE: samples/scheduler/program.py
================================================
"""This program demonstrates AutoKitteh's scheduler capabilities.

It implements a single entry-point function, configured in the "autokitteh.yaml"
file to receive "scheduler" events, and uses constant values defined in the
"autokitteh.yaml" manifest for each AutoKitteh environment.
"""

from datetime import datetime, timedelta, UTC
import os

from autokitteh.github import github_client


# Set in "autokitteh.yaml"
GITHUB_OWNER = os.getenv("GITHUB_OWNER")
GITHUB_REPO = os.getenv("GITHUB_REPO")
OPENED_CUTOFF = os.getenv("OPENED_CUTOFF")
UPDATE_CUTOFF = os.getenv("UPDATE_CUTOFF")

github = github_client("github_conn")


def on_cron_trigger(_):
    """Handles the AutoKitteh cron schedule trigger."""
    # Fetch open pull requests that are not drafts or WIP
    repo = github.get_repo(f"{GITHUB_OWNER}/{GITHUB_REPO}")
    active_prs = [
        pr
        for pr in repo.get_pulls(state="open")
        if not pr.draft
        and "draft" not in pr.title.lower()
        and "wip" not in pr.title.lower()
    ]

    now = datetime.now(UTC)
    opened_cutoff = now - timedelta(days=int(OPENED_CUTOFF))
    update_cutoff = now - timedelta(days=int(UPDATE_CUTOFF))

    msg = "Daily reminder about stalled PRs:"

    for pr in active_prs:
        stalled_details = _get_stalled_pr_details(pr, now, opened_cutoff, update_cutoff)

        if stalled_details:
            print(f"PR {pr.number} is stalled")
            msg += f"\nPR: `{pr.title}`\n  {pr.url}\n  {stalled_details}\n"
            print(msg)


def _get_stalled_pr_details(pr, now, opened_cutoff, update_cutoff):
    """Returns details if a PR is stalled, otherwise returns an empty string."""
    details = []

    if pr.created_at < opened_cutoff:
        details.append(f"opened {_hours_ago(now, pr.created_at)}h ago")
    if pr.updated_at < update_cutoff:
        details.append(f"last updated {_hours_ago(now, pr.updated_at)}h ago")

    return ", ".join(details)


def _hours_ago(now, past_time):
    """Returns the number of hours between now and a past datetime."""
    delta = now - past_time
    return delta.total_seconds() // 3600



================================================
FILE: samples/slack/README.md
================================================
title: Slack sample
description: Samples using Slack APIs
integrations: ["slack"]
categories: ["Samples"]
tags: ["interactive_workflows", "user_interactions", "AttrDict", "webhook_handling", "essential"]



================================================
FILE: samples/slack/approval_message.json.txt
================================================
[
    {
        "type": "header",
        "text": {
            "type":  "plain_text",
            "emoji": true,
            "text":  "Title"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "Message"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "actions",
        "elements": [
            {
                "type":  "button",
                "style": "primary",
                "text": {
                    "type":  "plain_text",
                    "emoji": true,
                    "text":  "Approve"
                },
                "value":     "Approve",
                "action_id": "Approve ActionID"
            },
            {
                "type":  "button",
                "style": "danger",
                "text": {
                    "type":  "plain_text",
                    "emoji": true,
                    "text":  "Deny"
                },
                "value":     "Deny",
                "action_id": "Deny ActionID"
            }
        ]
    }
]



================================================
FILE: samples/slack/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Slack (https://slack.com).

version: v1

project:
  name: slack_sample

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: slack_app_mention
      connection: slack_conn
      event_type: app_mention
      call: program.py:on_slack_app_mention
    - name: slack_interaction
      connection: slack_conn
      event_type: interaction
      call: program.py:on_slack_interaction
    - name: slack_message
      connection: slack_conn
      event_type: message
      call: program.py:on_slack_message
    - name: slack_reaction_added
      connection: slack_conn
      event_type: reaction_added
      call: program.py:on_slack_reaction_added
    - name: slack_slash_command
      connection: slack_conn
      event_type: slash_command
      call: program.py:on_slack_slash_command



================================================
FILE: samples/slack/message.json
================================================
{
    "blocks": [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": "This is a header block",
                "emoji": true
            }
        },
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "This is a section block with a button."
            },
            "accessory": {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "text": "Click Me",
                    "emoji": true
                },
                "value": "click_me_123",
                "url": "https://google.com",
                "action_id": "button-action"
            }
        }
    ]
}



================================================
FILE: samples/slack/program.py
================================================
"""This program demonstrates AutoKitteh's 2-way Slack integration.

This program implements multiple entry-point functions that are triggered
by incoming Slack events, as defined in the "autokitteh-python.yaml"
manifest file. These functions also execute various Slack API calls.

Events that this program responds to:
- Mentions of the Slack app in messages (e.g. "Hi @autokitteh")
- Slash commands registered by the Slack app (`/autokitteh <channel name or ID>`)
- New and edited messages and replies
- New emoji reactions

Slack API documentation:
- Python client API: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html
- Events API reference: https://api.slack.com/events?filter=Events

This program isn't meant to cover all available functions and events.
It merely showcases a few illustrative, annotated, reusable examples.
"""

from pathlib import Path
import time

import autokitteh
from autokitteh.slack import slack_client


def on_slack_app_mention(event):
    """https://api.slack.com/events/app_mention

    Args:
        event: Slack event data.
    """
    slack = slack_client("slack_conn")

    # Send messages in response to the event:
    # - DM to the user who triggered the event (channel ID = user ID)
    # - Two messages to the channel "#slack-test"
    # See: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html#slack_sdk.web.client.WebClient.chat_postMessage
    text = f"You mentioned me in <#{event.data.channel}> and wrote: `{event.data.text}`"
    slack.chat_postMessage(channel=event.data.user, text=text)

    text = text.replace("You", f"<@{event.data.user}>")
    slack.chat_postMessage(channel="#slack-test", text=text)

    text = "Before update :crying_cat_face:"
    resp = slack.chat_postMessage(channel="#slack-test", text=text)

    # Encountered an error? Print debugging information
    # in the AutoKitteh session's log, and finish.
    resp.validate()

    # Update the last sent message, after a few seconds.
    # See: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html#slack_sdk.web.client.WebClient.chat_update
    time.sleep(10)
    resp = autokitteh.AttrDict(resp.data)
    text = "After update :smiley_cat:"
    resp = slack.chat_update(channel=resp.channel, ts=resp.ts, text=text)
    resp = autokitteh.AttrDict(resp.data)

    # Reply to the message's thread, after a few seconds.
    time.sleep(5)
    text = "Reply before update :crying_cat_face:"
    resp = slack.chat_postMessage(channel=resp.channel, text=text, thread_ts=resp.ts)
    resp = autokitteh.AttrDict(resp.data)

    # Update the threaded reply message, after a few seconds.
    time.sleep(5)
    text = "Reply after update :smiley_cat:"
    slack.chat_update(channel=resp.channel, ts=resp.ts, text=text)

    # Add a reaction to the threaded reply message.
    # See: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html#slack_sdk.web.client.WebClient.reactions_add
    slack.reactions_add(channel=resp.channel, name="blob-clap", timestamp=resp.ts)

    # Retrieve all the replies.
    # See: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html#slack_sdk.web.client.WebClient.conversations_replies
    resp = slack.conversations_replies(channel=resp.channel, ts=resp.ts)

    # For educational purposes, print all the replies in the AutoKitteh session's log.
    resp.validate()
    for text in resp.get("messages", default=[]):
        print(text)


def on_slack_message(event):
    """https://api.slack.com/events/message

    Args:
        event: Slack event data.
    """
    slack = slack_client("slack_conn")

    if not event.data.subtype:
        user = f"<@{event.data.user}>"
        if not event.data.thread_ts:
            _on_slack_new_message(slack, event.data, user)
        else:
            # https://api.slack.com/events/message/message_replied
            _on_slack_reply_message(slack, event.data, user)
    elif event.data.subtype == "message_changed":
        user = f"<@{event.data.message.user}>"  # Not the same as above!
        _on_slack_message_changed(slack, event.data, user)


def _on_slack_new_message(slack, data, user):
    """Someone wrote a new message."""
    text = f":point_up: {user} wrote: `{data.text}`"
    slack.chat_postMessage(channel=data.channel, text=text)


def _on_slack_reply_message(slack, data, user):
    """Someone wrote a reply in a thread."""
    text = f":point_up: {user} wrote a reply to <@{data.parent_user_id}>: `{data.text}`"
    ts = data.thread_ts
    slack.chat_postMessage(channel=data.channel, text=text, thread_ts=ts)


def _on_slack_message_changed(slack, data, user):
    """Someone edited a message."""
    old, new = data.previous_message.text, data.message.text
    text = f":point_up: {user} edited a message from `{old}` to `{new}`"

    # Thread TS may or may not be empty, depending on the edited message.
    thread = data.message.thread_ts

    slack.chat_postMessage(channel=data.channel, text=text, thread_ts=thread)


def on_slack_reaction_added(event):
    """https://api.slack.com/events/reaction_added

    Args:
        event: Slack event data.
    """
    # For educational purposes, print the event data in the AutoKitteh session's log.
    print(event.data.user)
    print(event.data.reaction)
    print(event.data.item)


def on_slack_slash_command(event):
    """https://api.slack.com/interactivity/slash-commands

    See also: https://api.slack.com/interactivity/handling#message_responses

    The text after the slash command is expected to be a valid target for a
    Slack message (https://api.slack.com/methods/chat.postMessage#channels):
    Slack user ID ("U"), user DM ID ("D"), multi-person/group DM ID ("G"),
    channel ID ("C"), or channel name (with or without the "#" prefix).

    Note that all targets except "U", "D" and public channels require
    the Slack app to be added in advance.

    Args:
        event: Slack event data.
    """
    slack = slack_client("slack_conn")

    # Retrieve the profile information of the user who triggered this event.
    # See: https://slack.dev/python-slack-sdk/api-docs/slack_sdk/web/client.html#slack_sdk.web.client.WebClient.users_info
    user_info = slack.users_info(user=event.data.user_id)

    # Encountered an error? Print debugging information
    # in the AutoKitteh session's log, and finish.
    user_info.validate()

    profile = autokitteh.AttrDict(user_info.data).user.profile
    text = f"Slack mention: <@{event.data.user_id}>"
    slack.chat_postMessage(channel=event.data.user_id, text=text)
    text = "Full name: " + profile.real_name
    slack.chat_postMessage(channel=event.data.user_id, text=text)
    text = "Email: " + profile.email
    slack.chat_postMessage(channel=event.data.user_id, text=text)

    # Treat the text of the user's slash command as a message target (e.g.
    # channel or user), and send an interactive message to that target.
    blocks = Path("approval_message.json.txt").read_text()
    changes = [
        ("Title", "Question From " + profile.real_name),
        ("Message", "Please select one of these options... :smiley_cat:"),
        ("ActionID", event.data.user_id),
    ]
    for old, new in changes:
        blocks = blocks.replace(old, new)

    slack.chat_postMessage(channel=event.data.text, blocks=blocks)


def on_slack_interaction(event):
    """https://api.slack.com/reference/interaction-payloads/block-actions

    Args:
        event: Slack event data.
    """
    # The Slack ID of the user who sent the question
    # (we stored this in the buttons' action IDs).
    action = autokitteh.AttrDict(event.data.actions[0])
    origin = action.action_id.split()[-1]

    # User selection = action value = button text
    # (our convention, not Slack's, alternatives: action style/text).
    text = f"<@{event.data.user.id}> clicked the `{action.value}` button"
    if action.style == "primary":  # Green button.
        text += " :+1:"
    elif action.style == "danger":  # Red button.
        text += " :-1:"

    slack = slack_client("slack_conn")
    slack.chat_postMessage(channel=origin, text=text)



================================================
FILE: samples/sync_webhook/README.md
================================================
title: Sync Webhook sample
description: Sample demonstrating synchronous webhook handling with multiple triggers
integrations: []
categories: ["Samples"]
tags: ["webhook", "sync", "subscribe", "next_event", "http_outcome", "outcome", "essential"]



================================================
FILE: samples/sync_webhook/autokitteh.yaml
================================================
version: v1

project:
  name: sync_webhook

  triggers:
    - name: first
      type: webhook
      call: program.py:on_first
      is_sync: true

    - name: second
      type: webhook
      # No call specified, this is just used to allocate a webhook URL.
      # The script in program.py will just call `next_event` on this
      # to detect that it's triggered.



================================================
FILE: samples/sync_webhook/program.py
================================================
"""A simple workflow that is triggered by a webhook."""

from autokitteh import http_outcome, next_event, subscribe


def on_first(_):
    print("First webhook triggered!")

    s = subscribe("second")
    e = next_event(s)

    print("Second webhook triggered!")

    http_outcome(status_code=200, body=e.body.text)



================================================
FILE: samples/twilio/README.md
================================================
title: Twilio sample
description: Samples using Twilio APIs
integrations: ["twilio"]
categories: ["Samples"]



================================================
FILE: samples/twilio/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates 2-way integration with
# Twilio (https://www.twilio.com).

version: v1

project:
  name: twilio_sample

  vars:
    - name: FROM_PHONE_NUMBER
      value:

  connections:
    - name: twilio_conn
      integration: twilio

  triggers:
    - name: http_get
      type: webhook
      event_type: get
      call: program.py:on_http_get



================================================
FILE: samples/twilio/program.py
================================================
"""This program demonstrates AutoKitteh's Twilio integration.

This program implements a single entry-point function triggered by an
HTTP GET request event, as defined in the "autokitteh.yaml" manifest file.

API details:
- Messaging API overview: https://www.twilio.com/docs/messaging/api
- Voice API overview: https://www.twilio.com/docs/voice/api

It also demonstrates using constant values which are set for each
AutoKitteh environment in the "autokitteh.yaml" manifest file.
"""

import os

from autokitteh.twilio import twilio_client


FROM_PHONE_NUMBER = os.getenv("FROM_PHONE_NUMBER")

t = twilio_client("twilio_conn")


def on_http_get(event):
    """Entry-point for workflow.

    This function is triggered by an HTTP GET request event and is used to
    send SMS and WhatsApp messages via Twilio.

    Example usage:
    curl "http://localhost:9980/webhooks/<webhook_slug>?to=+15551234567"

    The phone number to send the message to must be provided in the query
    parameter 'to'. The message will be sent both as an SMS and a WhatsApp
    message to the specified number.

    Args:
        event (object): An event object containing the request data.
    """
    to = event.data["url"]["query"]["to"]

    # Add a '+' if missing
    if not to.startswith("+"):
        to = f"+{to}"

    # Send SMS text via Twilio
    message = t.messages.create(
        from_=FROM_PHONE_NUMBER,
        to=to,
        body="This is an AutoKitteh demo message, meow!",
    )
    print(f"SMS message sent: {message.sid}")

    # Send a WhatsApp message to the same number
    whatsapp_message = t.messages.create(
        from_="whatsapp:" + FROM_PHONE_NUMBER,
        to="whatsapp:" + to,
        body="This is an AutoKitteh demo message, meow!",
    )
    print(f"WhatsApp message sent: {whatsapp_message.sid}")



================================================
FILE: scrapingbee_fetch_news/README.md
================================================
title: ScrapingBee News Digest
description: Fetch news from RSS feeds and post article summaries to Slack using ScrapingBee
integrations: ["slack"]
categories: ["Samples"]
tags: ["web_scraping"]



================================================
FILE: scrapingbee_fetch_news/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that fetches news articles using ScrapingBee
# and posts summaries to a Slack channel.

version: v2

project:
  name: ScrapingBee
  connections:
    - name: slack_conn
      integration: slack
  triggers:
    - name: on_app_mention
      event_type: app_mention
      is_durable: false
      connection: slack_conn
      call: program.py:on_app_mention
  vars:
    - name: SB_API_KEY
      value: ""
      description: "scrapingbee api key"
    - name: NEWS_WEBSITE_URL
      value: "https://www.theguardian.com/international/rss"
      description: "news website url"
    - name: SLACK_CHANNEL
      value: ""
      description: "slack channel name or ID"



================================================
FILE: scrapingbee_fetch_news/program.py
================================================
"""Web scraping with ScrapingBee to fetch news articles and post summaries to Slack."""

import os
from scrapingbee import ScrapingBeeClient
from bs4 import BeautifulSoup
from autokitteh.slack import slack_client

SB_API_KEY = os.getenv("SB_API_KEY")
NEWS_WEBSITE_URL = os.getenv("NEWS_WEBSITE_URL")
SLACK_CHANNEL = os.getenv("SLACK_CHANNEL", "#news")

client = ScrapingBeeClient(api_key=SB_API_KEY)
slack = slack_client("slack_conn")


def on_app_mention(event):
    """Fetch news articles and post summaries to Slack."""
    if not NEWS_WEBSITE_URL:
        print("NEWS_WEBSITE_URL not set")
        return

    feed = client.get(
        NEWS_WEBSITE_URL, params={"render_js": False, "block_resources": True}
    )
    if feed.status_code != 200:
        slack.chat_postMessage(
            channel=SLACK_CHANNEL,
            text=f"Failed to fetch news feed: HTTP {feed.status_code}",
        )
        print("Feed fetch failed:", feed.status_code)
        return

    soup = BeautifulSoup(feed.content, "xml")
    items = soup.select("item")[:5]

    if not items:
        slack.chat_postMessage(
            channel=SLACK_CHANNEL,
            text="No news items found in the feed.",
        )
        print("No items found in feed.")
        return

    slack.chat_postMessage(
        channel=SLACK_CHANNEL,
        text="News Digest",
        blocks=build_blocks(items),
    )


def extract_excerpt(html):
    """Best-effort article body extraction."""
    soup = BeautifulSoup(html, "html.parser")
    body = (
        soup.select_one('[data-gu-name="body"]')
        or soup.select_one("article")
        or soup.select_one('[itemprop="articleBody"]')
    )
    text = body.get_text(" ", strip=True) if body else ""
    return text[:400] + ("‚Ä¶" if len(text) > 400 else "")


def build_blocks(items):
    blocks = [
        {"type": "header", "text": {"type": "plain_text", "text": "Top Headlines"}},
        {
            "type": "context",
            "elements": [
                {"type": "mrkdwn", "text": f"Source: <{NEWS_WEBSITE_URL}|RSS>"}
            ],
        },
        {"type": "divider"},
    ]

    for item in items:
        title = item.title.get_text(strip=True)
        link = item.link.get_text(strip=True)
        r = client.get(link, params={"render_js": False, "block_resources": True})
        excerpt = (
            extract_excerpt(r.content)
            if r.status_code == 200
            else "_Unable to fetch article_"
        )

        blocks += [
            {
                "type": "section",
                "text": {"type": "mrkdwn", "text": f"*<{link}|{title}>*\n{excerpt}"},
            },
            {"type": "divider"},
        ]
    return blocks



================================================
FILE: scrapingbee_fetch_news/requirements.txt
================================================
scrapingbee
bs4


================================================
FILE: sheets_to_soap/README.md
================================================
title: Google Sheets to SOAP Calculator
description: Reads numeric values from Google Sheets and sends them to a SOAP-based calculator API
integrations: ["googlesheets"]
categories: ["Productivity", "DevOps"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: sheets_to_soap/autokitteh.yaml
================================================
# Autokitteh configuration file for the sheets_to_soap project

version: v1

project:
  name: sheets_to_soap
  vars:
    - name: SOAP_WSDL
      value: http://www.dneonline.com/calculator.asmx?WSDL
    - name: SHEET_ID
      value:
    - name: SHEET_RANGE
      value:

  connections:
    - name: sheets_conn
      integration: googlesheets

  triggers:
    - name: webhook
      type: webhook
      event_type: get
      call: program.py:on_trigger



================================================
FILE: sheets_to_soap/program.py
================================================
"""Reads pairs of numbers from a Google Sheet and sends them to a SOAP calculator."""

import os

from autokitteh.google import google_sheets_client
from zeep import Client


sheet = google_sheets_client("sheets_conn").spreadsheets().values()

SHEET_ID = os.getenv("SHEET_ID")
SHEET_RANGE = os.getenv("SHEET_RANGE")
SOAP_WSDL = os.getenv("SOAP_WSDL")

client = Client(SOAP_WSDL)


def on_trigger(_):
    """Workflow entry point."""
    response = sheet.get(spreadsheetId=SHEET_ID, range=SHEET_RANGE).execute()
    rows = response.get("values", [])

    if not rows:
        print("No data found.")
        return

    for row in rows:
        a = int(row[0])
        b = int(row[1])

        result = client.service.Add(intA=a, intB=b)
        print(f"{a} + {b} = {result}")



================================================
FILE: sheets_to_soap/requirements.txt
================================================
zeep


================================================
FILE: slack_discord_sync/README.md
================================================
title: Slack-Discord Message Mirroring Workflow
description: Automatically mirror messages between Slack and Discord channels
integrations: ["slack", "discord"]
categories: ["Productivity"]
tags: ["webhook_handling", "notifications", "data_processing"]



================================================
FILE: slack_discord_sync/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that mirrors messages between Slack and
# Discord using AutoKitteh integrations.

version: v1

project:
  name: slack_discord_sync

  vars:
    - name: DISCORD_CHANNEL_ID
      value:
    - name: SLACK_CHANNEL_NAME_OR_ID
      value:

  connections:
    - name: discord_conn
      integration: discord
    - name: slack_conn
      integration: slack

  triggers:
    - name: on_discord_message
      connection: discord_conn
      event_type: message_create
      call: program.py:on_discord_message
    - name: on_slack_message
      connection: slack_conn
      call: program.py:on_slack_message



================================================
FILE: slack_discord_sync/program.py
================================================
"""Mirror messages between Slack and Discord channels using.

Discord documentation:
- https://discordpy.readthedocs.io/

Note:
The `discord` import is crucial for enabling specific Discord API
configurations, such as intents and error handling, but all functional
API calls are made through the autokitteh `ak_discord` wrapper, which
streamlines authentication and secret management.
"""

import os

from autokitteh import discord as ak_discord
from autokitteh import slack
import discord


DISCORD_CHANNEL_ID = int(os.getenv("DISCORD_CHANNEL_ID", ""))
SLACK_CHANNEL = os.getenv("SLACK_CHANNEL_NAME_OR_ID", "")

# Discord intents that enable the bot to read message content
intents = discord.Intents.default()
intents.message_content = True

client = ak_discord.discord_client("discord_conn", intents)
slack_api = slack.slack_client("slack_conn")

# Stores the latest message received from Slack, to be posted to Discord
slack_message = None


def on_discord_message(event):
    slack_api.chat_postMessage(channel=SLACK_CHANNEL, text=event.data["content"])


def on_slack_message(event):
    global slack_message
    slack_message = event.data["text"]
    client.run(ak_discord.bot_token("discord_conn"))


@client.event
async def on_ready():
    """An asynchronous event triggered when the Discord bot successfully connects.

    It fetches the Discord channel by ID and sends the latest message received
    from Slack to the channel, then closes the client connection.
    """
    try:
        channel = await client.fetch_channel(DISCORD_CHANNEL_ID)
    except discord.DiscordException as e:
        print(f"Could not find Discord channel with ID: {DISCORD_CHANNEL_ID}: {e}")
        return

    await channel.send(slack_message)

    await client.close()



================================================
FILE: slack_support/README.md
================================================
title: AI-driven Slack bot for assistance requests
description: Automatically route help requests to the right expert based on topic analysis and expertise matching
integrations: ["slack", "googlesheets", "googlegemini"]
categories: ["AI", "Productivity"]
tags: ["next_event", "subscribe", "interactive_workflows", "user_interactions", "event_loops", "timeout_handling", "notifications", "state_management"]



================================================
FILE: slack_support/autokitteh.yaml
================================================
version: v1

project:
  name: slack_support

  vars:
    - # Google Sheet ID for a sheet that contains a mapping between users and the
      # the topics they can support.
      # Expected google sheet structure:
      #   | A       | B         | C
      # --+---------+-----------+--------------
      # 1 | Gizmo   | U12345678 | topic1,topic2
      # 2 | George  | U87654321 | topic3
      name: DIRECTORY_GOOGLE_SHEET_ID
      value:
    - # Time in minutes to wait for the issue to be picked up before
      # reminder.
      name: HELP_REQUEST_TIMEOUT_MINUTES
      value: 10

  connections:
    - name: myslack
      integration: slack
    - name: mygsheets
      integration: googlesheets
    - name: gemini_conn
      integration: googlegemini

  triggers:
    - name: slack_app_mention
      connection: myslack
      event_type: app_mention
      call: main.py:on_slack_mention



================================================
FILE: slack_support/directory.py
================================================
"""Mapping between topics and people who are knowledgeable about them."""

from dataclasses import dataclass
import os

from autokitteh.google import google_sheets_client


DIRECTORY_GOOGLE_SHEET_ID = os.getenv("DIRECTORY_GOOGLE_SHEET_ID", "")

gsheets = google_sheets_client("mygsheets").spreadsheets().values()


@dataclass
class Person:
    """A person in the directory."""

    name: str
    slack_id: str
    topics: list[str]


def load() -> dict[str, list[Person]]:  # topic -> list of people
    vs = (
        gsheets.get(spreadsheetId=DIRECTORY_GOOGLE_SHEET_ID, range="A1:C100")
        .execute()
        .get("values", [])
    )

    ppl = [Person(v[0], v[1], v[2].split(",")) for v in vs]

    topics = {topic for person in ppl for topic in person.topics}

    return {
        topic: [person for person in ppl if topic in person.topics] for topic in topics
    }



================================================
FILE: slack_support/gemini.py
================================================
"""Deduce the topic of a given text."""

import json

from autokitteh.google import gemini_client


generation_config = {"response_mime_type": "application/json"}
gemini = gemini_client("gemini_conn", generation_config=generation_config)


def extract_topic(text: str, topics: set[str]) -> str:
    prompt = f"""Topics: {", ".join(topics)}
        Is the following text a request for help with one of these topics?
        Example responses:
        If a request for help and a topic is in the list:
        {{"help": true, "topic": "cats" }}
        If a request for help and topic is not in the list:
        {{"help": true, "topic": None }}
        If not a request for help: {{"help": false}}

        Text to analyze:
        {text}"""

    resp = json.loads(gemini.generate_content(prompt).text)
    return resp.get("help"), resp.get("topic")



================================================
FILE: slack_support/main.py
================================================
"""Handles Slack mentions and help requests, sending reminders if unresolved."""

from datetime import datetime, UTC
import os

import autokitteh
from autokitteh.slack import slack_client

import directory
import gemini


HELP_REQUEST_TIMEOUT_MINUTES = int(os.getenv("HELP_REQUEST_TIMEOUT_MINUTES"))

slack_client = slack_client("myslack")


def on_slack_mention(event):
    def send(text):
        """Helper function to just post some text back in the same thread."""
        slack_client.chat_postMessage(
            channel=event.data.channel,
            thread_ts=event.data.ts,
            text=text,
        )

        # prints are used for logging, and can be seen in the console output.
        print(f"sent: '{text}'")

    topics_to_people = directory.load()

    help, topic = gemini.extract_topic(event.data.text, topics_to_people.keys())
    if not help:
        return

    people = topics_to_people.get(topic)
    if not people:
        send(f"Sorry, I don't know who to ask about {topic}.")
        return

    mentions = ", ".join(f"<@{p.slack_id}>" for p in people)

    send(f"""People who can help are: {mentions}.
Responders: please reply in this thread with `!take` or `!resolve`.
If not taken or resolved, I will remind you in {HELP_REQUEST_TIMEOUT_MINUTES}m.
""")

    # From this point on we are interested in any message that is added to the thread.
    # Further below we'll consume the messages and act on them using `next_event`.
    filter = "data.type == 'message' && data.thread_ts == "
    filter += f"'{event.data.ts}' && data.text.startsWith('!')"
    s = autokitteh.subscribe("myslack", filter)

    taken_by = None
    start_time = datetime.now(UTC)

    while True:
        msg = autokitteh.next_event(s, timeout=60)

        if not msg:  # timeout
            dt = (datetime.now(UTC) - start_time).total_seconds()
            print(f"timeout, dt={dt}")

            if not taken_by and dt >= HELP_REQUEST_TIMEOUT_MINUTES * 60:
                send(f"Reminder: {mentions}, please respond.")
                start_time = datetime.now(UTC)
            continue

        cmd = msg.text.strip()[1:]
        if cmd == "resolve":
            send("Issue is now resolved.")
            # this effectively ends the workflow.
            return
        if cmd == "take":
            taken_by = msg.user
            send(f"Thanks <@{msg.user}>, you've taken this issue.")



================================================
FILE: task_chain/README.md
================================================



================================================
FILE: task_chain/event_driven/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that runs a sequence of tasks, using an
# event-driven approach.

version: v1

project:
  name: task_chain

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: slack_slash_command
      connection: slack_conn
      event_type: slash_command
      call: program.py:on_slack_slash_command
    - name: slack_interaction
      connection: slack_conn
      event_type: interaction
      call: program.py:on_slack_interaction



================================================
FILE: task_chain/event_driven/interactive_message.json.txt
================================================
[
    {
        "type": "header",
        "text": {
            "type": "plain_text",
            "emoji": true,
            "text": ":warning: Workflow Error"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "MESSAGE"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "actions",
        "elements": [
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Retry"
                },
                "value": "retry",
                "action_id": "RETRY INDEX"
            },
            {
                "type": "button",
                "style": "danger",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Abort"
                },
                "value": "abort",
                "action_id": "ABORT INDEX"
            }
        ]
    }
]



================================================
FILE: task_chain/event_driven/program.py
================================================
"""This module uses an event-driven approach for the task-chain project.

A single workflow runs all the tasks, except retries:

1. First workflow:
   - Trigger: Slack slash command
   - Task 1 -> Task 2 -> Task 3 (error) -> Workflow error
2. Second workflow:
   - Trigger: user clicks the "Retry" button in Slack
   - Task 3 (retry) -> Task 4 -> Successful workflow completion
"""

from pathlib import Path
import random

from autokitteh.slack import slack_client


slack = slack_client("slack_conn")


def step1():
    print("Step 1 is doing stuff...")


def step2():
    print("Step 2 is doing stuff...")


def step3():
    print("Step 3 is doing stuff...")
    if random.choice([True, False]):
        raise RuntimeError("Something bad happened")


def step4():
    print("Step 4 is doing stuff...")


tasks = [step1, step2, step3, step4]


def on_slack_slash_command(event):
    """Use a Slack slash command from a user to start a chain of tasks."""
    run_tasks(0, event.data.user_id)


def run_tasks(start_index, user_id):
    # Note to the interested reader: it's easy to improve this project
    # to traverse a dynamic DAG, instead of a simple static list.
    for i, task in enumerate(tasks):
        if i >= start_index:
            run_retriable_task(task, i, user_id)

    message = "Workflow completed successfully :smiley_cat:"
    slack.chat_postMessage(channel=user_id, text=message)


def run_retriable_task(task, i, user_id):
    try:
        task()
    except Exception as e:
        ask_user_retry_or_abort(task.__name__, e, i, user_id)
        raise e  # Abort the current workflow.

    message = f"Task `{task.__name__}` completed"
    slack.chat_postMessage(channel=user_id, text=message)


def ask_user_retry_or_abort(task_name, error, i, user_id):
    message = f"The task `{task_name}` failed: `{error}`"
    blocks = Path("interactive_message.json.txt").read_text()
    blocks = blocks.replace("MESSAGE", message).replace("INDEX", str(i))
    slack.chat_postMessage(channel=user_id, text="Workflow error", blocks=blocks)


def on_slack_interaction(event):
    """Handle the user's response (retry / abort) in a new workflow."""
    if event.data.actions[0]["value"] == "abort":
        return

    # This workflow's starting point is a retry of the failed task in the aborted one.
    i = int(event.data.actions[0]["action_id"].split()[-1])
    run_tasks(i, event.data.user.id)



================================================
FILE: task_chain/single_workflow/advanced/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that runs a sequence of tasks, using an
# advanced single-workflow approach.

version: v1

project:
  name: task_chain

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: slack_slash_command
      connection: slack_conn
      event_type: slash_command
      call: program.py:on_slack_slash_command



================================================
FILE: task_chain/single_workflow/advanced/interactive_message.json.txt
================================================
[
    {
        "type": "header",
        "text": {
            "type": "plain_text",
            "emoji": true,
            "text": ":warning: Workflow Error"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "MESSAGE"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "actions",
        "elements": [
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Retry"
                },
                "value": "retry",
            },
            {
                "type": "button",
                "style": "danger",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Abort"
                },
                "value": "abort",
            }
        ]
    }
]



================================================
FILE: task_chain/single_workflow/advanced/program.py
================================================
"""This module uses a single-workflow approach for the task-chain project.

A single workflow runs all the tasks, including retry loops.
It handles Slack interactions using runtime event subscriptions.
"""

from pathlib import Path
import random

import autokitteh
from autokitteh.slack import slack_client


slack = slack_client("slack_conn")


def step1():
    print("Step 1 is doing stuff...")


def step2():
    print("Step 2 is doing stuff...")


def step3():
    print("Step 3 is doing stuff...")
    if random.choice([True, False]):
        raise RuntimeError("Something bad happened")


def step4():
    print("Step 4 is doing stuff...")


tasks = [step1, step2, step3, step4]


def on_slack_slash_command(event):
    """Use a Slack slash command from a user to start a chain of tasks."""
    user_id = event.data.user_id

    # Note to the interested reader: it's easy to improve this project
    # to traverse a dynamic DAG, instead of a simple static list.
    success = True
    while len(tasks) > 0 and success:
        success = run_retriable_task(tasks[0], user_id)

    if success:
        message = "Workflow completed successfully :smiley_cat:"
        slack.chat_postMessage(channel=user_id, text=message)


def run_retriable_task(task, user_id) -> bool:
    try:
        task()
    except RuntimeError as e:
        return ask_user_retry_or_abort(task.__name__, e, user_id)

    message = f"Task `{task.__name__}` completed"
    slack.chat_postMessage(channel=user_id, text=message)

    global tasks
    tasks.remove(task)
    return True


def ask_user_retry_or_abort(task_name, error, user_id) -> bool:
    sub = autokitteh.subscribe("slack_conn", 'event_type == "interaction"')

    blocks = Path("interactive_message.json.txt").read_text()
    blocks = blocks.replace("MESSAGE", f"The task `{task_name}` failed: `{error}`")
    slack.chat_postMessage(channel=user_id, text="Workflow error", blocks=blocks)

    # Wait for and handle the user's response in this workflow.
    event = autokitteh.next_event(sub)
    autokitteh.unsubscribe(sub)
    return event.actions[0]["value"] == "retry"



================================================
FILE: task_chain/single_workflow/basic/README.md
================================================
title: Fault tolerant workflow with manual Slack approvals
description: Runs a sequence of tasks with fault tolerance. In case of failure, user can decide to terminate or retry from the point of failure.
integrations: ["slack"]
categories: ["Durability"]
tags: ["retry_mechanisms", "error_handling", "interactive_workflows", "user_interactions", "subscribe", "next_event", "unsubscribe", "essential"]



================================================
FILE: task_chain/single_workflow/basic/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that runs a sequence of tasks, using a
# basic single-workflow approach.

version: v1

project:
  name: task_chain

  connections:
    - name: slack_conn
      integration: slack

  triggers:
    - name: slack_slash_command
      connection: slack_conn
      event_type: slash_command
      call: program.py:on_slack_slash_command



================================================
FILE: task_chain/single_workflow/basic/interactive_message.json.txt
================================================
[
    {
        "type": "header",
        "text": {
            "type": "plain_text",
            "emoji": true,
            "text": ":warning: Workflow Error"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "MESSAGE"
        }
    },
    {
        "type": "divider"
    },
    {
        "type": "actions",
        "elements": [
            {
                "type": "button",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Retry"
                },
                "value": "retry",
            },
            {
                "type": "button",
                "style": "danger",
                "text": {
                    "type": "plain_text",
                    "emoji": true,
                    "text": "Abort"
                },
                "value": "abort",
            }
        ]
    }
]



================================================
FILE: task_chain/single_workflow/basic/program.py
================================================
"""This module uses a single-workflow approach for the task-chain project.

A single workflow runs all the tasks, including retry loops.
It handles Slack interactions using runtime event subscriptions.
"""

from pathlib import Path
import random

import autokitteh
from autokitteh.slack import slack_client


slack = slack_client("slack_conn")


def step1():
    print("Step 1 is doing stuff...")


def step2():
    print("Step 2 is doing stuff...")


def step3():
    print("Step 3 is doing stuff...")
    if random.choice([True, False]):
        raise RuntimeError("Something bad happened")


def step4():
    print("Step 4 is doing stuff...")


def on_slack_slash_command(event):
    """Use a Slack slash command from a user to start a chain of tasks."""
    user_id = event.data.user_id

    if not run_retriable_task(step1, user_id):
        return
    if not run_retriable_task(step2, user_id):
        return
    if not run_retriable_task(step3, user_id):
        return
    if not run_retriable_task(step4, user_id):
        return

    message = "Workflow completed successfully :smiley_cat:"
    slack.chat_postMessage(channel=user_id, text=message)


def run_retriable_task(task, user_id) -> bool:
    result = True
    while result:
        try:
            task()
            break
        except RuntimeError as e:
            result = ask_user_retry_or_abort(task.__name__, e, user_id)

    if result:
        message = f"Task `{task.__name__}` completed"
        slack.chat_postMessage(channel=user_id, text=message)

    return result


def ask_user_retry_or_abort(task_name, error, user_id) -> bool:
    sub = autokitteh.subscribe("slack_conn", 'event_type == "interaction"')

    blocks = Path("interactive_message.json.txt").read_text()
    blocks = blocks.replace("MESSAGE", f"The task `{task_name}` failed: `{error}`")
    slack.chat_postMessage(channel=user_id, text="Workflow error", blocks=blocks)

    # Wait for and handle the user's response in this workflow.
    event = autokitteh.next_event(sub)
    autokitteh.unsubscribe(sub)
    return event.actions[0]["value"] == "retry"



================================================
FILE: telegram_ai_translator/README.md
================================================
title: Telegram AI Translator Bot
description: Smart translation bot with contextual understanding using Gemini AI
integrations: ["telegram", "googlegemini"]
categories: ["AI"]
tags: ["translation", "ai", "chatbot", "multilingual"]



================================================
FILE: telegram_ai_translator/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that creates a Telegram bot for AI-powered translation

version: v1

project:
  name: telegram_ai_translator

  connections:
    - name: gemini_conn
      integration: googlegemini
    - name: telegram_conn
      integration: telegram

  triggers:
    - name: on_message
      connection: telegram_conn
      event_type: message
      call: program.py:on_message_trigger



================================================
FILE: telegram_ai_translator/program.py
================================================
"""Telegram AI Translator Bot

A smart translation bot that uses Gemini AI to provide contextual translations
with cultural nuances.
"""

import asyncio

from autokitteh.google import gemini_client
from autokitteh.telegram import telegram_client

from prompts import DETECT_USAGE
from prompts import get_detect_prompt
from prompts import get_translate_prompt
from prompts import HELP_TEXT
from prompts import TRANSLATE_USAGE


gemini = gemini_client("gemini_conn", model_name="gemini-2.5-flash-lite")
telegram = telegram_client("telegram_conn")


def on_message_trigger(event):
    """Entry point for handling incoming messages.

    Note: AutoKitteh triggers call this function synchronously,
    so we use asyncio.run() to execute async handlers.
    """
    asyncio.run(on_telegram_message(event))


async def on_telegram_message(event):
    """Handle incoming Telegram messages and provide AI-powered translations."""
    message = event.data.message
    chat_id = message.chat.id
    text = message.text

    # Ignore empty messages.
    if not text:
        return

    command = text.split()[0] if text else ""

    match command:
        case "/translate":
            await handle_translate_command(text, chat_id)
        case "/detect":
            await handle_detect_command(text, chat_id)
        case "/help":
            await handle_help_command(chat_id)


async def handle_translate_command(text: str, chat_id):
    """Handle /translate command.

    Note: Expected format is "/translate <target_lang> <text>"
    Example: /translate Spanish Hello, how are you?
    """
    parts = text.split(maxsplit=2)
    if len(parts) < 3:  # Not enough parts
        await telegram.send_message(chat_id=chat_id, text=TRANSLATE_USAGE)
        return

    target_lang = parts[1]
    text_to_translate = parts[2]
    prompt = get_translate_prompt(target_lang, text_to_translate)

    response = gemini.generate_content(prompt)
    await telegram.send_message(chat_id=chat_id, text=response.text)


async def handle_detect_command(text: str, chat_id):
    """Handle /detect command.

    Note: Expected format is "/detect <target_lang> <text>"
    Example: /detect English Hola, ¬øc√≥mo est√°s?
    """
    parts = text.split(maxsplit=2)
    if len(parts) < 3:
        await telegram.send_message(chat_id=chat_id, text=DETECT_USAGE)
        return

    target_lang = parts[1]
    text_to_translate = parts[2]
    prompt = get_detect_prompt(target_lang, text_to_translate)

    response = gemini.generate_content(prompt)
    await telegram.send_message(chat_id=chat_id, text=response.text)


async def handle_help_command(chat_id):
    """Handle /help command."""
    await telegram.send_message(chat_id=chat_id, text=HELP_TEXT)



================================================
FILE: telegram_ai_translator/prompts.py
================================================
"""Constants for the Telegram AI Translator bot."""

# Help message
HELP_TEXT = """üåç AI Translator Bot

Commands:
/translate <lang> <text> - Translate text to target language
/detect <lang> <text> - Auto-detect source language and translate
/help - Show this help message

Examples:
/translate es Hello, how's your project going?
/translate fr Good morning!
/detect en Bonjour le monde!

Powered by Gemini AI ü§ñ
"""

# Usage messages
TRANSLATE_USAGE = """Usage: /translate <target_language> <text>
Example: /translate es Hello, how are you?"""

DETECT_USAGE = """Usage: /detect <target_language> <text>
Example: /detect en Hola, ¬øc√≥mo est√°s?"""


# Prompt templates
def get_translate_prompt(target_lang: str, text: str) -> str:
    """Generate translation prompt for Gemini."""
    return f"""Translate the following text to {target_lang}.
Provide a natural, contextual translation that preserves tone and meaning.
If there are cultural nuances or idioms, briefly explain them after the translation.

Text: {text}

Format your response as:
Translation: <translated text>
Notes: <any cultural context or notes, if applicable>
"""


def get_detect_prompt(target_lang: str, text: str) -> str:
    """Generate auto-detect translation prompt for Gemini."""
    return f"""Detect the source language and translate to {target_lang}.
Provide a natural translation with cultural context.

Text: {text}

Format:
Detected: <source language>
Translation: <translated text>
Notes: <cultural context if relevant>
"""



================================================
FILE: walkthroughs/new_gmail_notification/README.md
================================================
title: Gmail new email notification
description: Poll for new emails in Gmail inbox and handle them with custom logic
integrations: ["gmail"]
categories: ["Productivity"]



================================================
FILE: walkthroughs/new_gmail_notification/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that demonstrates how to poll for new emails
version: v1

project:
  name: new_mail

  vars:
    - name: TIME_LIMIT_MINUTES
      value:

  connections:
    - name: gmail_conn
      integration: gmail

  triggers:
    - name: poll
      schedule: "@every 15m"
      call: program.py:poll_new_emails



================================================
FILE: walkthroughs/new_gmail_notification/program.py
================================================
"""Custom Gmail event system that works as a trigger when new emails arrive."""

from datetime import datetime, UTC
import os

import autokitteh
from autokitteh.google import gmail_client
from googleapiclient.errors import HttpError


gmail = gmail_client("gmail_conn")
TIME_LIMIT_MINUTES = int(os.getenv("TIME_LIMIT_MINUTES") or "16")


def poll_new_emails(_):
    """Poll for new emails in the Gmail inbox."""
    messages = (
        gmail.users()
        .messages()
        .list(userId="me", labelIds=["INBOX"])
        .execute()
        .get("messages", [])
    )
    if not messages:
        print("No messages found in inbox")
        return

    latest_msg_id = messages[0]["id"]
    last_msg_id = autokitteh.get_value("last_msg_id")

    # First run: store latest message ID.
    if last_msg_id is None:
        autokitteh.set_value("last_msg_id", latest_msg_id)
        print("First run - storing latest message ID")
        return

    new_msg_ids = collect_new_messages(last_msg_id)

    if new_msg_ids:
        print(f"New emails: {len(new_msg_ids)}")
        for msg_id in new_msg_ids:
            process_message(msg_id)

    autokitteh.set_value("last_msg_id", latest_msg_id)


def collect_new_messages(last_msg_id):
    """Collect new message IDs until reaching last processed message or time limit."""
    new_msg_ids = []
    current_time = datetime.now(UTC)
    next_page_token = None

    while True:
        params = {"userId": "me", "labelIds": ["INBOX"]}
        if next_page_token:
            params["pageToken"] = next_page_token

        response = gmail.users().messages().list(**params).execute()
        messages = response.get("messages", [])

        if not messages:
            break

        for msg in messages:
            if msg["id"] == last_msg_id:
                return new_msg_ids

            if is_message_too_old(msg["id"], current_time):
                return new_msg_ids

            new_msg_ids.append(msg["id"])

        next_page_token = response.get("nextPageToken")
        if not next_page_token:
            break

    return new_msg_ids


def process_message(msg_id):
    """Process a single message."""
    try:
        full_message = gmail.users().messages().get(userId="me", id=msg_id).execute()
        headers = {
            h["name"]: h["value"]
            for h in full_message.get("payload", {}).get("headers", [])
        }

        print("New Mail Received:")
        print(f"From: {headers.get('From')}")
        print(f"To: {headers.get('To')}")
        print(f"Subject: {headers.get('Subject')}")
        print("-" * 50)

    except HttpError as e:
        print(f"Error fetching message {msg_id}: {e}")


def is_message_too_old(msg_id, current_time):
    """Check if a message is older than the time limit."""
    try:
        msg_details = (
            gmail.users()
            .messages()
            .get(userId="me", id=msg_id, fields="internalDate")
            .execute()
        )
        email_timestamp = int(msg_details.get("internalDate", 0)) / 1000
        email_datetime = datetime.fromtimestamp(email_timestamp, UTC)
        time_diff_minutes = (current_time - email_datetime).total_seconds() / 60

        if time_diff_minutes > TIME_LIMIT_MINUTES:
            print(f"Stopped processing emails older than {TIME_LIMIT_MINUTES} minutes.")
            return True

        return False

    except HttpError as e:
        print(f"Error checking timestamp for message {msg_id}: {e}")
        return False



================================================
FILE: walkthroughs/quickstart/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes
# the minimal setup of an AutoKitteh project.

version: v1

project:
  name: quickstart



================================================
FILE: walkthroughs/quickstart/program.py
================================================
"""Handler for manual runs with a simple loop."""

import time


SLEEP_SECONDS = 1
ITERATIONS = 5


def on_manual_run(_):
    for i in range(ITERATIONS):
        print(f"Loop iteration: {i + 1} of {ITERATIONS}")
        time.sleep(SLEEP_SECONDS)



================================================
FILE: walkthroughs/send_email/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes
# the minimal setup of an AutoKitteh project.

version: v1

project:
  name: send_email

  connections:
    - name: gmail_conn
      integration: gmail



================================================
FILE: walkthroughs/send_email/program.py
================================================
"""Simple workflow for sending emails."""

import base64

from autokitteh.google import gmail_client
from googleapiclient.errors import HttpError


gmail = gmail_client("gmail_conn").users()


def on_manual_run(_):
    profile = gmail.getProfile(userId="me").execute()

    msg = f"""From: {profile["emailAddress"]}
    To: {profile["emailAddress"]}
    Subject: Test from AutoKitteh

    Meow! Just wanted to let you know that your cat overlords are pleased with your
    service today. Keep up the good work with the treats and belly rubs!"""

    msg = msg.replace("\n", "\r\n").replace("    ", "")
    msg = base64.urlsafe_b64encode(msg.encode()).decode()
    try:
        gmail.messages().send(userId="me", body={"raw": msg}).execute()
    except HttpError as e:
        print(f"Error: `{e.reason}`")
        return

    print("Message sent successfully!")



================================================
FILE: walkthroughs/send_slack_message/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes
# the minimal setup of an AutoKitteh project.

version: v1

project:
  name: send_slack_message

  vars:
    - name: CHANNEL
      value: general

  connections:
    - name: slack_conn
      integration: slack
    



================================================
FILE: walkthroughs/send_slack_message/program.py
================================================
"""Simple workflow that sends a message to Slack."""

import os

from autokitteh.slack import slack_client


CHANNEL = os.getenv("CHANNEL")


def on_manual_run(_):
    slack_client("slack_conn").chat_postMessage(
        channel=CHANNEL,
        text="Meow, world!",
    )



================================================
FILE: walkthroughs/webhook/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes
# the minimal setup of an AutoKitteh project.

version: v1

project:
  name: webhook



================================================
FILE: walkthroughs/webhook/program.py
================================================
"""A simple workflow that is triggered by a webhook."""


def on_webhook(event):
    print(event)



================================================
FILE: webhook_to_jira/README.md
================================================
title: Create Jira ticket from webhook data
description: Create Jira issues automatically from HTTP webhooks
integrations: ["jira"]
categories: ["DevOps"]
tags: ["webhook_handling", "data_processing", "notifications"]



================================================
FILE: webhook_to_jira/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup of
# an AutoKitteh project that creates Jira issues based on HTTP requests.

version: v1

project:
  name: webhook_to_jira

  connections:
    - name: jira_conn
      integration: jira

  triggers:
    - name: http_get_or_post_request
      type: webhook
      filter: data.method == "GET" || data.method == "POST"
      call: program.py:on_http_request



================================================
FILE: webhook_to_jira/program.py
================================================
"""Create Jira issues based on HTTP GET/POST requests.

Atlassian Jira API documentation:
- https://docs.autokitteh.com/integrations/atlassian/jira/python

HTTP API documentation:
- https://docs.autokitteh.com/integrations/http/events
"""

from autokitteh.atlassian import jira_client


def on_http_request(event):
    """Webhook for HTTP GET and POST requests."""
    if event.data.method == "GET":
        _create_jira_issue(event.data.url.query)
        return

    match event.data.headers.get("Content-Type"):
        case "application/json":
            json_body = event.data.body.json  # Or: json.loads(event.data.body.bytes)
            _create_jira_issue(json_body)
        case "application/x-www-form-urlencoded":
            form_body = event.data.body.form  # Or: dict(urllib.parse.parse_qsl(body))
            _create_jira_issue(form_body)


def _create_jira_issue(fields):
    if isinstance(fields["project"], str):
        fields["project"] = {"key": fields["project"]}
    if isinstance(fields["issuetype"], str):
        fields["issuetype"] = {"name": fields["issuetype"]}

    issue = jira_client("jira_conn").issue_create(fields=fields)
    print("Created Jira issue:", issue["key"])



================================================
FILE: whatsapp_chatbot/README.md
================================================
title: WhatsApp ChatGPT Bot
description: WhatsApp chatbot that responds to messages using ChatGPT intelligence
integrations: ["twilio", "chatgpt"]
categories: ["AI", "Productivity"]
tags: ["webhook_handling", "next_event", "long_running"]



================================================
FILE: whatsapp_chatbot/autokitteh.yaml
================================================
# Autokitteh configuration for WhatsApp Chatbot

version: v1

project:
  name: whatsapp_chatbot

  connections:
    - name: twilio_conn
      integration: twilio
    - name: chatgpt_conn
      integration: chatgpt

  triggers:
    - name: whatsapp_message
      type: webhook
    - name: start_chatbot
      type: webhook
      call: program.py:start_chatbot

  vars:
    - name: FROM_NUMBER
      value: ""



================================================
FILE: whatsapp_chatbot/program.py
================================================
"""WhatsApp chatbot using Twilio and ChatGPT."""

import os

from tenacity import retry
from tenacity import retry_if_exception
from tenacity import stop_after_attempt
from tenacity import wait_exponential
from twilio.base.exceptions import TwilioRestException

import autokitteh
from autokitteh.openai import openai_client
from autokitteh.twilio import twilio_client


twilio = twilio_client("twilio_conn")
chatgpt = openai_client("chatgpt_conn")


SYSTEM_PROMPT = """You are a helpful WhatsApp chatbot assistant. Respond in a friendly,
        conversational tone.
        Keep your responses concise and helpful since this is a messaging platform.
        Be engaging and personable while providing useful information or assistance."""


# Number from environment variable or default Twilio number.
FROM_NUMBER = os.getenv("FROM_NUMBER", "whatsapp:+14155238886")

CHAT_HIST = {}


def start_chatbot(_):
    """Start WhatsApp chatbot that listens for messages and responds with ChatGPT."""
    print("Starting WhatsApp chatbot - waiting for messages...")
    webhook_sub = autokitteh.subscribe("whatsapp_message")

    while True:
        webhook_event = autokitteh.next_event(webhook_sub)

        if webhook_event:
            message_body = webhook_event.body.form.get("Body", "")
            sender_number = webhook_event.body.form.get("From", "")
            print(f"Message from {sender_number}: {message_body}")

            # Skip empty messages.
            if not message_body.strip():
                print("Empty message received, skipping")
                continue
            try:
                if "clear history" in message_body.lower():
                    clear_conversation_history(sender_number)
                    send_whatsapp_message(
                        sender_number, "Conversation history cleared."
                    )
                    continue

                response = generate_chatgpt_response(sender_number, message_body)
                send_whatsapp_message(sender_number, response)
                print(f"Response sent to {sender_number}: {response}")

            except (KeyError, ValueError, AttributeError, TwilioRestException) as e:
                print(f"Error processing message: {e}")
                continue


def generate_chatgpt_response(sender_number, user_message):
    """Generate response using ChatGPT with conversation history."""
    try:
        if sender_number not in CHAT_HIST:
            CHAT_HIST[sender_number] = []

        # Add user message to history.
        CHAT_HIST[sender_number].append({"role": "user", "content": user_message})

        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        messages.extend(CHAT_HIST[sender_number])

        # Limit conversation history to prevent token overflow (keep last 20 messages).
        if len(messages) > 21:
            messages = [messages[0]] + messages[-20:]
            CHAT_HIST[sender_number] = messages[1:]

        print(f"Sending {len(messages)} messages to ChatGPT for {sender_number}")

        response = chatgpt.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=500,
            temperature=0.7,
        )

        ai_response = response.choices[0].message.content.strip()

        CHAT_HIST[sender_number].append({"role": "assistant", "content": ai_response})

        return ai_response

    except (KeyError, ValueError, AttributeError) as e:
        print(f"Error generating ChatGPT response: {e}")
        return "I'm sorry, I couldn't process your request right now. Please try again."


def retry_on_rate_limit(exception):
    return "429" in str(exception)


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception(retry_on_rate_limit),
    reraise=True,
)
def send_whatsapp_message(to_number, message):
    """Send WhatsApp message via Twilio with retry on rate limits."""
    try:
        result = twilio.messages.create(body=message, from_=FROM_NUMBER, to=to_number)
        print(f"Message sent with SID: {result.sid}")
        return result.sid
    except Exception as e:
        print(f"Failed to send message: {e}")
        print("retrying to send message...")
        raise


def clear_conversation_history(sender_number):
    """Clear conversation history for a specific user."""
    if sender_number in CHAT_HIST:
        del CHAT_HIST[sender_number]
        print(f"Cleared conversation history for {sender_number}")



================================================
FILE: youtube_upload_notif/README.md
================================================
title: YouTube Video Notifier
description: Polls YouTube channels for new videos and sends Slack notifications
integrations: ["youtube", "slack"]
categories: ["Productivity"]
tags: ["Polling", "notifications", "memory vars"]



================================================
FILE: youtube_upload_notif/autokitteh.yaml
================================================
# This YAML file is a declarative manifest that describes the setup
# of an AutoKitteh project that polls for new YouTube videos from a specific channel.

version: v1

project:
  name: youtube_video_poller

  connections:
    - name: youtube_conn
      integration: youtube

    - name: slack_conn
      integration: slack

  triggers:
    - name: poll_for_new_videos
      schedule: "*/5 * * * *"
      call: program.py:poll_for_new_videos

  vars:
    - name: YOUTUBE_CHANNEL_NAME
      value: ""
    - name: SLACK_CHANNEL
      value: ""



================================================
FILE: youtube_upload_notif/program.py
================================================
"""Poll for new YouTube videos from a specific channel and send to slack."""

from datetime import datetime, UTC
import os

import autokitteh
from autokitteh.google import youtube_client
from autokitteh.slack import slack_client


youtube = youtube_client("youtube_conn")
slack = slack_client("slack_conn")


YT_CHANNEL_NAME = os.getenv("YOUTUBE_CHANNEL_NAME")
SLACK_CHANNEL = os.getenv("SLACK_CHANNEL")
MAX_RESULTS = 5  # Number of videos to check.


def poll_for_new_videos(event):
    """Poll for new videos from the configured YouTube channel.

    This function is triggered by a scheduled cron job.
    It checks for new videos and send to slack info about any new ones found.
    """
    channel_id = get_channel_id()
    if channel_id is None:
        print("no channel found")
        return

    search_response = (
        youtube.search()
        .list(
            part="snippet",
            channelId=channel_id,
            order="date",
            type="video",
            maxResults=MAX_RESULTS,
        )
        .execute()
    )

    videos = search_response.get("items", [])

    if not videos:
        print("No videos found for this channel")
        return

    # Get the last checked timestamp.
    last_checked = autokitteh.get_value("last_checked_timestamp")

    if last_checked:
        last_checked_dt = datetime.fromisoformat(last_checked)
    else:
        current_time = datetime.now(UTC).isoformat()
        autokitteh.set_value("last_checked_timestamp", current_time)
        print("Will be notified about new videos.")
        return

    new_videos = []
    latest_timestamp = last_checked

    for video in videos:
        video_published = video["snippet"]["publishedAt"]
        video_published_dt = datetime.fromisoformat(
            video_published.replace("Z", "+00:00")
        )

        if video_published_dt > last_checked_dt:
            new_videos.append(video)

            if video_published > latest_timestamp:
                latest_timestamp = video_published

    if new_videos:
        for video in new_videos:
            snippet = video["snippet"]
            video_id = video["id"]["videoId"]
            video_url = f"https://www.youtube.com/watch?v={video_id}"

            message = create_slack_message(snippet, video_url)

            slack.chat_postMessage(
                channel=SLACK_CHANNEL,
                text=f"üÜï New video from {YT_CHANNEL_NAME}!",
                blocks=message,
            )

        autokitteh.set_value("last_checked_timestamp", latest_timestamp)


def get_channel_id():
    resp = (
        youtube.search()
        .list(part="snippet", q=YT_CHANNEL_NAME, type="channel", maxResults=1)
        .execute()
    )

    items = resp.get("items") or []
    return items[0]["snippet"]["channelId"] if items else None


def create_slack_message(snippet, video_url):
    """Create a formatted Slack message block for a new video."""
    title = snippet["title"]
    description = snippet["description"]
    published_at = snippet["publishedAt"]
    thumbnail_url = snippet.get("thumbnails", {}).get("medium", {}).get("url", "")

    short_desc = description[:300] + "..." if len(description) > 300 else description

    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": "üé¨ New YouTube Video!"},
        },
        {
            "type": "section",
            "fields": [
                {"type": "mrkdwn", "text": f"*üì∫ Channel:*\n{YT_CHANNEL_NAME}"},
                {"type": "mrkdwn", "text": f"*üìÖ Published:*\n{published_at}"},
            ],
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"*{title}*\n\n{short_desc}"},
            "accessory": {
                "type": "button",
                "text": {"type": "plain_text", "text": "‚ñ∂Ô∏è Watch Video"},
                "url": video_url,
                "action_id": "watch_video",
            },
        },
    ]

    if thumbnail_url:
        blocks.append(
            {
                "type": "image",
                "image_url": thumbnail_url,
                "alt_text": f"Thumbnail for {title}",
            }
        )

    return blocks


